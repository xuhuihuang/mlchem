{
  "examples": [
    {
      "source": "Chapter 7: Generating Chemical Data \u2013 AI Generative Models\n---------------------------------------------------",
      "names": [],
      "example": {
        "document": "examples",
        "ref_id": "chapter-7-generating-chemical-data-ai-generative-models",
        "headings": [
          "Jupyter Notebook Tutorial Gallery",
          "Chapter 7: Generating Chemical Data \u2013 AI Generative Models"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/cluster/Reference_Ch3_part_1_agglomerative_from_scratch": [
    {
      "source": "import random\nimport numpy as np\nfrom scipy.spatial.distance import pdist, squareform\n\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ncmap = plt.get_cmap('tab10')\ncolors = [cmap(i) for i in range(cmap.N)]\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\nn_samples = 10\nmarkersize = 100",
      "names": [
        {
          "import_components": [
            "random"
          ],
          "code_str": "random",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "random"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 7,
          "end_lineno": 7,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "get_cmap"
          ],
          "code_str": "plt.get_cmap",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.get_cmap"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "random",
            "seed"
          ],
          "code_str": "random.seed",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "random.seed"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "seed"
          ],
          "code_str": "np.random.seed",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.random.seed"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_agglomerative_from_scratch",
        "ref_id": "Agglomerative-Clustering-From-Scratch",
        "headings": [
          "Agglomerative Clustering From Scratch"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "m1 = [1, 1]\ncov1 = [[1, 0], [0, 1]]\ns1 = np.random.multivariate_normal(m1, cov1, 5)\n\nm2 = [-1, -1]\ncov2 = [[1, -0.5], [-0.5, 1]]\ns2 = np.random.multivariate_normal(m2, cov2, 5)\n\nsamples = np.concat([s1, s2])\nnp.random.shuffle(samples)",
      "names": [
        {
          "import_components": [
            "numpy",
            "random",
            "multivariate_normal"
          ],
          "code_str": "np.random.multivariate_normal",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.random.multivariate_normal"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "multivariate_normal"
          ],
          "code_str": "np.random.multivariate_normal",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "numpy.random.multivariate_normal"
        },
        {
          "import_components": [
            "numpy",
            "concat"
          ],
          "code_str": "np.concat",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.concat"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "shuffle"
          ],
          "code_str": "np.random.shuffle",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.random.shuffle"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_agglomerative_from_scratch",
        "ref_id": "Sample-data-points",
        "headings": [
          "Agglomerative Clustering From Scratch",
          "Sample data points"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1], s=markersize, color=\"k\")\n# plt.axis(\"off\")\nplt.xlim([-2, 2])\nplt.ylim([-2, 2])\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_agglomerative_from_scratch",
        "ref_id": "Sample-data-points",
        "headings": [
          "Agglomerative Clustering From Scratch",
          "Sample data points"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def agglomerative_clustering(points, n_clusters):\n    n_points = points.shape[0]\n    cur_clusters = n_points\n    clusters = {i: [i] for i in range(n_points)}\n    distances = squareform(pdist(points))\n    np.fill_diagonal(distances, np.inf)\n\n    merge_list = []\n    labels_list = []\n\n    while cur_clusters > n_clusters:\n        # single-linkage\n        idx = np.argmin(distances)\n        i, j = int(idx//n_points), int(idx%n_points)\n\n        merge_list.append((i, j))\n\n        # merge datapoints in cluster i and j\n        clusters[i].extend(clusters[j])\n        for k in clusters:\n            if k != i:\n                distances[i, k] = distances[k, i] = min(distances[i, k], distances[j, k])\n\n        # remove cluster j\n        clusters.pop(j)\n        cur_clusters -= 1\n        distances[:, j] = np.inf\n        distances[j, :] = np.inf\n\n        # assign labels\n        labels = np.zeros(n_points, dtype=int)\n        for cluster_id, points in clusters.items():\n            for point in points:\n                labels[point] = cluster_id\n        labels_list.append(labels)\n\n    return labels_list, merge_list",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "fill_diagonal"
          ],
          "code_str": "np.fill_diagonal",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.fill_diagonal"
        },
        {
          "import_components": [
            "numpy",
            "inf"
          ],
          "code_str": "np.inf",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.inf"
        },
        {
          "import_components": [
            "numpy",
            "argmin"
          ],
          "code_str": "np.argmin",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.argmin"
        },
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "min"
          ],
          "code_str": "min",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "min"
        },
        {
          "import_components": [
            "numpy",
            "inf"
          ],
          "code_str": "np.inf",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "numpy.inf"
        },
        {
          "import_components": [
            "numpy",
            "inf"
          ],
          "code_str": "np.inf",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.inf"
        },
        {
          "import_components": [
            "numpy",
            "zeros"
          ],
          "code_str": "np.zeros",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "numpy.zeros"
        },
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "int"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_agglomerative_from_scratch",
        "ref_id": "Clustering-Algorithm",
        "headings": [
          "Agglomerative Clustering From Scratch",
          "Clustering Algorithm"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1],\n            s=markersize, color=colors)\n# plt.axis(\"off\")\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_agglomerative_from_scratch",
        "ref_id": "Initialize-clusters",
        "headings": [
          "Agglomerative Clustering From Scratch",
          "Initialize clusters"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "k = 2 # divide into 2 clusters\nlabels_list, merge_list = agglomerative_clustering(samples, k)",
      "names": [],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_agglomerative_from_scratch",
        "ref_id": "After-i-steps",
        "headings": [
          "Agglomerative Clustering From Scratch",
          "After i steps"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# modify this index to visualize results step-by-step\nstep_idx = 0 # after the first step\n\nplt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1],\n            s=markersize, color=[colors[l] for l in labels_list[step_idx]])\n# plt.axis(\"off\")\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_agglomerative_from_scratch",
        "ref_id": "After-i-steps",
        "headings": [
          "Agglomerative Clustering From Scratch",
          "After i steps"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1],\n            s=markersize, color=[colors[l] for l in labels_list[-1]])\n# plt.axis(\"off\")\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_agglomerative_from_scratch",
        "ref_id": "Final-results",
        "headings": [
          "Agglomerative Clustering From Scratch",
          "Final results"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/cluster/Reference_Ch3_part_1_compare_kmeans_kcenter_on_simulated_data": [
    {
      "source": "import random\nimport numpy as np\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ncmap = plt.get_cmap('tab10')\ncolors = [cmap(i) for i in range(cmap.N)]\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\n\nmarkersize = 50",
      "names": [
        {
          "import_components": [
            "random"
          ],
          "code_str": "random",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "random"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "get_cmap"
          ],
          "code_str": "plt.get_cmap",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.get_cmap"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "random",
            "seed"
          ],
          "code_str": "random.seed",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "random.seed"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "seed"
          ],
          "code_str": "np.random.seed",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.random.seed"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_compare_kmeans_kcenter_on_simulated_data",
        "ref_id": "Compare-K-Means-and-K-Center-on-Simulated-Data",
        "headings": [
          "Compare K-Means and K-Center on Simulated Data"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "centers = np.array([[0, 0], [np.sin(np.pi/3), np.cos(np.pi/3)], [np.sin(np.pi/3*2), np.cos(np.pi/3*2)], \\\n    [np.sin(np.pi/3*3), np.cos(np.pi/3*3)], [np.sin(np.pi/3*4), np.cos(np.pi/3*4)],\n    [np.sin(np.pi/3*5), np.cos(np.pi/3*5)]])*3\nn_samples = [300, 4, 4, 4, 4, 4]\nsamples = None\nfor center, n in zip(centers, n_samples):\n    cov = [[0.1, 0], [0, 0.1]]\n    s = np.random.multivariate_normal(center, cov, n)\n    if samples is None:\n        samples = s\n    else:\n        samples = np.vstack([samples, s])",
      "names": [
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "sin"
          ],
          "code_str": "np.sin",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.sin"
        },
        {
          "import_components": [
            "numpy",
            "pi"
          ],
          "code_str": "np.pi",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.pi"
        },
        {
          "import_components": [
            "numpy",
            "cos"
          ],
          "code_str": "np.cos",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.cos"
        },
        {
          "import_components": [
            "numpy",
            "pi"
          ],
          "code_str": "np.pi",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.pi"
        },
        {
          "import_components": [
            "numpy",
            "sin"
          ],
          "code_str": "np.sin",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.sin"
        },
        {
          "import_components": [
            "numpy",
            "pi"
          ],
          "code_str": "np.pi",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.pi"
        },
        {
          "import_components": [
            "numpy",
            "cos"
          ],
          "code_str": "np.cos",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.cos"
        },
        {
          "import_components": [
            "numpy",
            "pi"
          ],
          "code_str": "np.pi",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.pi"
        },
        {
          "import_components": [
            "numpy",
            "sin"
          ],
          "code_str": "np.sin",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.sin"
        },
        {
          "import_components": [
            "numpy",
            "pi"
          ],
          "code_str": "np.pi",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.pi"
        },
        {
          "import_components": [
            "numpy",
            "cos"
          ],
          "code_str": "np.cos",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.cos"
        },
        {
          "import_components": [
            "numpy",
            "pi"
          ],
          "code_str": "np.pi",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.pi"
        },
        {
          "import_components": [
            "numpy",
            "sin"
          ],
          "code_str": "np.sin",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.sin"
        },
        {
          "import_components": [
            "numpy",
            "pi"
          ],
          "code_str": "np.pi",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.pi"
        },
        {
          "import_components": [
            "numpy",
            "cos"
          ],
          "code_str": "np.cos",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.cos"
        },
        {
          "import_components": [
            "numpy",
            "pi"
          ],
          "code_str": "np.pi",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.pi"
        },
        {
          "import_components": [
            "numpy",
            "sin"
          ],
          "code_str": "np.sin",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.sin"
        },
        {
          "import_components": [
            "numpy",
            "pi"
          ],
          "code_str": "np.pi",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.pi"
        },
        {
          "import_components": [
            "numpy",
            "cos"
          ],
          "code_str": "np.cos",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.cos"
        },
        {
          "import_components": [
            "numpy",
            "pi"
          ],
          "code_str": "np.pi",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.pi"
        },
        {
          "import_components": [
            "zip"
          ],
          "code_str": "zip",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "zip"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "multivariate_normal"
          ],
          "code_str": "np.random.multivariate_normal",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.random.multivariate_normal"
        },
        {
          "import_components": [
            "numpy",
            "vstack"
          ],
          "code_str": "np.vstack",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.vstack"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_compare_kmeans_kcenter_on_simulated_data",
        "ref_id": "Simulate-Outliers",
        "headings": [
          "Compare K-Means and K-Center on Simulated Data",
          "Simulate Outliers"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1], s=markersize, color=\"k\", alpha=0.5)\nplt.xlim([-2, 2])\nplt.ylim([-2, 2])\n# plt.axis(\"off\")\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_compare_kmeans_kcenter_on_simulated_data",
        "ref_id": "Simulate-Outliers",
        "headings": [
          "Compare K-Means and K-Center on Simulated Data",
          "Simulate Outliers"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.cluster import k_means\nk = 6\ncentroid, labels, inertia = k_means(samples, n_clusters=k,\n                                    init=samples[:k, :])\n\nplt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1], s=markersize,\n            color=[colors[l] for l in labels], alpha=0.5)\n\nplt.title(\"KMeans\")\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "title"
          ],
          "code_str": "plt.title",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.title"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_compare_kmeans_kcenter_on_simulated_data",
        "ref_id": "K-Means-Results",
        "headings": [
          "Compare K-Means and K-Center on Simulated Data",
          "K-Means Results"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def k_center(points, k):\n    losses = []\n    n_points = points.shape[0]\n    centers = []\n    distances = np.full(n_points, np.inf)\n\n    for j in range(0, k):\n        if j == 0:\n            centers = [0]\n\n        for i in range(n_points):\n            new_dist = np.linalg.norm(points[i]-points[centers[-1]])\n            distances[i] = min(distances[i], new_dist)\n\n        if j>=1:\n            next_center = np.argmax(distances)\n            centers.append(next_center)\n\n        losses.append(np.max(distances))\n\n    return centers, losses",
      "names": [
        {
          "import_components": [
            "numpy",
            "full"
          ],
          "code_str": "np.full",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.full"
        },
        {
          "import_components": [
            "numpy",
            "inf"
          ],
          "code_str": "np.inf",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.inf"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "linalg",
            "norm"
          ],
          "code_str": "np.linalg.norm",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.linalg.norm"
        },
        {
          "import_components": [
            "min"
          ],
          "code_str": "min",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "min"
        },
        {
          "import_components": [
            "numpy",
            "argmax"
          ],
          "code_str": "np.argmax",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.argmax"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "numpy.max"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_compare_kmeans_kcenter_on_simulated_data",
        "ref_id": "K-Center-Results",
        "headings": [
          "Compare K-Means and K-Center on Simulated Data",
          "K-Center Results"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "k = 6\nnew_centers, losses = k_center(samples, k)\nnew_centers = samples[new_centers]",
      "names": [],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_compare_kmeans_kcenter_on_simulated_data",
        "ref_id": "K-Center-Results",
        "headings": [
          "Compare K-Means and K-Center on Simulated Data",
          "K-Center Results"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "labels = [np.argmin(np.sum((samples[i, :]-new_centers)**2, axis=1)) for i in range(samples.shape[0])]\nplt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1],\n            s=markersize, color=[colors[l] for l in labels], alpha=0.5)\n\nplt.title(\"KCenter\")\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "argmin"
          ],
          "code_str": "np.argmin",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.argmin"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "title"
          ],
          "code_str": "plt.title",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.title"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_compare_kmeans_kcenter_on_simulated_data",
        "ref_id": "K-Center-Results",
        "headings": [
          "Compare K-Means and K-Center on Simulated Data",
          "K-Center Results"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/cluster/Reference_Ch3_part_1_dbscan_from_scratch": [
    {
      "source": "import random\nimport numpy as np\nfrom scipy.spatial.distance import pdist, squareform\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ncmap = plt.get_cmap('tab10')\ncolors = [cmap(i) for i in range(cmap.N)]\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2\n\nimport networkx as nx\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\nn_samples = 10\nmarkersize = 100",
      "names": [
        {
          "import_components": [
            "random"
          ],
          "code_str": "random",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "random"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "get_cmap"
          ],
          "code_str": "plt.get_cmap",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.get_cmap"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "random",
            "seed"
          ],
          "code_str": "random.seed",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "random.seed"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "seed"
          ],
          "code_str": "np.random.seed",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "numpy.random.seed"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_dbscan_from_scratch",
        "ref_id": "DBSCAN-From-Scratch",
        "headings": [
          "DBSCAN From Scratch"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "m1 = [1, 1]\ncov1 = [[1, 0], [0, 1]]\ns1 = np.random.multivariate_normal(m1, cov1, 5)\n\nm2 = [-1, -1]\ncov2 = [[1, -0.5], [-0.5, 1]]\ns2 = np.random.multivariate_normal(m2, cov2, 5)\n\nsamples = np.concat([s1, s2])\nnp.random.shuffle(samples)",
      "names": [
        {
          "import_components": [
            "numpy",
            "random",
            "multivariate_normal"
          ],
          "code_str": "np.random.multivariate_normal",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.random.multivariate_normal"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "multivariate_normal"
          ],
          "code_str": "np.random.multivariate_normal",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "numpy.random.multivariate_normal"
        },
        {
          "import_components": [
            "numpy",
            "concat"
          ],
          "code_str": "np.concat",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.concat"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "shuffle"
          ],
          "code_str": "np.random.shuffle",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.random.shuffle"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_dbscan_from_scratch",
        "ref_id": "Sample-data-points",
        "headings": [
          "DBSCAN From Scratch",
          "Sample data points"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1], s=markersize, color=\"k\")\nplt.xlim([-2, 2])\nplt.ylim([-2, 2])\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_dbscan_from_scratch",
        "ref_id": "Sample-data-points",
        "headings": [
          "DBSCAN From Scratch",
          "Sample data points"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "eps = 2.0\n# when min_samples=1,\n# it is equivalent to find connected components\nmin_samples = 3\n\nn_points = samples.shape[0]\ndistances = squareform(pdist(samples))\n\n# create a networkx graph\nG = nx.Graph()\n\n# add nodes with positions\nfor i in range(n_points):\n    G.add_node(i, pos=(samples[i, 0], samples[i, 1]))\n\n# add edges according to distance cutoff\nfor i in range(n_points):\n    for j in range(i + 1, n_points):\n        if distances[i, j] < eps:\n            G.add_edge(i, j)",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_dbscan_from_scratch",
        "ref_id": "Build-\\epsilon-neighbourhood",
        "headings": [
          "DBSCAN From Scratch",
          "Build \\epsilon-neighbourhood"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# find core points\ncore_points = []\nfor i in range(n_points):\n    neighbors = list(G.neighbors(i))\n    if len(neighbors) >= min_samples:\n        core_points.append(i)\n\ndef core_border_noise(node):\n    if node in core_points:\n        return \"core\"\n    else:\n        neighbors = list(G.neighbors(node))\n        connect_to_core = set(neighbors).intersection(core_points)\n        if len(connect_to_core) >= 1:\n            return \"border\"\n        else:\n            return \"noise\"\n\ncolor_dct = {\n    \"core\": \"b\",\n    \"border\": \"r\",\n    \"noise\": \"k\"\n}\n\nfig, ax = plt.subplots(figsize=(5, 5))\npos = nx.get_node_attributes(G, \"pos\")\nnx.draw_networkx_nodes(G, pos,\n        node_size=markersize, \\\n        node_color=[color_dct[core_border_noise(node)] for node in G], ax=ax)\nnx.draw_networkx_edges(G, pos, edgelist=G.edges,\n                       edge_color=\"gray\", width=2)\n\nax.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\nplt.xlim([-2, 2])\nplt.ylim([-2, 2])\nplt.axis(\"equal\")\nplt.show()",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "set"
          ],
          "code_str": "set",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "set"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 34,
          "end_lineno": 34,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 35,
          "end_lineno": 35,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 36,
          "end_lineno": 36,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 37,
          "end_lineno": 37,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_dbscan_from_scratch",
        "ref_id": "Identify-core,-border,-and-noise-points",
        "headings": [
          "DBSCAN From Scratch",
          "Identify core, border, and noise points"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "labels = np.full(n_points, -1)\ncluster_id = 0\n\nfor core_point in core_points:\n    if labels[core_point] == -1:\n        stack = [core_point]\n        # dfs-like search\n        while stack:\n            point = stack.pop()\n            if labels[point] == -1:\n                labels[point] = cluster_id\n                neighbors = list(G.neighbors(point))\n                for neighbor in neighbors:\n                    if neighbor in core_points and labels[neighbor] == -1:\n                        stack.append(neighbor)\n                    else:\n                        # truncate search for non-core point\n                        labels[neighbor] = cluster_id\n        cluster_id += 1",
      "names": [
        {
          "import_components": [
            "numpy",
            "full"
          ],
          "code_str": "np.full",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.full"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "list"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_dbscan_from_scratch",
        "ref_id": "Assign-clusters-using-Depth-First-Search-(DFS)",
        "headings": [
          "DBSCAN From Scratch",
          "Assign clusters using Depth-First Search (DFS)"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig, ax = plt.subplots(figsize=(5, 5))\npos = nx.get_node_attributes(G, \"pos\")\nnx.draw_networkx_nodes(G, pos,\n        node_size=markersize, node_color=[colors[l] if l>=0 else \"k\" for l in labels], ax=ax)\nnx.draw_networkx_edges(G, pos, edgelist=G.edges,\n                       edge_color=\"gray\", width=2)\n\nax.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\nplt.xlim([-2, 2])\nplt.ylim([-2, 2])\nplt.axis(\"equal\")\nplt.show()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_dbscan_from_scratch",
        "ref_id": "Assign-clusters-using-Depth-First-Search-(DFS)",
        "headings": [
          "DBSCAN From Scratch",
          "Assign clusters using Depth-First Search (DFS)"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/cluster/Reference_Ch3_part_1_kcenter_from_scratch": [
    {
      "source": "import random\nimport numpy as np\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ncmap = plt.get_cmap('tab10')\ncolors = [cmap(i) for i in range(cmap.N)]\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\nn_samples = 10\nmarkersize = 100",
      "names": [
        {
          "import_components": [
            "random"
          ],
          "code_str": "random",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "random"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "get_cmap"
          ],
          "code_str": "plt.get_cmap",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.get_cmap"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "random",
            "seed"
          ],
          "code_str": "random.seed",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "random.seed"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "seed"
          ],
          "code_str": "np.random.seed",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.random.seed"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kcenter_from_scratch",
        "ref_id": "K-Center-From-Scratch",
        "headings": [
          "K-Center From Scratch"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "m1 = [1, 1]\ncov1 = [[1, 0], [0, 1]]\ns1 = np.random.multivariate_normal(m1, cov1, 5)\n\nm2 = [-1, -1]\ncov2 = [[1, -0.5], [-0.5, 1]]\ns2 = np.random.multivariate_normal(m2, cov2, 5)\n\nsamples = np.concat([s1, s2])\nnp.random.shuffle(samples)",
      "names": [
        {
          "import_components": [
            "numpy",
            "random",
            "multivariate_normal"
          ],
          "code_str": "np.random.multivariate_normal",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.random.multivariate_normal"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "multivariate_normal"
          ],
          "code_str": "np.random.multivariate_normal",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "numpy.random.multivariate_normal"
        },
        {
          "import_components": [
            "numpy",
            "concat"
          ],
          "code_str": "np.concat",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.concat"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "shuffle"
          ],
          "code_str": "np.random.shuffle",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.random.shuffle"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kcenter_from_scratch",
        "ref_id": "Sample-data-points",
        "headings": [
          "K-Center From Scratch",
          "Sample data points"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1], s=markersize, color=\"k\")\n# plt.axis(\"off\")\nplt.xlim([-2, 2])\nplt.ylim([-2, 2])\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kcenter_from_scratch",
        "ref_id": "Sample-data-points",
        "headings": [
          "K-Center From Scratch",
          "Sample data points"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# initialize 1st center\ncenters = [0, ]\n\n# initialize distance matrix\nlosses = []\nn_points = samples.shape[0]\ndistances = np.full(n_points, np.inf)",
      "names": [
        {
          "import_components": [
            "numpy",
            "full"
          ],
          "code_str": "np.full",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "numpy.full"
        },
        {
          "import_components": [
            "numpy",
            "inf"
          ],
          "code_str": "np.inf",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "numpy.inf"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kcenter_from_scratch",
        "ref_id": "Select-one-initial-cluster-center",
        "headings": [
          "K-Center From Scratch",
          "Select one initial cluster center"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1], s=markersize, color=\"k\")\nplt.scatter(samples[centers][:,0], samples[centers][:, 1],\n            s=markersize*3, c=colors[:len(centers)], marker=(5, 1))\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kcenter_from_scratch",
        "ref_id": "Select-one-initial-cluster-center",
        "headings": [
          "K-Center From Scratch",
          "Select one initial cluster center"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "last_center = centers[-1]\nfor i in range(n_points):\n    new_dist = np.linalg.norm(samples[i]-samples[last_center])\n    distances[i] = min(distances[i], new_dist)",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "linalg",
            "norm"
          ],
          "code_str": "np.linalg.norm",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.linalg.norm"
        },
        {
          "import_components": [
            "min"
          ],
          "code_str": "min",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "min"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kcenter_from_scratch",
        "ref_id": "Update-distance-of-each-point-to-its-closest-center",
        "headings": [
          "K-Center From Scratch",
          "Update distance of each point to its closest center"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1],\n            s=markersize, color=\"k\")\n\n# old centers\nplt.scatter(samples[centers][:,0], samples[centers][:, 1], \\\n            s=markersize*3, c=colors[:len(centers)], marker=(5, 1))\n\n# assign predicted labels\nlabels = [np.argmin(np.sum((samples[i, :]-samples[centers])**2, axis=1)) \\\n    for i in range(samples.shape[0])]\n\n# add assignment vectors\nfor i in range(samples.shape[0]):\n    to_point = samples[centers[labels[i]]]\n    from_point = samples[i]\n    plt.quiver(from_point[0], from_point[1],\n               to_point[0]-from_point[0], to_point[1]-from_point[1],\n               angles=\"xy\", scale_units=\"xy\", scale=1, color=\"gray\",\n               linewidth=1.5, linestyle=\"--\")\n\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "argmin"
          ],
          "code_str": "np.argmin",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.argmin"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kcenter_from_scratch",
        "ref_id": "Update-distance-of-each-point-to-its-closest-center",
        "headings": [
          "K-Center From Scratch",
          "Update distance of each point to its closest center"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "## pick the point with the maximum distance as next center\nnext_center = np.argmax(distances)\ncenters.append(next_center)",
      "names": [
        {
          "import_components": [
            "numpy",
            "argmax"
          ],
          "code_str": "np.argmax",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.argmax"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kcenter_from_scratch",
        "ref_id": "Add-a-new-cluster-center",
        "headings": [
          "K-Center From Scratch",
          "Add a new cluster center"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1],\n            s=markersize, color=\"k\")\n\n# new centers\nplt.scatter(samples[centers][:,0], samples[centers][:, 1], \\\n            s=markersize*3, c=colors[:len(centers)], marker=(5, 1))\n\n# assign predicted labels\nlabels = [np.argmin(np.sum((samples[i, :]-samples[centers])**2, axis=1)) \\\n    for i in range(samples.shape[0])]\n\n# add assignment vectors\nfor i in range(samples.shape[0]):\n    to_point = samples[centers[labels[i]]]\n    from_point = samples[i]\n    plt.quiver(from_point[0], from_point[1],\n               to_point[0]-from_point[0], to_point[1]-from_point[1],\n               angles=\"xy\", scale_units=\"xy\", scale=1, color=\"gray\",\n               linewidth=1.5, linestyle=\"--\")\n\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "argmin"
          ],
          "code_str": "np.argmin",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.argmin"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kcenter_from_scratch",
        "ref_id": "Add-a-new-cluster-center",
        "headings": [
          "K-Center From Scratch",
          "Add a new cluster center"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def k_center(points, k):\n    losses = []\n    n_points = points.shape[0]\n    centers = []\n    distances = np.full(n_points, np.inf)\n\n    for j in range(0, k):\n        if j == 0:\n            centers = [0]\n\n        for i in range(n_points):\n            new_dist = np.linalg.norm(points[i]-points[centers[-1]])\n            distances[i] = min(distances[i], new_dist)\n\n        if j>=1:\n            next_center = np.argmax(distances)\n            centers.append(next_center)\n\n        losses.append(np.max(distances))\n\n    return centers, losses",
      "names": [
        {
          "import_components": [
            "numpy",
            "full"
          ],
          "code_str": "np.full",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.full"
        },
        {
          "import_components": [
            "numpy",
            "inf"
          ],
          "code_str": "np.inf",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.inf"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "linalg",
            "norm"
          ],
          "code_str": "np.linalg.norm",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.linalg.norm"
        },
        {
          "import_components": [
            "min"
          ],
          "code_str": "min",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "min"
        },
        {
          "import_components": [
            "numpy",
            "argmax"
          ],
          "code_str": "np.argmax",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.argmax"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "numpy.max"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kcenter_from_scratch",
        "ref_id": "Show-clutering-results",
        "headings": [
          "K-Center From Scratch",
          "Show clutering results"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "k = 3\nnew_centers, losses = k_center(samples, k)\nnew_centers = samples[new_centers]",
      "names": [],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kcenter_from_scratch",
        "ref_id": "Show-clutering-results",
        "headings": [
          "K-Center From Scratch",
          "Show clutering results"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "labels = [np.argmin(np.sum((samples[i, :]-new_centers)**2, axis=1)) for i in range(samples.shape[0])]\n\nplt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1],\n            s=markersize, color=[colors[l] for l in labels])\n\n# new centers\nplt.scatter(new_centers[:,0], new_centers[:, 1],\n            s=markersize*3, c=colors[:k], marker=(5, 1))\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "argmin"
          ],
          "code_str": "np.argmin",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.argmin"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kcenter_from_scratch",
        "ref_id": "Show-clutering-results",
        "headings": [
          "K-Center From Scratch",
          "Show clutering results"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/cluster/Reference_Ch3_part_1_kmeans_from_scratch": [
    {
      "source": "import random\nimport numpy as np\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ncmap = plt.get_cmap('tab10')\ncolors = [cmap(i) for i in range(cmap.N)]\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\nn_samples = 10\nmarkersize = 100",
      "names": [
        {
          "import_components": [
            "random"
          ],
          "code_str": "random",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "random"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "get_cmap"
          ],
          "code_str": "plt.get_cmap",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.get_cmap"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "random",
            "seed"
          ],
          "code_str": "random.seed",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "random.seed"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "seed"
          ],
          "code_str": "np.random.seed",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.random.seed"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kmeans_from_scratch",
        "ref_id": "KMeans-From-Scratch",
        "headings": [
          "KMeans From Scratch"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# Sample 10 points\nm1 = [1, 1]\ncov1 = [[1, 0], [0, 1]]\ns1 = np.random.multivariate_normal(m1, cov1, 5)\n\nm2 = [-1, -1]\ncov2 = [[1, -0.5], [-0.5, 1]]\ns2 = np.random.multivariate_normal(m2, cov2, 5)\n\nsamples = np.concat([s1, s2])\nnp.random.shuffle(samples)",
      "names": [
        {
          "import_components": [
            "numpy",
            "random",
            "multivariate_normal"
          ],
          "code_str": "np.random.multivariate_normal",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.random.multivariate_normal"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "multivariate_normal"
          ],
          "code_str": "np.random.multivariate_normal",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.random.multivariate_normal"
        },
        {
          "import_components": [
            "numpy",
            "concat"
          ],
          "code_str": "np.concat",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.concat"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "shuffle"
          ],
          "code_str": "np.random.shuffle",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.random.shuffle"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kmeans_from_scratch",
        "ref_id": "Sample-data-points",
        "headings": [
          "KMeans From Scratch",
          "Sample data points"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1], s=markersize, color=\"k\")\nplt.xlim([-2, 2])\nplt.ylim([-2, 2])\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kmeans_from_scratch",
        "ref_id": "Sample-data-points",
        "headings": [
          "KMeans From Scratch",
          "Sample data points"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "## any two clusters\ncluster_ids = [0, 2]\ncenters = samples[cluster_ids]\nk = len(cluster_ids)\n\n\nplt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1], s=markersize, color=\"k\")\nplt.scatter(centers[:,0], centers[:, 1],\n            s=markersize*3, c=colors[:k], marker=(5, 1))\n\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kmeans_from_scratch",
        "ref_id": "Select-initial-cluster-centers",
        "headings": [
          "KMeans From Scratch",
          "Select initial cluster centers"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def kmeans(centers, data, steps):\n    k = len(centers)\n    losses = []\n    labels = []\n    for _ in range(steps):\n        distances = np.linalg.norm(data[:, np.newaxis] - centers, axis=2)\n        labels = np.argmin(distances, axis=1)\n        diff = data - centers[labels]\n        loss = np.sum(diff**2)\n        losses.append(loss)\n        new_centers = np.array([data[labels == i].mean(axis=0) for i in range(k)])\n        if np.all(centers == new_centers):\n            print(\"Converged\")\n            break\n        centers = new_centers\n    return centers, labels, losses",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "linalg",
            "norm"
          ],
          "code_str": "np.linalg.norm",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.linalg.norm"
        },
        {
          "import_components": [
            "numpy",
            "newaxis"
          ],
          "code_str": "np.newaxis",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.newaxis"
        },
        {
          "import_components": [
            "numpy",
            "argmin"
          ],
          "code_str": "np.argmin",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "numpy.argmin"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "all"
          ],
          "code_str": "np.all",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.all"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kmeans_from_scratch",
        "ref_id": "Iteratively-update-cluster-centers",
        "headings": [
          "KMeans From Scratch",
          "Iteratively update cluster centers"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "new_centers, labels, losses = kmeans(centers, samples, 1)",
      "names": [],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kmeans_from_scratch",
        "ref_id": "Run-one-step-iteration",
        "headings": [
          "KMeans From Scratch",
          "Iteratively update cluster centers",
          "Run one step iteration"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1],\n            s=markersize, color=[colors[l] for l in labels])\n\n# old centers\nplt.scatter(centers[:,0], centers[:, 1],\n            s=markersize*3, edgecolor=colors, marker=(5, 1),\n            facecolor=\"none\", linestyle=\"dashed\")\n\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kmeans_from_scratch",
        "ref_id": "Run-one-step-iteration",
        "headings": [
          "KMeans From Scratch",
          "Iteratively update cluster centers",
          "Run one step iteration"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1],\n            s=markersize, color=[colors[l] for l in labels])\n\n# old centers\nplt.scatter(centers[:,0], centers[:, 1],\n            s=markersize*3, edgecolor=colors[:k], marker=(5, 1),\n            facecolor=\"none\", linestyle=\"dashed\")\n\n# new centers\nplt.scatter(new_centers[:,0], new_centers[:, 1],\n            s=markersize*3, c=colors[:k], marker=(5, 1))\n\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kmeans_from_scratch",
        "ref_id": "Run-one-step-iteration",
        "headings": [
          "KMeans From Scratch",
          "Iteratively update cluster centers",
          "Run one step iteration"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "new_centers, labels, losses = kmeans(centers, samples, 10)",
      "names": [],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kmeans_from_scratch",
        "ref_id": "Run-until-converge",
        "headings": [
          "KMeans From Scratch",
          "Iteratively update cluster centers",
          "Run until converge"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1],\n            s=markersize, color=[colors[l] for l in labels])\n\n# new centers\nplt.scatter(new_centers[:,0], new_centers[:, 1],\n            s=markersize*3, c=colors[:k], marker=(5, 1))\n\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kmeans_from_scratch",
        "ref_id": "Run-until-converge",
        "headings": [
          "KMeans From Scratch",
          "Iteratively update cluster centers",
          "Run until converge"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.plot(range(1, len(losses)+1), losses, \"o-\", markersize=10, c=\"blue\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kmeans_from_scratch",
        "ref_id": "Run-until-converge",
        "headings": [
          "KMeans From Scratch",
          "Iteratively update cluster centers",
          "Run until converge"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(labels)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_kmeans_from_scratch",
        "ref_id": "Run-until-converge",
        "headings": [
          "KMeans From Scratch",
          "Iteratively update cluster centers",
          "Run until converge"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/cluster/Reference_Ch3_part_1_sklearn_clustering_example": [
    {
      "source": "import random\nimport numpy as np\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ncmap = plt.get_cmap('tab10')\ncolors = [cmap(i) for i in range(cmap.N)]\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\nn_samples = 10\nmarkersize = 100",
      "names": [
        {
          "import_components": [
            "random"
          ],
          "code_str": "random",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "random"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "get_cmap"
          ],
          "code_str": "plt.get_cmap",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.get_cmap"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "random",
            "seed"
          ],
          "code_str": "random.seed",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "random.seed"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "seed"
          ],
          "code_str": "np.random.seed",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.random.seed"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_sklearn_clustering_example",
        "ref_id": "SKLearn-Clustering-Examples",
        "headings": [
          "SKLearn Clustering Examples"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# Sample 10 points\nm1 = [1, 1]\ncov1 = [[1, 0], [0, 1]]\ns1 = np.random.multivariate_normal(m1, cov1, 5)\n\nm2 = [-1, -1]\ncov2 = [[1, -0.5], [-0.5, 1]]\ns2 = np.random.multivariate_normal(m2, cov2, 5)\n\nsamples = np.concat([s1, s2])\nnp.random.shuffle(samples)",
      "names": [
        {
          "import_components": [
            "numpy",
            "random",
            "multivariate_normal"
          ],
          "code_str": "np.random.multivariate_normal",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.random.multivariate_normal"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "multivariate_normal"
          ],
          "code_str": "np.random.multivariate_normal",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.random.multivariate_normal"
        },
        {
          "import_components": [
            "numpy",
            "concat"
          ],
          "code_str": "np.concat",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.concat"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "shuffle"
          ],
          "code_str": "np.random.shuffle",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.random.shuffle"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_sklearn_clustering_example",
        "ref_id": "Sample-data-points",
        "headings": [
          "SKLearn Clustering Examples",
          "Sample data points"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1], s=markersize, color=\"k\")\nplt.xlim([-2, 2])\nplt.ylim([-2, 2])\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_sklearn_clustering_example",
        "ref_id": "Sample-data-points",
        "headings": [
          "SKLearn Clustering Examples",
          "Sample data points"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.cluster import k_means\ncentroid, labels, inertia = k_means(samples, n_clusters=2,\n       init=samples[[0, 2], :])\nprint(labels)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_sklearn_clustering_example",
        "ref_id": "KMeans-from-sklearn",
        "headings": [
          "SKLearn Clustering Examples",
          "KMeans from sklearn"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1],\n            s=markersize, color=[colors[l] for l in labels])\n\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_sklearn_clustering_example",
        "ref_id": "KMeans-from-sklearn",
        "headings": [
          "SKLearn Clustering Examples",
          "KMeans from sklearn"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.cluster import DBSCAN\n\neps = 2.0\nmin_samples = 3\ndbscan = DBSCAN(eps=eps, min_samples=min_samples, \\\n    metric=\"euclidean\", algorithm=\"auto\")\ndbscan.fit(samples)\nprint(dbscan.labels_)\n\nplt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1],\n            s=markersize, color=[colors[l] if l>=0 else \"k\" for l in dbscan.labels_])\n# plt.axis(\"off\")\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/cluster/Reference_Ch3_part_1_sklearn_clustering_example",
        "ref_id": "DBSCAN-from-sklearn",
        "headings": [
          "SKLearn Clustering Examples",
          "DBSCAN from sklearn"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab": [
    {
      "source": "!pip install wget seaborn tqdm",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Predict-log-EC50s-of-Dual-Agonist-Peptides-using-Convolutional-Neural-Network",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\n\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2",
      "names": [
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Import-Packages",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Import Packages"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", device)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Import-Packages",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Import Packages"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget https://raw.githubusercontent.com/xuhuihuang/uwmadisonchem361/refs/heads/main/CNN_training_data.csv \\\n--output CNN_training_data.csv",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Download-&-Load-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Download & Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "filename = \"CNN_training_data.csv\"\ndf = pd.read_csv(filename)\ndf",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Download-&-Load-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Download & Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def seq2onehot(sequence):\n    AMINOACIDS = 'ACDEFGHIKLMNPQRSTVWY'\n    onehot = np.zeros((len(sequence), len(AMINOACIDS)+1))\n    aa_to_idx = {aa: idx for idx, aa in enumerate(AMINOACIDS)}\n    for i, aa in enumerate(sequence):\n        if aa in aa_to_idx:\n            onehot[i, aa_to_idx[aa]] = 1\n        else:\n            onehot[i, -1] = 1\n    return onehot",
      "names": [
        {
          "import_components": [
            "numpy",
            "zeros"
          ],
          "code_str": "np.zeros",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.zeros"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "enumerate"
        },
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "enumerate"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Convert-sequence-to-onehot-embedding",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Create PyTorch Dataset",
          "Convert sequence to onehot embedding"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "seq = df.iloc[0][\"Aligned_Sequence\"]\nprint(\"Peptide sequence:\", seq)\nonehot = seq2onehot(seq)\nprint(\"Onehot Embedding:\")\nprint(onehot)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Convert-sequence-to-onehot-embedding",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Create PyTorch Dataset",
          "Convert sequence to onehot embedding"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class PeptideDataset(Dataset):\n    def __init__(self, df, encoder,\n                 seq_col=\"Aligned_Sequence\", target_cols=(\"EC50_LOG_T1\", \"EC50_LOG_T2\")):\n        self.df = df\n        self.encoder = encoder\n        self.seq_col = seq_col\n        self.target_cols = target_cols\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        sequence = row[self.seq_col]\n        onehot_sequence = self.encoder(sequence)\n        onehot_sequence = np.transpose(onehot_sequence)\n        label = [row[col] for col in self.target_cols]\n        return torch.tensor(onehot_sequence, dtype=float), torch.tensor(label, dtype=float).reshape(1, -1)",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "transpose"
          ],
          "code_str": "np.transpose",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.transpose"
        },
        {
          "import_components": [
            "float"
          ],
          "code_str": "float",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "float"
        },
        {
          "import_components": [
            "float"
          ],
          "code_str": "float",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "float"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Convert-sequence-to-onehot-embedding",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Create PyTorch Dataset",
          "Convert sequence to onehot embedding"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.model_selection import train_test_split\n\n# training/validation dataset\ndata_size = df.shape[0]\ntest_ratio = 0.10\ntest_size = int(data_size*test_ratio)\ntrain_indices, test_indices = train_test_split(range(data_size), test_size=test_size, shuffle=True)\nprint(f\"Training size: {len(train_indices)}, test size: {len(test_indices)}\")\ntrain_df, test_df = df.iloc[train_indices], df.iloc[test_indices]",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Split-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Split Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# create dataloaders\nbatch_size = 10\nencoder = seq2onehot\ntrain_data = PeptideDataset(train_df, encoder=encoder)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n                                           shuffle=True, drop_last=False)\ntest_data = PeptideDataset(test_df, encoder=encoder)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n                                          shuffle=False, drop_last=False)",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Split-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Split Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "## uncomment the block to see one datapoint\n# train_data[0]\nx, y = train_data[0]\nprint(\"Shape of one datapoint:\", x.shape)\nprint(\"Shape of one label:\", y.shape)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Split-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Split Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class BaseModel(nn.Module):\n\n    def __init__(self, in_shape, dropout=0.3):\n        super().__init__()\n\n        # Defining NN layers in Conv Block #1\n        in_channels = in_shape[0]\n        self.conv1 = nn.Sequential(\n            nn.Conv1d(in_channels, out_channels=256, kernel_size=3, stride=1, padding=0, bias=False),\n            nn.ReLU(),\n        )\n        self.bn1 = nn.BatchNorm1d(num_features=256)\n        self.pool1 = nn.MaxPool1d(kernel_size=2)\n        self.dropout1 = nn.Dropout1d(p=dropout)\n\n         # Defining NN layers in Conv Block #2\n        self.conv2 = nn.Sequential(\n            nn.Conv1d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=0, bias=False),\n            nn.ReLU(),\n        )\n        self.bn2 = nn.BatchNorm1d(num_features=512)\n        self.pool2 = nn.MaxPool1d(kernel_size=2)\n        self.dropout2 = nn.Dropout1d(p=dropout)\n\n        # Defining NN layers in Conv Block #3\n        self.conv3 = nn.Sequential(\n            nn.Conv1d(in_channels=512, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.ReLU(),\n        )\n        self.bn3 = nn.BatchNorm1d(num_features=128)\n        self.pool3 = nn.MaxPool1d(kernel_size=2)\n        self.dropout3 = nn.Dropout1d(p=dropout)\n\n        #Explore the diemnsion in order to concatenate the data later\n        self._dummy_input_shape = (1, in_channels, in_shape[1])\n        self.dummy_input = torch.randn(self._dummy_input_shape)\n        self.flattened_size = self._calculate_flattened_size()\n\n        self.dropout = nn.Dropout1d(p=dropout)\n\n        # Defining fully connected layer (128 hidden neurons)\n        self.dense1 = nn.Sequential(\n            nn.Linear(in_features=self.flattened_size, out_features=128, bias=True),\n            nn.ReLU(),\n        )\n\n        # Defining fully connected layer (64 hidden neurons)\n        self.dense2 = nn.Sequential(\n            nn.Linear(in_features=128, out_features=64, bias=True),\n            nn.ReLU(),\n        )\n\n    def forward(self, input_seqs):\n        # Calling NN layers in Cov Block #1\n        x = self.dropout1(self.pool1(self.bn1(self.conv1(input_seqs))))\n        # Calling NN layers in Cov Block #2\n        x = self.dropout2(self.pool2(self.bn2(self.conv2(x))))\n        # Calling NN layers in Cov Block #3\n        x = self.dropout3(self.pool3(self.bn3(self.conv3(x))))\n\n        # Pooling and concatenate the data\n        length = x.shape[-1]\n        max_pool = nn.MaxPool1d(kernel_size=length)(x).squeeze(-1)\n        avg_pool = nn.AvgPool1d(kernel_size=length)(x).squeeze(-1)\n        x = torch.cat([max_pool, avg_pool], dim=-1)\n\n        # Calling the dense NN layer #1\n        x = self.dropout(self.dense1(x))\n        # Calling the dense NN layer #2\n        x = self.dropout(self.dense2(x))\n\n        return x\n\n    def _calculate_flattened_size(self):\n        \"\"\"Pass dummy data through the network to get the flattened size.\"\"\"\n        with torch.no_grad():\n            x = self.dummy_input\n            x = self.dropout1(self.pool1(self.bn1(self.conv1(x))))\n            x = self.dropout2(self.pool2(self.bn2(self.conv2(x))))\n            x = self.dropout3(self.pool3(self.bn3(self.conv3(x))))\n\n            # max pooling and average pooling layer here turn each 30-residude peptide into a single dimension.\n            # 128*1: \"128\" can be traced back to the original 20+1 type of amino acides\n            # while \"1\" refers to a whole peptide in order to predict properties of whole peptides\n            length = x.shape[-1]\n            max_pool = nn.MaxPool1d(kernel_size=length)(x).squeeze(-1)\n            avg_pool = nn.AvgPool1d(kernel_size=length)(x).squeeze(-1)\n            x = torch.cat([max_pool, avg_pool], dim=-1)\n        return x.shape[1]\n\n\nclass MultiHeadModel(nn.Module):\n\n    def __init__(self, in_shape, dropout=0.3):\n        super().__init__()\n\n        self.base_model = BaseModel(in_shape=in_shape, dropout=dropout)\n        self.head_1 = nn.Linear(in_features=64, out_features=1, bias=True)\n        self.head_2 = nn.Linear(in_features=64, out_features=1, bias=True)\n\n    def forward(self, input_seqs):\n\n        base_out = self.base_model(input_seqs)\n        out_1 = self.head_1(base_out)\n        out_2 = self.head_2(base_out)\n\n        return torch.cat([out_1, out_2], dim=1)",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 95,
          "end_lineno": 95,
          "context": "none",
          "resolved_location": "super"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "CNN-Model",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "CNN Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def train_one_epoch(model, criterion, optimizer, dataloader):\n    losses = []\n    model.train()\n    for x, y_true in dataloader:\n        if device == \"cuda\":\n            x, y_true = x.to(device), y_true.to(device)\n        x, y_true = x.float(), y_true.float()\n        optimizer.zero_grad()\n        y_pred = model(x) # Forward propagation is called here.\n        # MSE loss for linear regression\n        loss = criterion(y_pred, y_true.squeeze(1))\n        loss.backward() # Backprogation\n        optimizer.step()\n        losses.append(loss.cpu().detach().item())\n    return losses\n\n\ndef val_one_epoch(model, criterion, dataloader):\n    losses = []\n    model.eval()\n    with torch.no_grad():\n        for x, y_true in dataloader:\n            if device == \"cuda\":\n                x, y_true = x.to(device), y_true.to(device)\n            x, y_true = x.float(), y_true.float()\n            y_pred = model(x)\n            loss = criterion(y_pred, y_true.squeeze(1))\n            losses.append(loss.cpu().detach().item())\n    return losses",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "CNN-Model",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "CNN Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def multi_task_loss(y_pred, y_true):\n    y1_pred, y1_true = y_pred[:, 0], y_true[:, 0]\n    y2_pred, y2_true = y_pred[:, -1], y_true[:, -1]\n    mse1 = nn.MSELoss()(y1_pred, y1_true)\n    mse2 = nn.MSELoss()(y2_pred, y2_true)\n    return 0.5 * mse1 + 0.5 * mse2",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "loss-function",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "loss function"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "model = MultiHeadModel(in_shape=(21, 30))\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\"Total number of parameters: {total_params}\")\n\n\nmodel = model.to(device)\nmodel = model.float()\ncriterion = multi_task_loss\n# using a gradient descsent based method for optimiztion\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n\nn_epochs = 1500",
      "names": [
        {
          "import_components": [
            "sum"
          ],
          "code_str": "sum",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "sum"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Training",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Training"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "train_loss = []\nval_loss = []\n\nfor epoch in tqdm.tqdm(range(n_epochs)):\n    losses = train_one_epoch(model, criterion, optimizer, train_loader)\n    train_loss.append(np.mean(losses))\n    losses = val_one_epoch(model, criterion, test_loader)\n    val_loss.append(np.mean(losses))",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Training",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Training"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(train_loss, c=\"blue\", label=\"Training\")\nax.plot(val_loss, c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Training",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Training"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "y1_true = []\ny1_pred = []\ny2_true = []\ny2_pred = []\n\nmodel.eval()\nwith torch.no_grad():\n    for x,y in test_loader:\n        if device == \"cuda\":\n            x = x.to(device)\n        x = x.float()\n\n        y_pred = model(x)\n        y1_pred.extend([y_pred[i, 0].item() for i in range(len(y_pred))])\n        y2_pred.extend([y_pred[i, 1].item() for i in range(len(y_pred))])\n\n        y = y.reshape(y_pred.shape)\n        y1_true.extend([y[i, 0].item() for i in range(len(y))])\n        y2_true.extend([y[i, 1].item() for i in range(len(y))])",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Evaluation-metrics",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Evaluation metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "tmp_df = pd.DataFrame({\"y1\": y1_true, r\"$\\hat{y_1}$\": y1_pred,\n                       \"y2\": y2_true, r\"$\\hat{y_2}$\": y2_pred})\n\n# scatter plot\ng = sns.JointGrid(x=\"y1\", y=r\"$\\hat{y_1}$\", data=tmp_df)\ng = g.plot_joint(plt.scatter, c=\"green\", alpha=0.5)\n\n# line: y_pred = y\ny_line = np.linspace(np.min(y1_true), np.max(y1_true), 200)\ng.ax_joint.plot(y_line, y_line, color=\"blue\", linestyle=\"--\");\n\n# histograms\ng = g.plot_marginals(sns.histplot, data=df, color=\"green\", kde=False)\n\ng.ax_joint.set_xlim(np.min(y_line), np.max(y_line))\ng.ax_joint.set_ylim(np.min(y_line), np.max(y_line))\n\nplt.show()",
      "names": [
        {
          "import_components": [
            "pandas",
            "DataFrame"
          ],
          "code_str": "pd.DataFrame",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "pandas.DataFrame"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Evaluation-metrics",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Evaluation metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(f\"MSE: {mean_squared_error(y1_true, y1_pred):.2f}\")\nprint(f\"Coefficient of determination: {r2_score(y1_true, y1_pred):.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Evaluation-metrics",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Evaluation metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# scatter plot\ng = sns.JointGrid(x=\"y2\", y=r\"$\\hat{y_2}$\", data=tmp_df)\ng = g.plot_joint(plt.scatter, c=\"blue\", alpha=0.5, label=\"GLP-1R\")\n\n# line: y_pred = y\ny_line = np.linspace(np.min(y2_true), np.max(y2_true), 200)\ng.ax_joint.plot(y_line, y_line, color=\"blue\", linestyle=\"--\");\n\n# histograms\ng = g.plot_marginals(sns.histplot, data=df, color=\"blue\", kde=False)\n\ng.ax_joint.set_xlim(np.min(y_line), np.max(y_line))\ng.ax_joint.set_ylim(np.min(y_line), np.max(y_line))\n\nplt.show()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Evaluation-metrics",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Evaluation metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(f\"MSE: {mean_squared_error(y2_true, y2_pred):.2f}\")\nprint(f\"Coefficient of determination: {r2_score(y2_true, y2_pred):.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_1_CNNs_colab",
        "ref_id": "Evaluation-metrics",
        "headings": [
          "Predict log EC50s of Dual-Agonist Peptides using Convolutional Neural Network",
          "Evaluation metrics"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/deep_nn/Reference_ch6_Part_2_GNN_colab": [
    {
      "source": "!pip install seaborn torch torch_geometric rdkit wget tqdm",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Install-Dependencies",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Install Dependencies"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m \\\n    wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Download-Dataset",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Download Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport matplotlib.patches as patches\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2\n\nimport tqdm\n\nimport rdkit.Chem as Chem\nimport rdkit.Chem.AllChem as AllChem\n\n\nimport torch\nimport torch.nn as nn\nfrom torch_geometric.data import Data\nfrom torch_geometric.data import Dataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn.conv import GCNConv\nfrom torch_geometric.nn.pool import global_mean_pool",
      "names": [
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "patches"
          ],
          "code_str": "matplotlib.patches",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "matplotlib.patches"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Import-Packages",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Import Packages"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", device)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Import-Packages",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Import Packages"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "DELANEY_FILE = \"delaney-processed.csv\"\nTASK_COL = 'measured log solubility in mols per litre'\ndf = pd.read_csv(DELANEY_FILE)\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Load-Dataset",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "df[\"mol\"] = df[\"smiles\"].apply(lambda x: Chem.MolFromSmiles(x))\n\ndf = df[df[\"mol\"].notna()]",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Load-Dataset",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# we will keep the following columns and discard the rest\ndf = df[[\"Compound ID\", TASK_COL, \"smiles\", \"mol\"]]\ndf",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Load-Dataset",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def mol2graph(mol):\n    # calculate node features\n    ATOMS = ['C', 'O', 'S', 'N', 'P', 'H', 'F', 'Cl', 'Br', 'I', 'UNK']\n    ATOM2DCT = {ele: (np.eye(len(ATOMS))[idx]).tolist() for idx, ele in enumerate(ATOMS)}\n    HYBRIDS = [Chem.rdchem.HybridizationType.SP,\n        Chem.rdchem.HybridizationType.SP2,\n        Chem.rdchem.HybridizationType.SP3,\n        Chem.rdchem.HybridizationType.SP3D,\n        Chem.rdchem.HybridizationType.SP3D2,\n        'UNK']\n    HYBRID2DCT = {ele: (np.eye(len(HYBRIDS))[idx]).tolist() for idx, ele in enumerate(HYBRIDS)}\n\n    x = []\n    ring = mol.GetRingInfo()\n    for idx in range(mol.GetNumAtoms()):\n        emd = []\n        at = mol.GetAtomWithIdx(idx)\n        ele = at.GetSymbol()\n        ele = ele if ele in ATOMS else 'UNK'\n        emd += ATOM2DCT[ele] # add atom type\n        emd += [at.GetDegree()]\n        hyb = at.GetHybridization()\n        hyb = hyb if hyb in HYBRIDS else \"UNK\"\n        emd += HYBRID2DCT[hyb] # add atom hybridization type\n        emd += [at.GetIsAromatic()] # add atom aromacity\n        emd += [ring.IsAtomInRingOfSize(idx, 3),\n              ring.IsAtomInRingOfSize(idx, 4),\n              ring.IsAtomInRingOfSize(idx, 5),\n              ring.IsAtomInRingOfSize(idx, 6),\n              ring.IsAtomInRingOfSize(idx, 7),\n              ring.IsAtomInRingOfSize(idx, 8)] # add ring size\n        x.append(emd)\n    x = torch.Tensor(np.array(x)).float()\n\n    # calculate edges\n    bonds = []\n    for bond in mol.GetBonds():\n        idx1 = bond.GetBeginAtomIdx()\n        idx2 = bond.GetEndAtomIdx()\n        bonds.append([idx1, idx2])\n        bonds.append([idx2, idx1])\n\n    # create graph\n    edge_index = torch.Tensor(np.array(bonds)).long()\n    data = Data(x=x, edge_index=edge_index.t().contiguous())\n    return data",
      "names": [
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "enumerate"
        },
        {
          "import_components": [
            "numpy",
            "eye"
          ],
          "code_str": "np.eye",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.eye"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "enumerate"
        },
        {
          "import_components": [
            "numpy",
            "eye"
          ],
          "code_str": "np.eye",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.eye"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 33,
          "end_lineno": 33,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 44,
          "end_lineno": 44,
          "context": "none",
          "resolved_location": "numpy.array"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Convert-%22mol%22-in-rdkit-to-molecualr-graphs",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Convert \u201cmol\u201d in rdkit to molecualr graphs"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "mol = df.iloc[4][\"mol\"]\n\nfrom IPython.display import SVG\ndef draw_single_mol(mol, size=(300, 300), **highlights):\n    # copy the molecule to avoid modifying the 3D coordinates\n    mol = Chem.Mol(mol)\n    drawer = Chem.Draw.rdMolDraw2D.MolDraw2DSVG(*size)\n    if highlights is not None:\n        Chem.Draw.rdMolDraw2D.PrepareAndDrawMolecule(drawer, mol, **highlights)\n    else:\n        drawer.DrawMolecule(mol)\n    drawer.FinishDrawing()\n    svg = drawer.GetDrawingText()\n    return svg.replace('svg:','')\n\ndef mol_with_atom_index(mol):\n    for atom in mol.GetAtoms():\n        atom.SetProp(\"molAtomMapNumber\", f\"{atom.GetIdx()}\")\n    return mol\n\nSVG(draw_single_mol(mol_with_atom_index(mol)))",
      "names": [
        {
          "import_components": [
            "IPython",
            "display"
          ],
          "code_str": "IPython.display",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_from",
          "resolved_location": "IPython.display"
        },
        {
          "import_components": [
            "IPython",
            "display",
            "SVG"
          ],
          "code_str": "SVG",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "IPython.core.display.SVG"
        },
        {
          "import_components": [
            "IPython",
            "display",
            "SVG"
          ],
          "code_str": "SVG",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "IPython.core.display.SVG"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Visulize-one-of-the-compoudns-in-the-dataset",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Visulize one of the compoudns in the dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "g = mol2graph(mol)\ng",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Visulize-a-moleuclar-graph",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Visulize a moleuclar graph"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "g.x",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Node-embeddings",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Node embeddings"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "g.edge_index.T",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Edge-list",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Edge list"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class MolGraphDataset(Dataset):\n    def __init__(self, df, mol_col=\"mol\", target_col=TASK_COL, transform_fn=None):\n        super().__init__()\n        self.df = df\n        self.mol_col = mol_col\n        self.target_col = target_col\n        self.transform_fn = transform_fn\n\n    def len(self):\n        return len(self.df)\n\n    def get(self, idx):\n        row = self.df.iloc[idx]\n        mol = row[self.mol_col]\n\n        try:\n            G = self.transform_fn(mol)\n            if self.target_col is not None:\n                target = torch.tensor([row[self.target_col]], dtype=torch.float)\n                G.y = target\n        except:\n            return None\n\n        return G",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Batch-compoudns-for-training",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Batch compoudns for training"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.model_selection import train_test_split\n\n# training/validation dataset\ndata_size = df.shape[0]\ntest_ratio = 0.10\ntest_size = int(data_size*test_ratio)\ntrain_indices, test_indices = train_test_split(range(data_size), test_size=test_size, shuffle=True)\nprint(f\"Training size: {len(train_indices)}, test size: {len(test_indices)}\")\ntrain_df, test_df = df.iloc[train_indices], df.iloc[test_indices]",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Split-Dataset",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Split Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# create dataloaders\nbatch_size = 32\ntrain_data = MolGraphDataset(train_df, transform_fn=mol2graph)\ntrain_loader = DataLoader(train_data, batch_size=batch_size,\n                                           shuffle=True, drop_last=False)\ntest_data = MolGraphDataset(test_df, transform_fn=mol2graph)\ntest_loader = DataLoader(test_data, batch_size=batch_size,\n                                          shuffle=False, drop_last=False)",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Please-note-here:-we-are-using-DataLoader-from-torch_geometric.loader,-not-torch.utils.data.DataLoader.-The-dataloader-from-torch_geometric-helps-combine-several-graphs-to-one-batch-(a-large-graph).",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Please note here: we are using DataLoader from torch_geometric.loader, not torch.utils.data.DataLoader. The dataloader from torch_geometric helps combine several graphs to one batch (a large graph)."
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# combine 5 graphs to one batch\nbatch = next(iter(DataLoader(train_data, batch_size=5,\n                        shuffle=True, drop_last=False)))\nprint(batch)\n\n\nimport networkx as nx\n# build a graph from the edge list of the large graph\nn = batch.x.shape[0]\nbatch_ids = np.array(batch.batch.tolist())\n\nedges = np.array(batch.edge_index.T.tolist())\nG = nx.Graph()\nG.add_nodes_from(range(n))\nG.add_edges_from([edges[i] for i in range(edges.shape[0])\n                  if edges[i][0] < edges[i][1]])\n\nnode_colors = [batch_ids[i] for i in G.nodes]\n\nplt.figure(figsize=(5, 5))\npos = nx.spring_layout(G)\nnx.draw(G, pos=pos, with_labels=False, node_color=node_colors, cmap=\"coolwarm\",\n        edge_color=\"gray\", node_size=10)\nplt.show()",
      "names": [
        {
          "import_components": [
            "next"
          ],
          "code_str": "next",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "next"
        },
        {
          "import_components": [
            "iter"
          ],
          "code_str": "iter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "iter"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Vislulization-of-graph-batching-(batch-5-compounds-in-a-single-graph)",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Vislulization of graph batching (batch 5 compounds in a single graph)"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "unique_batch_ids = np.unique(batch_ids)\n\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\n\nax.imshow(np.array(batch.x.tolist()), cmap=\"Blues\", interpolation='none')\n\nfor batch_id in unique_batch_ids:\n    indices = np.where(batch_ids == batch_id)[0]\n    start, end = indices[0], indices[-1]\n    rect = patches.Rectangle((-0.5, start-0.5), batch.x.shape[1]-0.5, end-start+1,\n                                linewidth=1, edgecolor='blue', facecolor='none', linestyle='-')\n    ax.add_patch(rect)\n\nplt.axis(\"off\")",
      "names": [
        {
          "import_components": [
            "numpy",
            "unique"
          ],
          "code_str": "np.unique",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.unique"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "matplotlib",
            "patches",
            "Rectangle"
          ],
          "code_str": "patches.Rectangle",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.patches.Rectangle"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Visualize-node-features-by-batch-ids",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Visualize node features by batch ids"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def edge_list_to_adjacency_matrix(edge_list, num_nodes):\n    adj_matrix = np.zeros((num_nodes, num_nodes), dtype=int)\n    for u, v in edge_list:\n        adj_matrix[u][v] = 1\n    return adj_matrix\n\nadj_matrix = edge_list_to_adjacency_matrix(edges, n)\nprint(adj_matrix)\n\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\nplt.imshow(1-adj_matrix, cmap=\"gray\")\n\n# add diagonal blocks\nunique_batch_ids = np.unique(batch_ids)\nlw = 2\nfor batch_id in unique_batch_ids:\n    indices = np.where(batch_ids == batch_id)[0]\n    start, end = indices[0], indices[-1]\n    rect = patches.Rectangle((start-0.5, start-0.5), end-start+1, end-start+1,\n                                linewidth=lw, edgecolor='blue', facecolor='none', linestyle='-')\n    ax.add_patch(rect)\n\nplt.axis(\"off\")",
      "names": [
        {
          "import_components": [
            "numpy",
            "zeros"
          ],
          "code_str": "np.zeros",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.zeros"
        },
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "imshow"
          ],
          "code_str": "plt.imshow",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.imshow"
        },
        {
          "import_components": [
            "numpy",
            "unique"
          ],
          "code_str": "np.unique",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.unique"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "matplotlib",
            "patches",
            "Rectangle"
          ],
          "code_str": "patches.Rectangle",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "matplotlib.patches.Rectangle"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Visualize-Adjacency-matrix-of-the-batched-graph",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Visualize Adjacency matrix of the batched graph"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class GCNModel(nn.Module):\n    def __init__(self, ndim, hidden_dims):\n        super(GCNModel, self).__init__()\n        total_dims = [ndim] + hidden_dims\n        net = []\n        self.bn = nn.BatchNorm1d(total_dims[0])\n\n        ##set up the graph convolutional layer ndim=25 (25 node features, input channels for GCN)\n        #hidden-dimes: output channel of the convolutional layer\n        # 3 GCN layers, len(total_dims)=4\n        for i in range(len(total_dims)-1):\n            net.extend([\n                GCNConv(total_dims[i], total_dims[i+1], add_self_loops=True),\n                nn.ReLU(),\n            ])\n        self.net = nn.Sequential(*net)\n        self.fc = nn.Linear(total_dims[-1], 1)\n\n\n    def forward(self, data):\n        batch = data.batch\n        out = data.x\n\n        out = self.bn(out)\n        edge_index = data.edge_index.long()\n\n        for idx in range(len(self.net)//2):\n            out = self.net[2*idx](out, edge_index)\n            out = self.net[2*idx+1](out)\n\n         # pool each molecule to one vector\n        out = global_mean_pool(out, batch)\n        # fully connected layer\n        out = self.fc(out)\n        return out",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "GCN-Model",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "GCN Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def train_one_epcoh(model, criterion, optimizer, dataloader):\n    losses = []\n    model.train()\n    for G in dataloader:\n        if device == \"cuda\":\n            G = G.to(device)\n        y_true = G.y\n        optimizer.zero_grad()\n        y_pred = model(G)\n        loss = criterion(y_pred, y_true.reshape(y_pred.shape))\n        loss.backward()\n        optimizer.step()\n        losses.append(loss.cpu().detach().item())\n    return losses\n\n\ndef val_one_epcoh(model, criterion, dataloader):\n    losses = []\n    model.eval()\n    with torch.no_grad():\n        for G in dataloader:\n            if device == \"cuda\":\n                G = G.to(device)\n            y_true = G.y\n            y_pred = model(G)\n            loss = criterion(y_pred, y_true.reshape(y_pred.shape))\n            losses.append(loss.cpu().detach().item())\n    return losses",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "GCN-Model",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "GCN Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "model = GCNModel(ndim=25, hidden_dims=[128, 64, 32]) # we stack 3 GCNs with dimensions: 128, 64 and 32\nmodel.to(device)\nmodel = model.float()\n\nn_epochs = 200\nlr = 5e-3 #learning rate\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nprint(\"Number of trainable parameters:\",\n      sum(p.numel() for p in model.parameters() if p.requires_grad))\n\ncriterion = nn.MSELoss() #Mean square error loss\n\ntrain_loss = []\nval_loss = []\nfor epoch in tqdm.tqdm(range(n_epochs)):\n    losses = train_one_epcoh(model, criterion, optimizer, train_loader)\n    train_loss.append(np.mean(losses))\n    losses = val_one_epcoh(model, criterion, test_loader)\n    val_loss.append(np.mean(losses))",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "sum"
          ],
          "code_str": "sum",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "sum"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Training",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Training"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(train_loss, c=\"blue\", label=\"Training\")\nax.plot(val_loss, c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Training",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Training"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "truths = []\npredictions = []\nmodel.eval()\nwith torch.no_grad():\n    for G in test_loader:\n        if device == \"cuda\":\n            G = G.to(device)\n        y = G.y\n        y_pred = model(G).reshape(-1)\n        # predictions.extend(y_pred.cpu().detach().numpy().tolist())\n        predictions.extend([y_pred[i].item() for i in range(len(y_pred))])\n\n        y = y.reshape(y_pred.shape)\n        # truths.extend(y.cpu().numpy().tolist())\n        truths.extend([y[i].item() for i in range(len(y))])",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "tmp_df = pd.DataFrame({\"y\": truths, r\"$\\hat{y}$\": predictions})\n\n# scatter plot\ng = sns.JointGrid(x=\"y\", y=r\"$\\hat{y}$\", data=tmp_df)\ng = g.plot_joint(plt.scatter, c=\"green\", alpha=0.5)\n\n# line: y_pred = y\ny_line = np.linspace(np.min(truths), np.max(predictions), 200)\ng.ax_joint.plot(y_line, y_line, color=\"blue\", linestyle=\"--\");\n\n# histograms\ng = g.plot_marginals(sns.histplot, data=df, color=\"green\", kde=False)\n\ng.ax_joint.set_xlim(np.min(y_line), np.max(y_line))\ng.ax_joint.set_ylim(np.min(y_line), np.max(y_line))\n\nplt.show()",
      "names": [
        {
          "import_components": [
            "pandas",
            "DataFrame"
          ],
          "code_str": "pd.DataFrame",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "pandas.DataFrame"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\nprint(f\"MSE: {mean_squared_error(truths, predictions):.2f}\")\nprint(f\"Coefficient of determination: {r2_score(truths, predictions):.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_2_GNN_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Predict Molecular Property using Graph Neural Network",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/deep_nn/Reference_ch6_Part_3_rnn_colab": [
    {
      "source": "!pip install numpy pandas matplotlib seaborn torch torch_geometric rdkit wget tqdm",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Install-Dependencies",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Install Dependencies"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m \\\n    wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Download-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Download Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport tqdm\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2\n\nimport rdkit.Chem as Chem\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader",
      "names": [
        {
          "import_components": [
            "re"
          ],
          "code_str": "re",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "re"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Import-Packages",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Import Packages"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", device)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Import-Packages",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Import Packages"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "DELANEY_FILE = \"delaney-processed.csv\"\nTASK_COL = 'measured log solubility in mols per litre'\ndf = pd.read_csv(DELANEY_FILE)\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Load-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "df[\"mol\"] = df[\"smiles\"].apply(lambda x: Chem.MolFromSmiles(x))\ndf = df[df[\"mol\"].notna()]",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Load-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# we will keep the following columns and discard the rest\ndf = df[[\"Compound ID\", TASK_COL, \"smiles\", \"mol\"]]\ndf",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Load-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class SMILESDataset(Dataset):\n    def __init__(self, df, mol_col, target_col, augment=True):\n        self.all_df = df\n        self.mol_col = mol_col\n        self.target_col = target_col\n        self.augment = augment\n\n    def _featurize(self, mol):\n        #The mapping of the chemical compounds to SMILES strings are not unique\n        # \"doRandom\" allows the generation of different SMILES strings\n        # for the same chemical compounds.\n        # This is our data augmentation approach\n        smi = Chem.MolToSmiles(mol, doRandom=self.augment)\n        return smi\n\n    def __getitem__(self, idx):\n        mol = self.all_df.iloc[idx][self.mol_col]\n        smi = self._featurize(mol)\n        pka = self.all_df.iloc[idx][self.target_col]\n        return smi, float(pka)\n\n    def __len__(self):\n        return self.all_df.shape[0]",
      "names": [
        {
          "import_components": [
            "float"
          ],
          "code_str": "float",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "float"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Create-SMILES-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Create SMILES Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class Collate:\n    def __init__(self, tokenizer, pad_token=\"PAD\"):\n        self.tokenizer = tokenizer\n        self.pad_token = pad_token\n\n    def collate(self, data):\n        smis = [smi for smi, pka in data]\n        X = [self.tokenizer.encode(smi) for smi in smis]\n        max_len = max([len(toks) for toks in X])\n        pad_idx = self.tokenizer.token2idx(self.pad_token)\n        # padded X\n        X = [[pad_idx]*(max_len-len(toks))+list(toks) for toks in X]\n        X = torch.Tensor(X).long()\n        Y = torch.Tensor([pka for smi, pka in data]).reshape(-1, 1).float()\n        return X, Y",
      "names": [
        {
          "import_components": [
            "max"
          ],
          "code_str": "max",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "max"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "list"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Create-SMILES-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Create SMILES Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# convert characters to integers\nclass Tokenizer():\n    def __init__(self):\n        self.vocab = [\"PAD\", \"UNK\", \"B\", \"Br\", \"Cl\", \"C\", \"H\", \\\n            \"N\", \"O\", \"S\", \"P\", \"F\", \"I\", \\\n            \"b\", \"c\", \"n\", \"o\", \"s\", \"p\", \"[\", \"]\", \\\n            \"(\", \")\", \".\", \" \", \"=\", \"#\", \\\n            \"+\", \"-\", \":\", \"~\", \"@\", \"*\", \"%\", \\\n            \"/\", \"\\\\\", \"0\", \"1\", \"2\", \"3\", \"4\", \\\n            \"5\", \"6\", \"7\", \"8\", \"9\"]\n        self.i2v = {i: v for i, v in enumerate(self.vocab)}\n        self.v2i = {v:i for i, v in enumerate(self.vocab)}\n\n\n        SMI_REGEX_PATTERN = r\"\"\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|\n        #|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\"\"\n        self.regex_pattern = SMI_REGEX_PATTERN\n        self.regex = re.compile(self.regex_pattern)\n\n    def token2idx(self, v):\n        if v in self.vocab:\n            return self.v2i[v]\n        else:\n            return self.v2i[\"UNK\"]\n\n    def encode(self, smi):\n        lst = []\n        tokens = [token for token in self.regex.findall(smi)]\n        for v in tokens:\n            lst.append(self.token2idx(v))\n        return lst",
      "names": [
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "enumerate"
        },
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "enumerate"
        },
        {
          "import_components": [
            "re",
            "compile"
          ],
          "code_str": "re.compile",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "re.compile"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Create-SMILES-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Create SMILES Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "tokenizer = Tokenizer()\n# smi = df.iloc[4][\"smiles\"]\nsmi = \"c1cccs1\"\n# smi = \"ClC(C)C\"\nprint(smi)\ntokens = [token for token in tokenizer.regex.findall(smi)]\nprint(\"Tokens:\", tokens)\ntok_ids = tokenizer.encode(smi)\nprint(\"Token ids:\", tok_ids)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Create-SMILES-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Create SMILES Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "Collate(tokenizer).collate([(\"c1cccs1\", -1.33), (\"ClC(C)C\", -1.41)])",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Create-SMILES-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Create SMILES Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.model_selection import train_test_split\n\n# training/validation dataset\ndata_size = df.shape[0]\ntest_ratio = 0.10\ntest_size = int(data_size*test_ratio)\ntrain_indices, test_indices = train_test_split(range(data_size), test_size=test_size, shuffle=True)\nprint(f\"Training size: {len(train_indices)}, test size: {len(test_indices)}\")\ntrain_df, test_df = df.iloc[train_indices], df.iloc[test_indices]",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Split-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Split Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# change to False in order to use rdkit CanonicalSMILES only\naugment = True\nbatch_size = 32\n\ntokenizer = Tokenizer()\nprint(tokenizer.vocab)\nvocab_size = len(tokenizer.vocab)\nprint(f\"Number of tokens: {vocab_size}\")\n\n## batching\ninstance = Collate(tokenizer)\ncollate_fn = instance.collate\n\ntrain_data = SMILESDataset(train_df, mol_col=\"mol\", target_col=TASK_COL, augment=augment)\ntrain_loader = DataLoader(train_data, \\\n    batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=False)\ntest_data = SMILESDataset(test_df, mol_col=\"mol\", target_col=TASK_COL, augment=augment)\ntest_loader = DataLoader(test_data, \\\n    batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=False)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Split-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Split Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "train_data[0]",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Split-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Split Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print([train_data[4] for i in range(5)])",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Split-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Split Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "batch = next(iter(DataLoader(train_data, \\\n    batch_size=5, shuffle=True, collate_fn=collate_fn, drop_last=False)))\nprint(batch)",
      "names": [
        {
          "import_components": [
            "next"
          ],
          "code_str": "next",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "next"
        },
        {
          "import_components": [
            "iter"
          ],
          "code_str": "iter",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "iter"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Split-Dataset",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Split Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class SMILESModel(nn.Module):\n    def __init__(self, vocab_size, emb_dim, \\\n            hidden_dim, n_layers, dropout=0.3, rnn_type=\"lstm\", bidirectional=True):\n        super(SMILESModel, self).__init__()\n        #Convert each input token into an \"emb_dim\" vector.\n        self.embedding = nn.Embedding(vocab_size, emb_dim)\n        self.rnn_type = rnn_type\n        # choose rnn module\n        if self.rnn_type == \"rnn\":\n            self.rnn = nn.RNN(emb_dim, hidden_dim, n_layers, dropout=dropout,\n                              batch_first=True, bidirectional=bidirectional)\n        elif self.rnn_type == \"lstm\":\n            self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout,\n                               batch_first=True, bidirectional=bidirectional)\n        elif self.rnn_type == \"gru\":\n            self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, dropout=dropout,\n                              batch_first=True, bidirectional=bidirectional)\n        else:\n            raise ValueError(\"rnn_type must be 'rnn', 'lstm', or 'gru'\")\n\n        self.dropout = nn.Dropout(dropout)\n        if bidirectional:\n            self.fc = nn.Linear(2*hidden_dim, 1)\n        else:\n            self.fc = nn.Linear(hidden_dim, 1)\n\n    def forward(self, token_batch):\n        out = token_batch.long()\n        out = self.embedding(out) # convert ingeters to continuous embeddings\n        out, _ = self.rnn(out)\n        out = out[:, -1, :]\n        out = self.dropout(out)\n        out = self.fc(out)\n        return out",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "ValueError"
          ],
          "code_str": "ValueError",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "ValueError"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Model",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def train_one_epoch(model, criterion, optimizer, dataloader, clip):\n    model.train()\n    train_loss = []\n    for (x, y) in dataloader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        y_pred = model(x)\n        loss = criterion(y_pred, y)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        train_loss.append(loss.detach().cpu().numpy())\n    return np.mean(train_loss)\n\ndef val_one_epoch(model, criterion, dataloader):\n    model.eval()\n    val_loss = []\n    with torch.no_grad():\n        for (x, y) in dataloader:\n            x, y = x.to(device), y.to(device)\n            y_pred = model(x)\n            loss = criterion(y_pred, y)\n            val_loss.append(loss.detach().cpu().numpy())\n    return np.mean(val_loss)",
      "names": [
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Model",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "vocab_size = len(Tokenizer().vocab)\nlr = 1e-3\nemb_dim = 16\nhidden_dim = 32\ndropout = 0.3\nn_layers = 4\nclip = 5 # mitigate gradient exploding in BPTT\n\n# bidirectional: run the sentence from \"left to right\" and from \"right to left\"\nmodel = SMILESModel(vocab_size, emb_dim, hidden_dim,\n                    n_layers, dropout=dropout, rnn_type=\"rnn\", bidirectional=False)\nmodel.to(device)\nmodel = model.float()\nprint(\"Number of trainable parameters:\",\n      sum(p.numel() for p in model.parameters() if p.requires_grad))\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.MSELoss()\n\nn_epochs = 200\ntrain_loss = []\nval_loss = []\nfor epoch in tqdm.tqdm(range(n_epochs)):\n    losses = train_one_epoch(model, criterion, optimizer, train_loader, clip)\n    train_loss.append(np.mean(losses))\n    losses = val_one_epoch(model, criterion, test_loader)\n    val_loss.append(np.mean(losses))",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "sum"
          ],
          "code_str": "sum",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "sum"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Training",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Training"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(train_loss, c=\"blue\", label=\"Training\")\nax.plot(val_loss, c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Training",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Training"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "truths = []\npredictions = []\nmodel.eval()\nwith torch.no_grad():\n    for x, y in test_loader:\n        if device == \"cuda\":\n            x = x.to(device)\n        y_pred = model(x).reshape(-1)\n        predictions.extend(y_pred.cpu().detach().numpy().tolist())\n\n        y = y.reshape(y_pred.shape).cpu().numpy().tolist()\n        truths.extend(y)",
      "names": [],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "tmp_df = pd.DataFrame({\"y\": truths, r\"$\\hat{y}$\": predictions})\n\n# scatter plot\ng = sns.JointGrid(x=\"y\", y=r\"$\\hat{y}$\", data=tmp_df)\ng = g.plot_joint(plt.scatter, c=\"green\", alpha=0.5)\n\n# line: y_pred = y\ny_line = np.linspace(np.min(truths), np.max(predictions), 200)\ng.ax_joint.plot(y_line, y_line, color=\"blue\", linestyle=\"--\");\n\n# histograms\ng = g.plot_marginals(sns.histplot, data=df, color=\"green\", kde=False)\n\ng.ax_joint.set_xlim(np.min(y_line), np.max(y_line))\ng.ax_joint.set_ylim(np.min(y_line), np.max(y_line))\n\nplt.show()",
      "names": [
        {
          "import_components": [
            "pandas",
            "DataFrame"
          ],
          "code_str": "pd.DataFrame",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "pandas.DataFrame"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\nprint(f\"MSE: {mean_squared_error(truths, predictions):.2f}\")\nprint(f\"Coefficient of determination: {r2_score(truths, predictions):.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/deep_nn/Reference_ch6_Part_3_rnn_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Predict Molecular Property using Recurrent Neural Networks",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/generative/Reference_Ch7_VAE_colab": [
    {
      "source": "!pip install numpy pandas matplotlib seaborn torch torch_geometric wget rdkit",
      "names": [],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Install-Dependencies",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Install Dependencies"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget \\\n    https://raw.githubusercontent.com/aspuru-guzik-group/selfies/master/examples/vae_example/datasets/0SelectedSMILES_QM9.txt",
      "names": [],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Download-Dataset",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Download Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import os\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport tqdm\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2\n\nimport rdkit.Chem as Chem\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader",
      "names": [
        {
          "import_components": [
            "os"
          ],
          "code_str": "os",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "os"
        },
        {
          "import_components": [
            "re"
          ],
          "code_str": "re",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "re"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Import-Packages",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Import Packages"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", device)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Import-Packages",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Import Packages"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "qm9file = \"0SelectedSMILES_QM9.txt\"\ndf = pd.read_csv(qm9file)\ndf = df.rename(columns={\"smiles\": \"SMILES\"})\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "QM9-Dataset",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Load Dataset",
          "QM9 Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "df.head()",
      "names": [],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "QM9-Dataset",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Load Dataset",
          "QM9 Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.subplots(1, 1, figsize=(5, 5))\nplt.hist(df[\"SMILES\"].str.len(), bins=50)\nplt.xlabel(\"SMILES length\")\nplt.ylabel(\"Number of molecules\")\nplt.tight_layout()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "hist"
          ],
          "code_str": "plt.hist",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.hist"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "tight_layout"
          ],
          "code_str": "plt.tight_layout",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.tight_layout"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "QM9-Dataset",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Load Dataset",
          "QM9 Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "max_len = 30 # filter out SMILES longer than this value\n\ndf = df[df[\"SMILES\"].str.len() <= max_len]\nprint(f\"Number of molecules after removing long SMILES: {df.shape[0]}\")\n\ndf[\"mol\"] = df[\"SMILES\"].apply(lambda x: Chem.MolFromSmiles(x))",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "QM9-Dataset",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Load Dataset",
          "QM9 Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "df.head()",
      "names": [],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "QM9-Dataset",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Load Dataset",
          "QM9 Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.model_selection import train_test_split\n\n# training/validation dataset\ndata_size = df.shape[0]\ntest_ratio = 0.10\ntest_size = int(data_size*test_ratio)\ntrain_indices, test_indices = train_test_split(range(data_size), test_size=test_size, shuffle=True)\nprint(f\"Training size: {len(train_indices)}, test size: {len(test_indices)}\")\ntrain_df, val_df = df.iloc[train_indices], df.iloc[test_indices]",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "QM9-Dataset",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Load Dataset",
          "QM9 Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "train_df.head()",
      "names": [],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "QM9-Dataset",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Load Dataset",
          "QM9 Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class SMILESDataset(Dataset):\n    def __init__(self, df, mol_col, target_col=None, augment=True):\n        self.all_df = df\n        self.mol_col = mol_col\n        self.target_col = target_col\n        self.augment = augment\n\n    def _featurize(self, mol):\n        smi = Chem.MolToSmiles(mol, doRandom=self.augment)\n        return smi\n\n    def __getitem__(self, idx):\n        mol = self.all_df.iloc[idx][self.mol_col]\n        smi = self._featurize(mol)\n        if self.target_col is None:\n            # without providing target variables\n            return smi\n        else:\n            # when provided target variable for regression or classification\n            target = self.all_df.iloc[idx][self.target_col].values\n            target = target.reshape(1, -1).astype(float)\n            return smi, torch.from_numpy(target).float()\n\n\n    def __len__(self):\n        return self.all_df.shape[0]\n\n\nclass Collate:\n    def __init__(self, tokenizer, pad_token=\"PAD\"):\n        self.tokenizer = tokenizer\n        self.pad_token = pad_token\n\n    def collate(self, data):\n        if not isinstance(data[0], tuple):\n            # X for generative model\n            smis = [smi for smi in data]\n        else:\n            # (X, Y) for regression and classification\n            smis = [smi for smi, target in data]\n\n        # tokenize SMILES and convert to token ids\n        X = [self.tokenizer.encode(smi) for smi in smis]\n        max_len = max([len(toks) for toks in X])\n        pad_idx = self.tokenizer.token2idx(self.pad_token)\n\n        # padded X\n        X = [[pad_idx]*(max_len-len(toks))+list(toks) for toks in X]\n        X = torch.Tensor(X).long()\n\n        if not isinstance(data[0], tuple):\n            return X\n        else:\n            n = len(data)\n            Y = torch.concat([target.reshape(1, -1) for smi, target in data], dim=0)\n            Y = Y.reshape(n, -1).float()\n            return X, Y\n\n\n# reference: https://deepchem.readthedocs.io/en/2.4.0/api_reference/tokenizers.html\nSMI_REGEX_PATTERN = r\"\"\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|\n#|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\"\"\n\n# convert characters to integers\nclass Tokenizer():\n    def __init__(self):\n        self.vocab = [\"PAD\", \"UNK\", \"SOS\", \"EOS\", \"B\", \"Br\", \"Cl\", \"C\", \"H\", \\\n            \"N\", \"O\", \"S\", \"P\", \"F\", \"I\", \\\n            \"b\", \"c\", \"n\", \"o\", \"s\", \"p\", \"[\", \"]\", \\\n            \"(\", \")\", \".\", \" \", \"=\", \"#\", \\\n            \"+\", \"-\", \":\", \"~\", \"@\", \"*\", \"%\", \\\n            \"/\", \"\\\\\", \"0\", \"1\", \"2\", \"3\", \"4\", \\\n            \"5\", \"6\", \"7\", \"8\", \"9\"]\n        self.i2v = {i: v for i, v in enumerate(self.vocab)}\n        self.v2i = {v:i for i, v in enumerate(self.vocab)}\n\n        self.regex_pattern = SMI_REGEX_PATTERN\n        self.regex = re.compile(self.regex_pattern)\n        self.SOS = self.token2idx(\"SOS\")\n        self.EOS = self.token2idx(\"EOS\")\n        self.PAD = self.token2idx(\"PAD\")\n        self.UNK = self.token2idx(\"UNK\")\n\n    def token2idx(self, v):\n        if v in self.vocab:\n            return self.v2i[v]\n        else:\n            return self.v2i[\"UNK\"]\n\n    def encode(self, smi):\n        lst = [self.token2idx(\"SOS\"), ]\n        tokens = [token for token in self.regex.findall(smi)]\n        for v in tokens:\n            lst.append(self.token2idx(v))\n        lst.append(self.token2idx(\"EOS\"))\n        return lst",
      "names": [
        {
          "import_components": [
            "float"
          ],
          "code_str": "float",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "float"
        },
        {
          "import_components": [
            "isinstance"
          ],
          "code_str": "isinstance",
          "lineno": 35,
          "end_lineno": 35,
          "context": "none",
          "resolved_location": "isinstance"
        },
        {
          "import_components": [
            "tuple"
          ],
          "code_str": "tuple",
          "lineno": 35,
          "end_lineno": 35,
          "context": "none",
          "resolved_location": "tuple"
        },
        {
          "import_components": [
            "max"
          ],
          "code_str": "max",
          "lineno": 44,
          "end_lineno": 44,
          "context": "none",
          "resolved_location": "max"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 44,
          "end_lineno": 44,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 48,
          "end_lineno": 48,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 48,
          "end_lineno": 48,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "isinstance"
          ],
          "code_str": "isinstance",
          "lineno": 51,
          "end_lineno": 51,
          "context": "none",
          "resolved_location": "isinstance"
        },
        {
          "import_components": [
            "tuple"
          ],
          "code_str": "tuple",
          "lineno": 51,
          "end_lineno": 51,
          "context": "none",
          "resolved_location": "tuple"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 54,
          "end_lineno": 54,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 74,
          "end_lineno": 74,
          "context": "none",
          "resolved_location": "enumerate"
        },
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 75,
          "end_lineno": 75,
          "context": "none",
          "resolved_location": "enumerate"
        },
        {
          "import_components": [
            "re",
            "compile"
          ],
          "code_str": "re.compile",
          "lineno": 78,
          "end_lineno": 78,
          "context": "none",
          "resolved_location": "re.compile"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Create-PyTorch-Dataset",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Create PyTorch Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "tokenizer = Tokenizer()\nsmi = train_df.iloc[0][\"SMILES\"]\nprint(smi)\n\ntokens = [token for token in tokenizer.regex.findall(smi)]\nprint(\"Tokens:\", tokens)\n\ntok_ids = tokenizer.encode(smi)\nprint(\"Token ids:\", tok_ids)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Create-PyTorch-Dataset",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Create PyTorch Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "## this is what we will use for VAE\n# post padding\nCollate(tokenizer).collate([\"c1cccs1\", \"ClC(C)C\"])",
      "names": [],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Create-PyTorch-Dataset",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Create PyTorch Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "augment = True\nbatch_size = 500\n\ntokenizer = Tokenizer()\nprint(\"Vocabulary:\", tokenizer.vocab)\nvocab_size = len(tokenizer.vocab)\nprint(f\"Number of tokens: {vocab_size}\")\n\n## batching\ninstance = Collate(tokenizer)\ncollate_fn = instance.collate\n\ntrain_data = SMILESDataset(train_df, mol_col=\"mol\", target_col=None, augment=augment)\ntrain_loader = DataLoader(train_data, \\\n    batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=False)\ntest_data = SMILESDataset(val_df, mol_col=\"mol\", target_col=None, augment=augment)\ntest_loader = DataLoader(test_data, \\\n    batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=False)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "id1",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "train_data[0]",
      "names": [],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "id1",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "batch = next(iter(DataLoader(train_data, \\\n    batch_size=5, shuffle=True, collate_fn=collate_fn, drop_last=False)))\nprint(batch)",
      "names": [
        {
          "import_components": [
            "next"
          ],
          "code_str": "next",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "next"
        },
        {
          "import_components": [
            "iter"
          ],
          "code_str": "iter",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "iter"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "id1",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class Encoder(nn.Module):\n    def __init__(self,\n                  vocab_size, # number of tokens\n                  emb_dim, # dimensions of token embedding\n                  hidden_dim, # hidden dimension in RNN\n                  n_layers, # number of layers in RNN\n                  latent_dim, # dimension of the latent space\n                  dropout=0.3,\n                  rnn_type=\"lstm\",\n                  bidirectional=True):\n        super(Encoder,self).__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_dim)\n        self.rnn_type = rnn_type\n        # choose rnn module\n        if self.rnn_type == \"rnn\":\n            self.rnn = nn.RNN(emb_dim, hidden_dim, n_layers, dropout=dropout,\n                              batch_first=True, bidirectional=bidirectional)\n        elif self.rnn_type == \"lstm\":\n            self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout,\n                               batch_first=True, bidirectional=bidirectional)\n        elif self.rnn_type == \"gru\":\n            self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, dropout=dropout,\n                              batch_first=True, bidirectional=bidirectional)\n        else:\n            raise ValueError(\"rnn_type must be 'rnn', 'lstm', or 'gru'\")\n\n        self.bidirectional = bidirectional\n        self.dropout = nn.Dropout(dropout)\n\n        # mu and sigma\n        self.bidirectional = bidirectional\n        if self.bidirectional:\n            self.mu_fc = nn.Linear(2*hidden_dim, latent_dim)\n            self.logvar_fc = nn.Linear(2*hidden_dim, latent_dim)\n        else:\n            self.mu_fc = nn.Linear(hidden_dim, latent_dim)\n            self.logvar_fc = nn.Linear(hidden_dim, latent_dim)\n\n    def forward(self, token_batch):\n        x = token_batch.long()\n        x = self.embedding(x) # convert ingeters to continuous embeddings\n        x, _ = self.rnn(x)\n        x = x[:, -1, :] # convert each SMILES string to a vector\n\n        # get mu and logvar\n        batch_size = x.shape[0]\n        x = nn.ReLU()(x)\n        x = x.reshape(batch_size, -1)\n        x = self.dropout(x)\n        mu, logvar = self.mu_fc(x), self.logvar_fc(x)\n        return mu, logvar",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "ValueError"
          ],
          "code_str": "ValueError",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "ValueError"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Encoder",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Model",
          "Encoder"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class Decoder(nn.Module):\n    def __init__(self, vocab_size,\n            embed_dim,\n            hidden_dim,\n            n_layers,\n            dropout,\n            rnn_type):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.rnn_type = rnn_type\n        self.n_layers = n_layers\n        # choose rnn module\n        if self.rnn_type == \"rnn\":\n            self.rnn = nn.RNN(embed_dim, hidden_dim, n_layers, dropout=dropout,\n                                batch_first=True, bidirectional=False)\n        elif self.rnn_type == \"lstm\":\n            self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout,\n                                batch_first=True, bidirectional=False)\n        elif self.rnn_type == \"gru\":\n            self.rnn = nn.GRU(embed_dim, hidden_dim, n_layers, dropout=dropout,\n                                batch_first=True, bidirectional=False)\n        else:\n            raise ValueError(\"rnn_type must be 'rnn', 'lstm', or 'gru'\")\n\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n\n    def forward(self, x, hidden):\n        shape = x.shape\n        x = self.embedding(x.long())\n\n        if len(hidden) != 2:\n            if len(hidden.shape) == 2:\n                # if didn't repeat n_layers times\n                hidden = hidden.repeat(self.n_layers, 1, 1)\n            if self.rnn_type == \"lstm\":\n                hidden = (hidden, hidden) # hidden state, cell state\n\n\n        x, hidden = self.rnn(x, hidden)\n\n        x = x.contiguous().reshape(-1, x.shape[-1]) # (B*len, hidden_dim)\n        x = self.fc(x) # (B*len, vocab_size)\n        x = x.view(*shape, x.shape[-1]) # (B, len, vocab_size)\n        return x, hidden",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "ValueError"
          ],
          "code_str": "ValueError",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "ValueError"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 32,
          "end_lineno": 32,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Decoder",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Model",
          "Decoder"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "tok_ids = tokenizer.encode(smi)\n# (B=1, len)\ntok_tensor = torch.Tensor(tok_ids).reshape(1, -1)\nprint(\"Token tensor:\", tok_tensor)\n\n## test encoder\nenc = Encoder(vocab_size=len(tokenizer.vocab), # number of tokens\n    emb_dim=2, # dimensions of token embedding\n    hidden_dim=4, # hidden dimension in RNN\n    n_layers=2, # number of layers in RNN\n    latent_dim=2, # dimension of the latent space\n    dropout=0.3,\n    rnn_type=\"lstm\",\n    bidirectional=True)\nmu, logvar = enc(tok_tensor)\nprint(\"Shape of mu:\", mu.shape)\n\n\n## test decoder\ndec = Decoder(vocab_size=len(tokenizer.vocab),\n    embed_dim=2,\n    hidden_dim=2,\n    n_layers=2,\n    dropout=0.3,\n    rnn_type=\"lstm\")\nsigma = torch.exp(0.5*logvar)\neps = torch.randn_like(sigma).float()\n# sample a vector\nz = mu + sigma * eps\nprint(\"Shape of sampled vector:\", z.shape)\n\n# repear for n_layers\n# z = z.unsqueeze(1)\n# z = z.repeat(2, 1, 1)\nprint(\"Shape of initial hidden state for decoder:\", z.shape)\n\nx = torch.ones((1, 3)) # three tokens\n\n# decode the vector\nx_plus_one, hidden_plus_one = dec(x, z)\n# print(\"Next token logits:\", x_plus_one)\nprint(\"Shape of next token logits:\", x_plus_one.shape) # (B=1, len, vocab_size)\nprint(\"Predicted next token id:\", x_plus_one.argmax(-1, keepdim=True))",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 30,
          "end_lineno": 30,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 35,
          "end_lineno": 35,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 42,
          "end_lineno": 42,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 43,
          "end_lineno": 43,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Unit-test-of-the-encoder-and-decoder-class",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Model",
          "Unit test of the encoder and decoder class"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class Molecule_VAE(nn.Module):\n    def __init__(self,\n                vocab_size, # number of tokens\n                emb_dim, # dimensions of token embedding\n                enc_hidden_dim, # hidden dimension in encoder\n                enc_n_layers, # number of layers in encoder\n                enc_rnn_type,\n                enc_bidirectional,\n                latent_dim, # dimension of the latent space\n                dec_n_layers, # number of layers in decoder\n                dec_rnn_type,\n                dropout=0.3,\n                tokenizer=Tokenizer()):\n\n        super(Molecule_VAE, self).__init__()\n        self.encoder = Encoder(vocab_size,\n                            emb_dim,\n                            enc_hidden_dim,\n                            enc_n_layers,\n                            latent_dim,\n                            dropout,\n                            enc_rnn_type,\n                            enc_bidirectional)\n\n        dec_hidden_dim = latent_dim\n        self.decoder = Decoder(vocab_size,\n                            emb_dim,\n                            dec_hidden_dim, # takes the latent vector as hidden state\n                            dec_n_layers,\n                            dropout,\n                            dec_rnn_type)\n        self.latent_dim = latent_dim\n        self.tokenizer = tokenizer\n\n    def reparameterize(self, mu, logvar):\n        \"\"\"Return the latent normal sample z ~ N(mu, sigma^2)\"\"\"\n        std = torch.exp(0.5*logvar)\n        eps = torch.randn_like(std).to(mu.device)\n        return mu + eps*std\n\n    def forward(self, x):\n        \"\"\"Forward Function which passes the data through entire model\"\"\"\n        mu, logvar = self.encoder(x) # latent space\n        z = self.reparameterize(mu, logvar) # sampled from latent space\n        hidden = z.unsqueeze(0).repeat(self.decoder.n_layers, 1, 1)\n        recon_x, hidden = self.decoder(x, hidden) # use the true labesl in the training data x as input for decoder\n        return recon_x, mu, logvar",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "super"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "VAE",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Model",
          "VAE"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def vae_loss_function(recon_x, x, mu, logvar, alpha_KDL=1.0e-05):\n    \"\"\"Return cross entropy loss (reconstruction) and KL divergence\"\"\"\n    CE = nn.CrossEntropyLoss()(recon_x, x)\n    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n    return CE, alpha_KDL*KLD",
      "names": [],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Define-loss-function",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Model",
          "Train Utils",
          "Define loss function"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def train_one_epoch(model, criterion, optimizer, dataloader, clip):\n    model.train()\n    train_loss = []\n    for x in dataloader:\n        x = x.to(device)\n        optimizer.zero_grad()\n        output, mu, logvar = model(x)\n\n        pred = output[:, :-1, :]\n        pred = pred.reshape(-1, pred.shape[-1]) # (B*(len-1), vocab_size), unormalized logits\n        truth = x[:, 1:]\n        truth = truth.reshape(-1) # (B*(len-1), ), labels\n\n        ce, kld = criterion(pred, truth, mu, logvar) # we want to keep track of two losses separately\n        loss = ce + kld\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        train_loss.append([ce.detach().cpu().numpy(), kld.detach().cpu().numpy()])\n    return train_loss\n\ndef val_one_epoch(model, criterion, dataloader):\n    model.eval()\n    val_loss = []\n    with torch.no_grad():\n        for x in dataloader:\n            x = x.to(device)\n            output, mu, logvar = model(x)\n\n            pred = output[:, :-1, :]\n            pred = pred.reshape(-1, pred.shape[-1])\n            truth = x[:, 1:]\n            truth = truth.reshape(-1)\n\n            ce, kld = criterion(pred, truth, mu, logvar)\n            val_loss.append([ce.detach().cpu().numpy(), kld.detach().cpu().numpy()])\n    return val_loss",
      "names": [],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Training-and-validation-functions",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Model",
          "Train Utils",
          "Training and validation functions"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "vocab_size = len(Tokenizer().vocab)\nlr = 1e-3\nemb_dim = 32\nenc_hidden_dim = 64\ndropout = 0.3\nenc_n_layers = 3\nenc_rnn_type = \"lstm\"\nenc_bidirectional = True\nlatent_dim = 64\ndec_n_layers = 3\ndec_rnn_type = \"lstm\"\nclip = 10 # mitigate gradient exploding/vanishing in BPTT\n\nmodel = Molecule_VAE(vocab_size, # number of tokens\n        emb_dim, # dimensions of token embedding\n        enc_hidden_dim, # hidden dimension in encoder\n        enc_n_layers, # number of layers in encoder\n        enc_rnn_type,\n        enc_bidirectional,\n        latent_dim, # dimension of the latent space\n        dec_n_layers, # number of layers in decoder\n        dec_rnn_type,\n        dropout=0.3,\n        tokenizer=Tokenizer())\nmodel.to(device)\nmodel = model.float()\n\nprint(\"Number of trainable parameters:\",\n      sum(p.numel() for p in model.parameters() if p.requires_grad))\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n\n# feel free to try different alpha_KDL\nalpha_KDL=1.0e-05\n\nfrom functools import partial\ncriterion = partial(vae_loss_function, alpha_KDL=alpha_KDL)",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "sum"
          ],
          "code_str": "sum",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "sum"
        },
        {
          "import_components": [
            "functools"
          ],
          "code_str": "functools",
          "lineno": 37,
          "end_lineno": 37,
          "context": "import_from",
          "resolved_location": "functools"
        },
        {
          "import_components": [
            "functools",
            "partial"
          ],
          "code_str": "partial",
          "lineno": 37,
          "end_lineno": 37,
          "context": "import_target",
          "resolved_location": "functools.partial"
        },
        {
          "import_components": [
            "functools",
            "partial"
          ],
          "code_str": "partial",
          "lineno": 38,
          "end_lineno": 38,
          "context": "none",
          "resolved_location": "functools.partial"
        },
        {
          "import_components": [
            "functools",
            "partial",
            "()"
          ],
          "code_str": "criterion",
          "lineno": 38,
          "end_lineno": 38,
          "context": "none",
          "resolved_location": "functools.partial"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Training",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Training"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "n_epochs = 100\nlog_interval = 10\n\nlogdir = f\"params_thres{max_len}_epochs{n_epochs}_qm9_alpha{alpha_KDL}\" # log directory\nos.makedirs(logdir, exist_ok=True)\nfinal_file = os.path.join(logdir, f\"final_params.pth\")\n\n\ntrain_loss = []\nval_loss = []",
      "names": [
        {
          "import_components": [
            "os",
            "makedirs"
          ],
          "code_str": "os.makedirs",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "os.makedirs"
        },
        {
          "import_components": [
            "os",
            "path",
            "join"
          ],
          "code_str": "os.path.join",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "os.path.join"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Training",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Training"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "for epoch in tqdm.tqdm(range(n_epochs)):\n    losses = train_one_epoch(model, criterion, optimizer, train_loader, clip)\n    mean_loss = np.mean(np.array(losses), axis=0)\n    train_loss.append([mean_loss[0], mean_loss[1]])\n\n    losses = val_one_epoch(model, criterion, test_loader)\n    mean_loss = np.mean(np.array(losses), axis=0)\n    val_loss.append([mean_loss[0], mean_loss[1]])\n\n    if epoch % log_interval == 0:\n        # print loss\n        print(f\"Training CE: {train_loss[-1][0]:.4f}, Training KL: {train_loss[-1][1]:.4f}\")\n        print(f\"Validation CE: {val_loss[-1][0]:.4f}, Validation KL: {val_loss[-1][1]:.4f}\")\n\n        # save checkpoint\n        checkpoint = {\n            \"train_loss\": train_loss,\n            \"val_loss\": val_loss,\n            \"model_state_dict\": model.state_dict(),\n            \"optimizer_state_dict\": optimizer.state_dict(),\n        }\n        torch.save(checkpoint, os.path.join(logdir, f\"checkpoint_epoch{epoch}.pth\"))\n\n# save final model\ncheckpoint = {\n    \"train_loss\": train_loss,\n    \"val_loss\": val_loss,\n    \"model_state_dict\": model.state_dict(),\n    \"optimizer_state_dict\": optimizer.state_dict(),\n}\ntorch.save(checkpoint, os.path.join(logdir, f\"final_params.pth\"))",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "functools",
            "partial",
            "()"
          ],
          "code_str": "criterion",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "functools.partial"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "functools",
            "partial",
            "()"
          ],
          "code_str": "criterion",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "functools.partial"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "os",
            "path",
            "join"
          ],
          "code_str": "os.path.join",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "os.path.join"
        },
        {
          "import_components": [
            "os",
            "path",
            "join"
          ],
          "code_str": "os.path.join",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "os.path.join"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Skip-the-following-block-if-the-model-is-trained.",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Training",
          "Skip the following block if the model is trained."
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "ckpt_file = os.path.join(logdir, \"final_params.pth\")\ncheckpoint = torch.load(ckpt_file, weights_only=False, map_location=device)\nmodel.load_state_dict(checkpoint[\"model_state_dict\"])\nprint(f\"Loaded parameters from existing file. \"\\\n    f\"Please manually detele {final_file} if you want to re-train the model\")\ntrain_loss = checkpoint[\"train_loss\"]\nval_loss = checkpoint[\"val_loss\"]",
      "names": [
        {
          "import_components": [
            "os",
            "path",
            "join"
          ],
          "code_str": "os.path.join",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "os.path.join"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Load-from-trained-file",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Training",
          "Load from trained file"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "train_loss = checkpoint[\"train_loss\"]\nval_loss = checkpoint[\"val_loss\"]\n\nf, ax = plt.subplots(1, 1, figsize=(5,5))\nax.plot([item[0] for item in train_loss], c=\"blue\", label=\"Training CE\")\nax.plot([item[0] for item in val_loss], c=\"red\", label=\"Test CE\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CE Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Load-from-trained-file",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Training",
          "Load from trained file"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\nax.plot([item[1] for item in train_loss], c=\"blue\", label=\"Training KL\")\nax.plot([item[1] for item in val_loss], c=\"red\", label=\"Test KL\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"KL Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Load-from-trained-file",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Training",
          "Load from trained file"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "train_loss = checkpoint[\"train_loss\"]\nval_loss = checkpoint[\"val_loss\"]\n\nf, ax = plt.subplots(1, 1, figsize=(5,5))\nax.plot([item[0]+item[1] for item in train_loss], c=\"blue\", label=\"Training\")\nax.plot([item[0]+item[1] for item in val_loss], c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Total Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Load-from-trained-file",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Training",
          "Load from trained file"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "probabilities = []\npredictions = []\ntruths = []\nmodel.eval()\n\nmax_length = max_len\n\n# change these two values to control the number of compounds to generate\nn_compounds = 100\nk_samples = 5\n\ncomp_indices = np.random.choice(val_df.shape[0], n_compounds, replace=False)\ngen_data = SMILESDataset(val_df.iloc[comp_indices, :], mol_col=\"mol\", target_col=None, augment=augment)\ngen_loader = DataLoader(gen_data, \\\n    batch_size=1, shuffle=False, collate_fn=collate_fn, drop_last=False)",
      "names": [
        {
          "import_components": [
            "numpy",
            "random",
            "choice"
          ],
          "code_str": "np.random.choice",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.random.choice"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import rdkit.Chem.Draw as Draw\nDraw.MolsToGridImage(val_df.iloc[comp_indices][\"mol\"], molsPerRow=10,\n                     legends=val_df.iloc[comp_indices][\"SMILES\"].values.tolist(), maxMols=1000)",
      "names": [],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "generated_token_ids = []\n\nwith torch.no_grad():\n    for x in gen_loader:\n        if device == \"cuda\":\n            x = x.to(device)\n        _, mu, logvar = model(x)\n\n        # sample n_samples times from latent space\n        mu = mu.repeat(k_samples, 1)\n        logvar = logvar.repeat(k_samples, 1)\n        z = model.reparameterize(mu, logvar)\n\n        # the latent space will be the initial hidden state of the decoder\n        hidden = z\n\n        # initial input: (B, 1) with <SOS> id\n        SOS_token = tokenizer.SOS\n        input_ = torch.full((k_samples, 1), SOS_token, dtype=torch.long, device=z.device)\n\n        outputs = torch.zeros(k_samples, max_length).to(z.device)\n\n        # generate SMILES\n        for t in range(max_length):\n            # output has the shape of (B, 1, vocab_size)\n            output, hidden_next = model.decoder(input_, hidden)\n            output = nn.Softmax(dim=-1)(output) # probabilities\n            output = torch.argmax(output, dim=-1) # predicted label with max prob\n\n            # update input and hidden state\n            outputs[:, t:t+1] = output\n            input_ = output\n            hidden = hidden_next\n\n        outputs = outputs.cpu().numpy()\n        generated_token_ids.append(outputs)",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# clean up generated SMILES\nconcat_token_ids = np.vstack(generated_token_ids)\n\nEOS_token = tokenizer.EOS\neos_positions = (concat_token_ids == EOS_token)\n\n# locate index of the first <EOS>, or return -1 if no <EOS>\neos_positions = np.where(np.sum(eos_positions, axis=-1)>0, eos_positions.argmax(axis=-1), -1)\n\ntruncated_sequences = []\n\nfor idx in range(concat_token_ids.shape[0]):\n    eos_idx = eos_positions[idx]\n    if eos_idx != -1:\n        token_ids = concat_token_ids[idx, :eos_idx]\n    else:\n        token_ids = concat_token_ids[idx, :]\n\n    generated_tokens = [tokenizer.i2v[i] for i in token_ids if i != tokenizer.PAD]\n    generated_smi = \"\".join(generated_tokens) # concat tokens to string\n    if len(generated_smi) > 0:\n        truncated_sequences.append(generated_smi)\n\nprint(\"All generated SMILES:\")\nprint(truncated_sequences)",
      "names": [
        {
          "import_components": [
            "numpy",
            "vstack"
          ],
          "code_str": "np.vstack",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.vstack"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from rdkit import RDLogger\nRDLogger.DisableLog('rdApp.*')\n\nsuccess_count = 0\nsuccessed_smi = []\nfor smi in truncated_sequences:\n    try:\n        mol = Chem.MolFromSmiles(smi)\n        if mol is not None:\n            success_count += 1\n            successed_smi.append(smi)\n    except:\n        continue\n\nprint(f\"Validity ratio of generated SMIMLES: {success_count/len(truncated_sequences)*100:.2f}%\")\nprint(\"Valid generated SMILES:\")\nprint(successed_smi)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "unique_mols = []\nfor smi in successed_smi:\n    mol = Chem.MolFromSmiles(smi)\n    is_new = True\n    for ref_mol in unique_mols:\n        s1 = mol.HasSubstructMatch(ref_mol)\n        s2 = ref_mol.HasSubstructMatch(mol)\n        if s1 and s2:\n            is_new = False\n            break\n    if is_new:\n        unique_mols.append(mol)\n\nprint(f\"Uniqueness ratio in valid SMILES: {len(unique_mols)/len(successed_smi)*100:.2f}%\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "unique_smi = [Chem.MolToSmiles(mol) for mol in unique_mols]\nDraw.MolsToGridImage(unique_mols, molsPerRow=10, legends=unique_smi, maxMols=1000)",
      "names": [],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def is_novel(mol):\n    hit = df[\"mol\"].apply(lambda x: x.HasSubstructMatch(mol) and mol.HasSubstructMatch(x))\n    return not any(hit)\n\nnovel_mols = []\nfor mol in unique_mols:\n    if is_novel(mol):\n        novel_mols.append(mol)\n\nnovel_smi = [Chem.MolToSmiles(mol) for mol in novel_mols]\nDraw.MolsToGridImage(novel_mols, molsPerRow=10, legends=novel_smi)",
      "names": [
        {
          "import_components": [
            "any"
          ],
          "code_str": "any",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "any"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(f\"Novelty ratio in unique SMILES: {len(novel_mols)/len(unique_mols)*100:.2f}%\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# # ## Download source code to compute synthetic availability score from rdkit\n# !python -m wget https://raw.githubusercontent.com/rdkit/rdkit/master/Contrib/SA_Score/sascorer.py\n# !python -m wget https://raw.githubusercontent.com/rdkit/rdkit/master/Contrib/SA_Score/fpscores.pkl.gz",
      "names": [],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from rdkit.Chem import Descriptors\nimport os, sys\nfrom rdkit.Chem import RDConfig\n# using literature contributors\n# from https://github.com/rdkit/rdkit/tree/master/Contrib\nsys.path.append(os.path.join(RDConfig.RDContribDir, 'SA_Score'))\nimport sascorer",
      "names": [
        {
          "import_components": [
            "os"
          ],
          "code_str": "os",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "os"
        },
        {
          "import_components": [
            "sys"
          ],
          "code_str": "sys",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "sys"
        },
        {
          "import_components": [
            "os",
            "path",
            "join"
          ],
          "code_str": "os.path.join",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "os.path.join"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "mols_in_lib = val_df.iloc[comp_indices][\"mol\"].values.tolist()\nmols_generated = unique_mols\n\neval_df = pd.DataFrame({\"mol\": mols_in_lib+mols_generated})\neval_df[\"label\"] = [\"lib\"]*len(mols_in_lib) + [\"gen\"]*len(mols_generated)\neval_df[\"logP\"] = eval_df[\"mol\"].apply(Descriptors.MolLogP)\neval_df[\"qed\"] = eval_df[\"mol\"].apply(Descriptors.qed)\neval_df[\"SAS\"] = eval_df[\"mol\"].apply(sascorer.calculateScore)",
      "names": [
        {
          "import_components": [
            "pandas",
            "DataFrame"
          ],
          "code_str": "pd.DataFrame",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "pandas.DataFrame"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "properties = [\"logP\", \"qed\", \"SAS\"]\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\naxs = axs.flatten()\nfor i, prop in enumerate(properties):\n    sns.histplot(data=eval_df, hue=\"label\", kde=True, x=prop, ax=axs[i])\nplt.tight_layout()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "enumerate"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "tight_layout"
          ],
          "code_str": "plt.tight_layout",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.tight_layout"
        }
      ],
      "example": {
        "document": "examples/generative/Reference_Ch7_VAE_colab",
        "ref_id": "Evaluation-Metrics",
        "headings": [
          "Generate SMILES using VAE+RNN",
          "Evaluation Metrics"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/linear_models/Reference_Ch4_Part_1_linear_regression": [
    {
      "source": "!pip install wget",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    },
    {
      "source": "import copy\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport seaborn as sns\n\ncmap = plt.get_cmap(\"tab10\")\ncolors = [cmap(i) for i in range(cmap.N)]\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2",
      "names": [
        {
          "import_components": [
            "copy"
          ],
          "code_str": "copy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "copy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "animation"
          ],
          "code_str": "matplotlib.animation",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "matplotlib.animation"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "get_cmap"
          ],
          "code_str": "plt.get_cmap",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.get_cmap"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Linear-Regression",
        "headings": [
          "Linear Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv \\\n    --output delaney-processed.csv",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Load-Dataset-and-Prepare-Data",
        "headings": [
          "Linear Regression",
          "Load Dataset and Prepare Data"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "DELANEY_FILE = \"delaney-processed.csv\"\ndf = pd.read_csv(DELANEY_FILE)\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Load-Dataset-and-Prepare-Data",
        "headings": [
          "Linear Regression",
          "Load Dataset and Prepare Data"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# features\nX = df[[\"Molecular Weight\"]].values\nX = X.reshape(-1, 1)\nX = np.hstack([np.ones_like(X), X])\n\n# ground truth\nY = df[\"measured log solubility in mols per litre\"].values\nY = Y.reshape(-1, 1)",
      "names": [
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones_like"
          ],
          "code_str": "np.ones_like",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.ones_like"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "logS-vs.-Molecular-Weight",
        "headings": [
          "Linear Regression",
          "Load Dataset and Prepare Data",
          "logS vs. Molecular Weight"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(\"Shape of X:\", X.shape)\nprint(\"Shape of Y:\", Y.shape)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "logS-vs.-Molecular-Weight",
        "headings": [
          "Linear Regression",
          "Load Dataset and Prepare Data",
          "logS vs. Molecular Weight"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n# scatter\n\nax.scatter(X[:, -1], Y.reshape(-1), \\\n            s=15, marker='o', \\\n            facecolors='none', edgecolor=\"blue\")\n\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"log solubility (mol/L)\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "logS-vs.-Molecular-Weight",
        "headings": [
          "Linear Regression",
          "Load Dataset and Prepare Data",
          "logS vs. Molecular Weight"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "theta = np.linalg.inv((X.T @ X)) @ (X.T @ Y)",
      "names": [
        {
          "import_components": [
            "numpy",
            "linalg",
            "inv"
          ],
          "code_str": "np.linalg.inv",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.linalg.inv"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Analytical-solution",
        "headings": [
          "Linear Regression",
          "Analytical solution"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "theta",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Analytical-solution",
        "headings": [
          "Linear Regression",
          "Analytical solution"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "y_pred = X @ theta\nloss = np.mean((y_pred - Y)**2)\nprint(f\"Loss: {loss}\")",
      "names": [
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Loss",
        "headings": [
          "Linear Regression",
          "Analytical solution",
          "Loss"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "min_logS = np.min(Y)\nmax_logS = np.max(Y)\nx_line = np.linspace(np.floor(min_logS), np.ceil(max_logS), 100)\n\ntmp_df = pd.DataFrame({\"y\": Y.reshape(-1), r\"$\\hat{y}$\": y_pred.reshape(-1)})\n\n# scatter plot\ng = sns.JointGrid(x=\"y\", y=r\"$\\hat{y}$\", data=tmp_df)\ng = g.plot_joint(plt.scatter, c=\"green\", alpha=0.5)\n\n# line: y_pred = y\ny_line = np.linspace(np.floor(Y.reshape(-1)), np.ceil(Y.reshape(-1)), 200)\ng.ax_joint.plot(y_line, y_line, color=\"blue\", linestyle=\"--\");\n\n# histograms\ng = g.plot_marginals(sns.histplot, data=df, color=\"green\", kde=False)",
      "names": [
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "floor"
          ],
          "code_str": "np.floor",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.floor"
        },
        {
          "import_components": [
            "numpy",
            "ceil"
          ],
          "code_str": "np.ceil",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.ceil"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame"
          ],
          "code_str": "pd.DataFrame",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "pandas.DataFrame"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "floor"
          ],
          "code_str": "np.floor",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.floor"
        },
        {
          "import_components": [
            "numpy",
            "ceil"
          ],
          "code_str": "np.ceil",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.ceil"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Plot-Correlation",
        "headings": [
          "Linear Regression",
          "Analytical solution",
          "Plot Correlation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.metrics import r2_score\nprint(f\"Coefficient of determination: {r2_score(Y.reshape(-1), y_pred):.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Plot-Correlation",
        "headings": [
          "Linear Regression",
          "Analytical solution",
          "Plot Correlation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nplt.tight_layout()\nax.scatter(X[:, -1], Y.reshape(-1), \\\n            s=15, marker='o', \\\n            facecolors='none', edgecolor=\"blue\")\n\nmin_X = np.min(X[:, -1])\nmax_X = np.max(X[:, -1])\nx_line = np.linspace(np.floor(min_X), np.ceil(max_X), 100)\nx_line = x_line.reshape(-1, 1)\nx_line = np.hstack([np.ones_like(x_line), x_line])\ny_pred_line = x_line @ theta\n\nline, = ax.plot(x_line[:, -1], y_pred_line, color=\"orange\", label=\"Fitted line\")\n\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"log solubility (mol/L)\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "tight_layout"
          ],
          "code_str": "plt.tight_layout",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.tight_layout"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "floor"
          ],
          "code_str": "np.floor",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.floor"
        },
        {
          "import_components": [
            "numpy",
            "ceil"
          ],
          "code_str": "np.ceil",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.ceil"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones_like"
          ],
          "code_str": "np.ones_like",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.ones_like"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Plot-the-regression-line",
        "headings": [
          "Linear Regression",
          "Analytical solution",
          "Plot the regression line"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "lr = 1e-6\n\ntheta_list = []\nloss_list = []\n# theta = np.random.randn(2, 1).reshape(-1, 1)\ntheta = np.array([0, 0]).reshape(-1, 1)\nn_epochs = 100\n\nfor _ in range(n_epochs):\n    theta_list.append(copy.deepcopy(theta))\n    y_pred = X @ theta\n    loss = np.mean((y_pred - Y).reshape(-1)**2)\n    loss_list.append(loss)\n    grad = 2*X.T @ (X @ theta - Y) / Y.shape[0]\n    theta = theta - lr * grad",
      "names": [
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "copy",
            "deepcopy"
          ],
          "code_str": "copy.deepcopy",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "copy.deepcopy"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Gradient-Descent",
        "headings": [
          "Linear Regression",
          "Gradient Descent"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(\"Final loss:\", loss_list[-1])",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Gradient-Descent",
        "headings": [
          "Linear Regression",
          "Gradient Descent"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(loss_list, c=\"blue\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Gradient-Descent",
        "headings": [
          "Linear Regression",
          "Gradient Descent"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n\nplt.tight_layout()\nax.scatter(X[:, -1], Y.reshape(-1), \\\n            s=15, marker='o', \\\n            facecolors='none', edgecolor=\"blue\")\n\nmin_X = np.min(X[:, -1])\nmax_X = np.max(X[:, -1])\nx_line = np.linspace(np.floor(min_X), np.ceil(max_X), 100)\nx_line = x_line.reshape(-1, 1)\nx_line = np.hstack([np.ones_like(x_line), x_line])\n\nline, = ax.plot([], [], color=\"orange\", label=\"\")\n\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"log solubility (mol/L)\")\n\nlegend = plt.legend(loc=\"upper right\")\n\ndef animate(i):\n    y_pred_line = x_line @ theta_list[i]\n    line.set_data(x_line[:, -1], y_pred_line)\n    line.set_label(f\"Epoch: {i}\")\n    legend = plt.legend()\n    return line, legend\n\n\nani = animation.FuncAnimation(f, animate, repeat=True, frames=len(theta_list), interval=100, blit=True)\n\nwriter = animation.PillowWriter(fps=10,\n                                metadata=dict(artist='Me'),\n                                bitrate=1800)\nani.save(\"theta_iteration.gif\", writer=writer)",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "tight_layout"
          ],
          "code_str": "plt.tight_layout",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.tight_layout"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "floor"
          ],
          "code_str": "np.floor",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.floor"
        },
        {
          "import_components": [
            "numpy",
            "ceil"
          ],
          "code_str": "np.ceil",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.ceil"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones_like"
          ],
          "code_str": "np.ones_like",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.ones_like"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        },
        {
          "import_components": [
            "matplotlib",
            "animation",
            "FuncAnimation"
          ],
          "code_str": "animation.FuncAnimation",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "matplotlib.animation.FuncAnimation"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "animation",
            "PillowWriter"
          ],
          "code_str": "animation.PillowWriter",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "matplotlib.animation.PillowWriter"
        },
        {
          "import_components": [
            "dict"
          ],
          "code_str": "dict",
          "lineno": 32,
          "end_lineno": 32,
          "context": "none",
          "resolved_location": "dict"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Plot-Iterative-Process",
        "headings": [
          "Linear Regression",
          "Gradient Descent",
          "Plot Iterative Process"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nnorm_mw = scaler.fit_transform(df[[\"Molecular Weight\"]].values)\nX = np.hstack([np.ones_like(norm_mw), norm_mw])",
      "names": [
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones_like"
          ],
          "code_str": "np.ones_like",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.ones_like"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Data-Normalization-in-Gradient-Descent",
        "headings": [
          "Linear Regression",
          "Data Normalization in Gradient Descent"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "lr = 1e-1\n\ntheta_list = []\nloss_list = []\n# theta = np.random.randn(2, 1).reshape(-1, 1)\ntheta = np.array([0, 0]).reshape(-1, 1)\nn_epochs = 20\n\nfor _ in range(n_epochs):\n    theta_list.append(copy.deepcopy(theta))\n    y_pred = X @ theta\n    loss = np.mean((y_pred - Y).reshape(-1)**2)\n    loss_list.append(loss)\n    grad = 2*X.T @ (X @ theta - Y) / Y.shape[0]\n    theta = theta - lr * grad",
      "names": [
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "copy",
            "deepcopy"
          ],
          "code_str": "copy.deepcopy",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "copy.deepcopy"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Data-Normalization-in-Gradient-Descent",
        "headings": [
          "Linear Regression",
          "Data Normalization in Gradient Descent"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(\"Final loss:\", loss_list[-1])",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Data-Normalization-in-Gradient-Descent",
        "headings": [
          "Linear Regression",
          "Data Normalization in Gradient Descent"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(loss_list, c=\"blue\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Plot-Training-Curve",
        "headings": [
          "Linear Regression",
          "Data Normalization in Gradient Descent",
          "Plot Training Curve"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def V(xx, yy):\n    losses = []\n    theta = np.hstack([xx.reshape(-1, 1), yy.reshape(-1, 1)])\n    for i in range(theta.shape[0]):\n        y_pred = X @ theta[i].reshape(-1, 1)\n        loss = np.mean((y_pred - Y).reshape(-1)**2)\n        losses.append(loss)\n    return np.array(losses)\n\n# calculate contour\nt1 = np.arange(-6, 2, 1e-1)\nt2 = np.arange(-4, 4, 1e-1)\nxx, yy = np.meshgrid(t1, t2)\nz = V(xx.ravel(), yy.ravel()).reshape(len(t2), -1)",
      "names": [
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Parameter-Contour",
        "headings": [
          "Linear Regression",
          "Data Normalization in Gradient Descent",
          "Parameter Contour"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig,ax = plt.subplots(1,1,figsize=(5,5))\n\nn_levels = 75\nc = ax.contourf(t1, t2, z, cmap='rainbow', levels=n_levels, zorder=1)\nax.contour(t1,t2, z, levels=n_levels, zorder=1, colors='black', alpha=0.2)\ncb = fig.colorbar(c)\ncb.set_label(\"Loss\")\n\nr=0.1\ng=0.1\nb=0.2\nax.patch.set_facecolor((r,g,b,.15))\n\n\n# plot trajectory\nfor i in range(len(theta_list)-1):\n    plt.quiver(theta_list[i][0], theta_list[i][1], # from point\n               theta_list[i+1][0]-theta_list[i][0],  theta_list[i+1][1]-theta_list[i][1], # to point:\n               angles=\"xy\", scale_units=\"xy\", scale=1, color=\"black\",\n               linewidth=1.5)\n\n\nax.set_xlabel(r'$\\theta_0$')\nax.set_ylabel(r'$\\theta_1$')",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Parameter-Contour",
        "headings": [
          "Linear Regression",
          "Data Normalization in Gradient Descent",
          "Parameter Contour"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "lr = 1e-1\n\ntheta_list = []\nloss_list = []\ntheta = np.array([0, 0]).reshape(-1, 1)\nn_epochs = 100\nbatch_size = 32 # change the batch size here\n\nfor _ in range(n_epochs):\n    indices = np.random.choice(X.shape[0], batch_size, replace=False)\n    theta_list.append(copy.deepcopy(theta))\n    y_pred = X[indices, :] @ theta\n    y_true = Y[indices]\n    loss = np.mean((y_pred - y_true).reshape(-1)**2)\n    loss_list.append(loss)\n    grad = 2*X[indices, :].T @ (y_pred - y_true) / len(indices)\n    theta = theta - lr * grad",
      "names": [
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "choice"
          ],
          "code_str": "np.random.choice",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.random.choice"
        },
        {
          "import_components": [
            "copy",
            "deepcopy"
          ],
          "code_str": "copy.deepcopy",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "copy.deepcopy"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Stochastic-Gradient-Descent-and-Mini-batching",
        "headings": [
          "Linear Regression",
          "Stochastic Gradient Descent and Mini-batching"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(\"Final loss:\", pd.Series(loss_list).rolling(5).mean().iloc[-1])",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "pandas",
            "Series"
          ],
          "code_str": "pd.Series",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "pandas.Series"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Stochastic-Gradient-Descent-and-Mini-batching",
        "headings": [
          "Linear Regression",
          "Stochastic Gradient Descent and Mini-batching"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(loss_list, c=\"blue\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "Plot-Training-CUrve",
        "headings": [
          "Linear Regression",
          "Stochastic Gradient Descent and Mini-batching",
          "Plot Training CUrve"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def V(xx, yy):\n    losses = []\n    theta = np.hstack([xx.reshape(-1, 1), yy.reshape(-1, 1)])\n    for i in range(theta.shape[0]):\n        y_pred = X @ theta[i].reshape(-1, 1)\n        loss = np.mean((y_pred - Y).reshape(-1)**2)\n        losses.append(loss)\n    return np.array(losses)\n\n# calculate contour\nregion = np.stack(theta_list)\n\nt1 = np.arange(-6, 2, 1e-1)\nt2 = np.arange(-4, 4, 1e-1)\nxx, yy = np.meshgrid(t1, t2)\nz = V(xx.ravel(), yy.ravel()).reshape(len(t2), -1)",
      "names": [
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "stack"
          ],
          "code_str": "np.stack",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.stack"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "id2",
        "headings": [
          "Linear Regression",
          "Stochastic Gradient Descent and Mini-batching",
          "Parameter Contour"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig,ax = plt.subplots(1,1,figsize=(5,5))\n\n# z = np.ma.masked_greater(z, 10)\nn_levels = 75\nc = ax.contourf(t1, t2, z, cmap='rainbow', levels=n_levels, zorder=1)\nax.contour(t1,t2, z, levels=n_levels, zorder=1, colors='black', alpha=0.2)\ncb = fig.colorbar(c)\ncb.set_label(\"Loss\")\n\nr=0.1\ng=0.1\nb=0.2\nax.patch.set_facecolor((r,g,b,.15))\n\n\n# plot trajectory\n\nfor i in range(50):\n    plt.quiver(theta_list[i][0], theta_list[i][1], # from point\n               theta_list[i+1][0]-theta_list[i][0],  theta_list[i+1][1]-theta_list[i][1], # to point:\n               angles=\"xy\", scale_units=\"xy\", scale=1, color=\"black\",\n               linewidth=1.5)\n\n\nax.set_xlabel(r'$\\theta_0$')\nax.set_ylabel(r'$\\theta_1$')",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_linear_regression",
        "ref_id": "id2",
        "headings": [
          "Linear Regression",
          "Stochastic Gradient Descent and Mini-batching",
          "Parameter Contour"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/linear_models/Reference_Ch4_Part_1_logistic_regression": [
    {
      "source": "!pip install wget",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    },
    {
      "source": "import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt",
      "names": [
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_from",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "pyplot",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": "Logistic-regression",
        "headings": [
          "Logistic regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget https://raw.githubusercontent.com/xuhuihuang/uwmadisonchem361/refs/heads/main/delaney_dataset_200compounds.csv \\\n--output delaney_dataset_200compounds.csv\n\n!python -m wget https://raw.githubusercontent.com/xuhuihuang/uwmadisonchem361/refs/heads/main/delaney_dataset_40compounds.csv \\\n--output delaney_dataset_40compounds.csv\n\n!python -m wget https://raw.githubusercontent.com/xuhuihuang/uwmadisonchem361/refs/heads/main/delaney_dataset_44compounds_with_outliers.csv \\\n--output delaney_dataset_44compounds_with_outliers.csv",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": "Download-Datasets",
        "headings": [
          "Logistic regression",
          "Download Datasets"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "df = pd.read_csv('delaney_dataset_40compounds.csv')\ndf.head(2)",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": "Load-the-curated-Delaney-dataset,-which-contains-40-compounds:",
        "headings": [
          "Logistic regression",
          "Download Datasets",
          "Load the curated Delaney dataset, which contains 40 compounds:"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "data = df.iloc[:].values",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": "Load-the-curated-Delaney-dataset,-which-contains-40-compounds:",
        "headings": [
          "Logistic regression",
          "Download Datasets",
          "Load the curated Delaney dataset, which contains 40 compounds:"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# data with Molecular Weight and Polar Surface Are as features.\nX = data[:,0:2]\n\n# solubility labels\ny = data[:,3].astype(int)",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "int"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": "Load-the-curated-Delaney-dataset,-which-contains-40-compounds:",
        "headings": [
          "Logistic regression",
          "Download Datasets",
          "Load the curated Delaney dataset, which contains 40 compounds:"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1,1,figsize=(3,3))\n\nax.scatter(X[np.where(y==1)[0],0],X[np.where(y==1)[0],1],s=25, marker='o', facecolors='none', edgecolor=\"blue\", label='soluble')\nax.scatter(X[np.where(y==-1)[0],0],X[np.where(y==-1)[0],1],s=50, marker='X', color='red',linewidths=0.1, label='non-soluble')\n\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"Polar Surface Area\")\n\nax.set_xlim(80,300)\nax.set_ylim(-20,120)\n\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": "visualize-the-40-compounds",
        "headings": [
          "Logistic regression",
          "Download Datasets",
          "visualize the 40 compounds"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# plot the decision boundary\ndef predict_boundary(x,regressor):\n    y = [(- regressor.coef_[0][0]*x[i] - regressor.intercept_)/(regressor.coef_[0][1]) for i in range(len(x))]\n    return y\n\n# coef_: Coefficient of the features in the decision function.\n# coef_: Shape of (1, n_features) for binary classification - \\theta_1 and \\theta_2\n# intercept_: \\thetha_0\n# Decision boundary line with x in the range of [80, 300].\n# Decison line: p=0, so that y (polar surface) = [(-\\theta_1*x (molecualr weight) - \\theta_0)/\\theta_1",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": "Fit-a-logistic-regression-model-using-sklearn",
        "headings": [
          "Logistic regression",
          "Download Datasets",
          "Fit a logistic regression model using sklearn"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.linear_model import LogisticRegression\n\nregressor = LogisticRegression(random_state=0,penalty=None).fit(X, y)",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": "Fit-a-logistic-regression-model-using-sklearn",
        "headings": [
          "Logistic regression",
          "Download Datasets",
          "Fit a logistic regression model using sklearn"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1,1,figsize=(3,3))\n\nax.plot(\n    [80,300],\n    predict_boundary([80,300],regressor=regressor),\n    linewidth=1,\n    color=\"tab:purple\",\n    label=\"Decision boundary\",\n)\n\nax.scatter(X[np.where(y==1)[0],0],X[np.where(y==1)[0],1],s=25, marker='o', facecolors='none', edgecolor=\"blue\", label='soluble')\nax.scatter(X[np.where(y==-1)[0],0],X[np.where(y==-1)[0],1],s=50, marker='X', color='red',linewidths=0.1, label='non-soluble')\n\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"Polar Surface Area\")\n\nax.set_xlim(80,300)\nax.set_ylim(-20,120)\n\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": "Fit-a-logistic-regression-model-using-sklearn",
        "headings": [
          "Logistic regression",
          "Download Datasets",
          "Fit a logistic regression model using sklearn"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "df = pd.read_csv('delaney_dataset_44compounds_with_outliers.csv')\ndf.head(2)\n\ndata = df.iloc[:].values\n\n# data with Molecular Weight and Polar Surface Are as features.\nX = data[:,0:2]\n\n# solubility labels\ny = data[:,3].astype(int)",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "int"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": "Logistic-regression-is-robust-to-outliers",
        "headings": [
          "Logistic regression",
          "Download Datasets",
          "Logistic regression is robust to outliers"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1,1,figsize=(3,3))\n\nax.scatter(X[np.where(y==1)[0],0],X[np.where(y==1)[0],1],s=25, marker='o', facecolors='none', edgecolor=\"blue\", label='soluble')\nax.scatter(X[np.where(y==-1)[0],0],X[np.where(y==-1)[0],1],s=50, marker='X', color='red',linewidths=0.1, label='non-soluble')\n\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"Polar Surface Area\")\n\nax.set_xlim(80,560)\nax.set_ylim(-20,120)\n\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": "Logistic-regression-is-robust-to-outliers",
        "headings": [
          "Logistic regression",
          "Download Datasets",
          "Logistic regression is robust to outliers"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.linear_model import LogisticRegression\n\nregressor = LogisticRegression(random_state=0,penalty=None).fit(X, y)",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": "Logistic-regression-is-robust-to-outliers",
        "headings": [
          "Logistic regression",
          "Download Datasets",
          "Logistic regression is robust to outliers"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1,1,figsize=(3,3))\n\nax.plot(\n    [80,560],\n    predict_boundary([80,560],regressor=regressor),\n    linewidth=1,\n    color=\"tab:purple\",\n    label=\"predicted boundary\",\n)\n\nax.scatter(X[np.where(y==1)[0],0],X[np.where(y==1)[0],1],s=25, marker='o', facecolors='none', edgecolor=\"blue\", label='soluble')\nax.scatter(X[np.where(y==-1)[0],0],X[np.where(y==-1)[0],1],s=50, marker='X', color='red',linewidths=0.1, label='non-soluble')\n\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"Polar Surface Area\")\n\nax.set_xlim(80,560)\nax.set_ylim(-20,120)\n\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_logistic_regression",
        "ref_id": "Logistic-regression-is-robust-to-outliers",
        "headings": [
          "Logistic regression",
          "Download Datasets",
          "Logistic regression is robust to outliers"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization": [
    {
      "source": "!pip install wget",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    },
    {
      "source": "import copy\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nmpl.rcParams[\"font.size\"] = 20\nmpl.rcParams[\"lines.linewidth\"] = 2\n\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\n\ndef seed_all(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n\n# for the purpose of reproduce\nSEED = 0\nseed_all(SEED)",
      "names": [
        {
          "import_components": [
            "copy"
          ],
          "code_str": "copy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "copy"
        },
        {
          "import_components": [
            "random"
          ],
          "code_str": "random",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "random"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "random",
            "seed"
          ],
          "code_str": "random.seed",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "random.seed"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "seed"
          ],
          "code_str": "np.random.seed",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "numpy.random.seed"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "Avoid-Overfitting-using-Regularization",
        "headings": [
          "Avoid Overfitting using Regularization"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv \\\n    --output delaney-processed.csv",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "Load-Dataset",
        "headings": [
          "Avoid Overfitting using Regularization",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "DELANEY_FILE = \"delaney-processed.csv\"\nTASK_COL = 'measured log solubility in mols per litre'\ndf = pd.read_csv(DELANEY_FILE)\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "Load-Dataset",
        "headings": [
          "Avoid Overfitting using Regularization",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "df",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "Load-Dataset",
        "headings": [
          "Avoid Overfitting using Regularization",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "X = df[[\"Molecular Weight\", \"Number of H-Bond Donors\", \"Number of Rings\", \"Number of Rotatable Bonds\"]].values\ny = df[TASK_COL].values.reshape(-1, 1)",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Avoid Overfitting using Regularization",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "test_size = int(len(X)*0.1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True)",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Avoid Overfitting using Regularization",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def run_gd(X_train, y_train, X_test, y_test, lr, M,\n           n_epochs=20, normalize=True, norm=None,\n           lamda=1, init=\"zero\", return_mse=True):\n    assert init in [\"zero\", \"random\"]\n    theta_list = []\n    loss_list = []\n    loss_test_list = []\n    if return_mse:\n        mse_list = []\n        mse_test_list = []\n\n    poly_features = PolynomialFeatures(degree=M)\n    X_train_poly = poly_features.fit_transform(X_train)\n    X_test_poly = poly_features.fit_transform(X_test)\n\n    if normalize:\n        scaler = StandardScaler()\n        X_train_poly = scaler.fit_transform(X_train_poly)\n        X_test_poly = scaler.transform(X_test_poly)\n    else:\n        scaler = None\n\n    X_train_poly = np.hstack([np.ones((X_train_poly.shape[0], 1)), X_train_poly])\n    X_test_poly = np.hstack([np.ones((X_test_poly.shape[0], 1)), X_test_poly])\n\n    if init == \"zero\":\n        theta = np.zeros(X_train_poly.shape[1]).reshape(-1, 1)\n    else:\n        theta = np.random.randn(X_train_poly.shape[1]).reshape(-1, 1)\n\n    # gd fit\n    for _ in range(n_epochs):\n        theta_list.append(copy.deepcopy(theta))\n\n        y_pred = X_train_poly @ theta\n        loss = np.mean((y_pred - y_train).reshape(-1)**2)\n        if return_mse:\n            mse_list.append(loss)\n        if norm is None:\n            loss = loss\n        elif norm == \"l1\":\n            loss += lamda*np.sum(np.abs(theta))\n        elif norm == \"l2\":\n            loss += lamda*np.sum(theta**2)\n        else:\n            NotImplementedError(f\"Norm {norm} is not valid normalization method\")\n        loss_list.append(loss)\n        grad = 2*X_train_poly.T @ (X_train_poly @ theta - y_train) / y_train.shape[0]\n        if norm is None:\n            grad = grad\n        elif norm == \"l1\":\n            grad += lamda*np.sign(theta)\n        elif norm == \"l2\":\n            grad += lamda*2*theta\n        else:\n            raise NotImplementedError(f\"Norm {norm} is not valid normalization method\")\n\n        theta = theta - lr * grad\n\n        # predict and calculate rmse of test dataset\n        y_test_pred = X_test_poly @ theta\n        loss_test = np.mean((y_test_pred-y_test).reshape(-1)**2)\n        if return_mse:\n            mse_test_list.append(loss_test)\n        if norm is None:\n            loss_test = loss_test\n        elif norm == \"l1\":\n            loss_test += lamda*np.sum(np.abs(theta))\n        elif norm == \"l2\":\n            loss_test += lamda*np.sum(theta**2)\n        else:\n            NotImplementedError(f\"Norm {norm} is not valid normalization method\")\n        loss_test_list.append(loss_test)\n    if return_mse:\n        return theta_list, mse_list, mse_test_list, scaler\n    else:\n        return theta_list, loss_list, loss_test_list, scaler",
      "names": [
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones"
          ],
          "code_str": "np.ones",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "numpy.ones"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones"
          ],
          "code_str": "np.ones",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "numpy.ones"
        },
        {
          "import_components": [
            "numpy",
            "zeros"
          ],
          "code_str": "np.zeros",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "numpy.zeros"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "randn"
          ],
          "code_str": "np.random.randn",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "numpy.random.randn"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 32,
          "end_lineno": 32,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "copy",
            "deepcopy"
          ],
          "code_str": "copy.deepcopy",
          "lineno": 33,
          "end_lineno": 33,
          "context": "none",
          "resolved_location": "copy.deepcopy"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 36,
          "end_lineno": 36,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 42,
          "end_lineno": 42,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 44,
          "end_lineno": 44,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "NotImplementedError"
          ],
          "code_str": "NotImplementedError",
          "lineno": 46,
          "end_lineno": 46,
          "context": "none",
          "resolved_location": "NotImplementedError"
        },
        {
          "import_components": [
            "numpy",
            "sign"
          ],
          "code_str": "np.sign",
          "lineno": 52,
          "end_lineno": 52,
          "context": "none",
          "resolved_location": "numpy.sign"
        },
        {
          "import_components": [
            "NotImplementedError"
          ],
          "code_str": "NotImplementedError",
          "lineno": 56,
          "end_lineno": 56,
          "context": "none",
          "resolved_location": "NotImplementedError"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 62,
          "end_lineno": 62,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 68,
          "end_lineno": 68,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 70,
          "end_lineno": 70,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "NotImplementedError"
          ],
          "code_str": "NotImplementedError",
          "lineno": 72,
          "end_lineno": 72,
          "context": "none",
          "resolved_location": "NotImplementedError"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Avoid Overfitting using Regularization",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "lr = 5e-3\nn_epochs = 1500\nnormalize = True\nnorm = None # regularization in GD\n\norders = [0, 1, 2, 3, 4, 5]\nresults = {}\n\nfor idx, M in enumerate(orders):\n    theta_list, loss_list, loss_test_list, scaler = run_gd(X_train, y_train, X_test, y_test, lr, M, n_epochs, normalize)\n    results[M] = (theta_list, loss_list, loss_test_list, scaler)",
      "names": [
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "enumerate"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "Without-Regularization",
        "headings": [
          "Avoid Overfitting using Regularization",
          "Without Regularization"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.plot(orders, [results[M][1][-1] for M in orders], \"-\", color=\"b\",\n         marker=\"o\", markersize=10, markerfacecolor=\"none\", markeredgecolor=\"b\", label=\"Training\")\nplt.plot(orders, [results[M][2][-1] for M in orders], \"-\", color=\"r\",\n         marker=\"o\", markersize=10, markerfacecolor=\"none\", markeredgecolor=\"r\", label=\"Test\")\nplt.xlabel(\"Polynomial Order\")\nplt.ylabel(\"Error (MSE)\")\nplt.xticks(orders)\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xticks"
          ],
          "code_str": "plt.xticks",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xticks"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "Without-Regularization",
        "headings": [
          "Avoid Overfitting using Regularization",
          "Without Regularization"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "M = orders[-1]\ntheta_list, loss_list, loss_test_list, scaler = results[M]\n\nf, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(loss_list, c=\"blue\", label=\"Training\")\nax.plot(loss_test_list, c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Error (MSE)\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "Without-Regularization",
        "headings": [
          "Avoid Overfitting using Regularization",
          "Without Regularization"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "normalize = True\nnorm = \"l2\" # regularization in GD\nlamda = 1\n\nresults = {}\n\n\nfor idx, M in enumerate(orders):\n    theta_list, loss_list, loss_test_list, scaler = run_gd(X_train, y_train, X_test, y_test,\n                                                           lr, M, n_epochs, normalize, norm=norm, lamda=lamda)\n    results[M] = (theta_list, loss_list, loss_test_list, scaler)",
      "names": [
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "enumerate"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "L2-Norm",
        "headings": [
          "Avoid Overfitting using Regularization",
          "L2 Norm"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.plot(orders, [results[M][1][-1] for M in orders], \"-\", color=\"b\",\n         marker=\"o\", markersize=10, markerfacecolor=\"none\", markeredgecolor=\"b\", label=\"Training\")\nplt.plot(orders, [results[M][2][-1] for M in orders], \"-\", color=\"r\",\n         marker=\"o\", markersize=10, markerfacecolor=\"none\", markeredgecolor=\"r\", label=\"Test\")\nplt.xlabel(\"Polynomial Order\")\nplt.ylabel(\"Loss\")\nplt.xticks(orders)\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xticks"
          ],
          "code_str": "plt.xticks",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xticks"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "L2-Norm",
        "headings": [
          "Avoid Overfitting using Regularization",
          "L2 Norm"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "M = orders[-1]\ntheta_list, loss_list, loss_test_list, scaler = results[M]\n\nf, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(loss_list, c=\"blue\", label=\"Training\")\nax.plot(loss_test_list, c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "L2-Norm",
        "headings": [
          "Avoid Overfitting using Regularization",
          "L2 Norm"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "normalize = True\nnorm = \"l1\" # regularization in GD\nlamda = 1\n\nresults = {}\n\nfor idx, M in enumerate(orders):\n    theta_list, loss_list, loss_test_list, scaler = run_gd(X_train, y_train, X_test, y_test,\n                                                           lr, M, n_epochs, normalize, norm=norm, lamda=lamda)\n    results[M] = (theta_list, loss_list, loss_test_list, scaler)",
      "names": [
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "enumerate"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "L1-Norm",
        "headings": [
          "Avoid Overfitting using Regularization",
          "L1 Norm"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.plot(orders, [results[M][1][-1] for M in orders], \"-\", color=\"b\",\n         marker=\"o\", markersize=10, markerfacecolor=\"none\", markeredgecolor=\"b\", label=\"Training\")\nplt.plot(orders, [results[M][2][-1] for M in orders], \"-\", color=\"r\",\n         marker=\"o\", markersize=10, markerfacecolor=\"none\", markeredgecolor=\"r\", label=\"Test\")\nplt.xlabel(\"Polynomial Order\")\nplt.ylabel(\"Loss\")\nplt.xticks(orders)\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xticks"
          ],
          "code_str": "plt.xticks",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xticks"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "L1-Norm",
        "headings": [
          "Avoid Overfitting using Regularization",
          "L1 Norm"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "M = orders[-1]\ntheta_list, loss_list, loss_test_list, scaler = results[M]\n\nf, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(loss_list, c=\"blue\", label=\"Training\")\nax.plot(loss_test_list, c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_add_regularization",
        "ref_id": "L1-Norm",
        "headings": [
          "Avoid Overfitting using Regularization",
          "L1 Norm"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_and_cross_validation": [
    {
      "source": "!pip install wget",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_and_cross_validation",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    },
    {
      "source": "import random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nmpl.rcParams[\"font.size\"] = 20\nmpl.rcParams[\"lines.linewidth\"] = 2\n\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\n\ndef seed_all(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n\n# for the purpose of reproduce\nSEED = 0\nseed_all(SEED)",
      "names": [
        {
          "import_components": [
            "random"
          ],
          "code_str": "random",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "random"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "random",
            "seed"
          ],
          "code_str": "random.seed",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "random.seed"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "seed"
          ],
          "code_str": "np.random.seed",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "numpy.random.seed"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_and_cross_validation",
        "ref_id": "Overfitting-and-Cross-Validation",
        "headings": [
          "Overfitting and Cross-Validation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv \\\n    --output delaney-processed.csv",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_and_cross_validation",
        "ref_id": "Load-Dataset",
        "headings": [
          "Overfitting and Cross-Validation",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "DELANEY_FILE = \"delaney-processed.csv\"\nTASK_COL = 'measured log solubility in mols per litre'\ndf = pd.read_csv(DELANEY_FILE)\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_and_cross_validation",
        "ref_id": "Load-Dataset",
        "headings": [
          "Overfitting and Cross-Validation",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "X = df[\"Molecular Weight\"].values\ny = df[TASK_COL].values",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_and_cross_validation",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Overfitting and Cross-Validation",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# do 90:10 train:test split\ntest_size = int(len(X)*0.1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_and_cross_validation",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Overfitting and Cross-Validation",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "orders = [0, 1, 5, 10]\nmse_train_list = []\n\nncols = 2\nnrows = len(orders)//ncols if len(orders)%ncols==0 else len(orders)//ncols+1\nfig, axs = plt.subplots(nrows, ncols, figsize=(5*ncols, 5*nrows))\naxs = axs.flatten()\nfig.tight_layout()\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, wspace=0.5, hspace=0.5)\n\nfor idx, M in enumerate(orders):\n    # use numpy polynomial fitting\n    # Use klearn PolynomialFeature+LinearRegression will not cause dramatic overfitting when M=subsamples-1\n    p = np.poly1d(np.polyfit(X_train.reshape(-1), y_train.reshape(-1), M))\n\n    y_train_pred = p(X_train)\n    mse_train = np.mean((y_train_pred-y_train)**2)\n    mse_train_list.append(mse_train)\n\n    # plot sampled datapoints\n    ax = axs[idx]\n    ax.scatter(X_train, y_train,\n                s=50, marker='o', facecolors='none', edgecolor=\"blue\")\n\n    # plot fitting curve\n    x_lin = np.linspace(np.min(X), np.max(X), 100).reshape(-1, 1)\n    ax.plot(x_lin, p(x_lin), \"red\", label=f\"M={M}\")\n    ax.set_ylim(-10, 2)\n    ax.set_xlabel(\"Molecular Weight (Da.)\")\n    ax.set_ylabel(\"log solubility (mol/L)\")\n    ax.legend(loc=\"upper right\")",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots_adjust"
          ],
          "code_str": "plt.subplots_adjust",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots_adjust"
        },
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "enumerate"
        },
        {
          "import_components": [
            "numpy",
            "poly1d"
          ],
          "code_str": "np.poly1d",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.poly1d"
        },
        {
          "import_components": [
            "numpy",
            "polyfit"
          ],
          "code_str": "np.polyfit",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.polyfit"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "numpy.max"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_and_cross_validation",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Overfitting and Cross-Validation",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.plot(orders, mse_train_list, \"-\", color=\"b\",\n         marker=\"o\", markersize=10, markerfacecolor=\"none\", markeredgecolor=\"b\", label=\"Training\")\nplt.xlabel(\"Polynomial Order\")\nplt.ylabel(\"Error (MSE)\")\nplt.xticks(orders)\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xticks"
          ],
          "code_str": "plt.xticks",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xticks"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_and_cross_validation",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Overfitting and Cross-Validation",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "## scanning\nmse_train_list = []\nmse_test_list = []\n\nfor M in orders:\n    p = np.poly1d(np.polyfit(X_train, y_train, M))\n\n\n    # predict and calculate rmse of training dataset\n    y_train_pred = p(X_train)\n    mse_train = np.mean((y_train_pred-y_train)**2)\n    mse_train_list.append(mse_train)\n\n    # predict and calculate rmse of test dataset\n    y_test_pred = p(X_test)\n    mse_test = np.mean((y_test_pred-y_test)**2)\n    mse_test_list.append(mse_test)\n\nplt.figure(figsize=(5, 5))\nplt.plot(orders, mse_train_list, \"-\", color=\"b\",\n         marker=\"o\", markersize=10, markerfacecolor=\"none\", markeredgecolor=\"b\", label=\"Training\")\nplt.plot(orders, mse_test_list, \"-\", color=\"r\",\n         marker=\"o\", markersize=10, markerfacecolor=\"none\", markeredgecolor=\"r\", label=\"Test\")\nplt.xlabel(\"Polynomial Order\")\nplt.ylabel(\"Error (MSE)\")\nplt.ylim([2, 5])\nplt.xticks(orders)\nplt.legend()",
      "names": [
        {
          "import_components": [
            "numpy",
            "poly1d"
          ],
          "code_str": "np.poly1d",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.poly1d"
        },
        {
          "import_components": [
            "numpy",
            "polyfit"
          ],
          "code_str": "np.polyfit",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.polyfit"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xticks"
          ],
          "code_str": "plt.xticks",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xticks"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_and_cross_validation",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Overfitting and Cross-Validation",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def run_one_fold(X_train, y_train, X_test, y_test, M):\n    p = np.poly1d(np.polyfit(X_train, y_train, M))\n    # predict and calculate rmse of training dataset\n    y_train_pred = p(X_train)\n    mse_train = np.mean((y_train_pred-y_train)**2)\n\n    # predict and calculate rmse of test dataset\n    y_test_pred = p(X_test)\n    mse_test = np.mean((y_test_pred-y_test)**2)\n    return mse_train, mse_test",
      "names": [
        {
          "import_components": [
            "numpy",
            "poly1d"
          ],
          "code_str": "np.poly1d",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.poly1d"
        },
        {
          "import_components": [
            "numpy",
            "polyfit"
          ],
          "code_str": "np.polyfit",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.polyfit"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_and_cross_validation",
        "ref_id": "Cross-Validation",
        "headings": [
          "Overfitting and Cross-Validation",
          "Cross Validation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "## 10-fold\nn_splits = 10\n\nmse_train_list = []\nstd_train_list = []\nmse_test_list = []\nstd_test_list = []\n\ncv_df = pd.DataFrame(columns=[\"M\", \"MSE_train\", \"MSE_test\"])\n\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\nfor M in orders:\n    mse_train_fold = []\n    mse_test_fold = []\n\n    for train_index, test_index in kf.split(X):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n\n        mse_train, mse_test = run_one_fold(X_train, y_train, X_test, y_test, M)\n        mse_train_fold.append(mse_train)\n        mse_test_fold.append(mse_test)\n\n    mse_train_list.append(np.mean(mse_train_fold))\n    std_train_list.append(np.std(mse_train_fold))\n    mse_test_list.append(np.mean(mse_test_fold))\n    std_test_list.append(np.std(mse_test_fold))",
      "names": [
        {
          "import_components": [
            "pandas",
            "DataFrame"
          ],
          "code_str": "pd.DataFrame",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "pandas.DataFrame"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.std"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_and_cross_validation",
        "ref_id": "Cross-Validation",
        "headings": [
          "Overfitting and Cross-Validation",
          "Cross Validation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.errorbar(orders, mse_train_list, yerr=std_train_list, color=\"b\", \\\n    marker=\"o\", markersize=10, markerfacecolor=\"none\", markeredgecolor=\"b\",\n    capsize=5, label=\"Training\")\nplt.errorbar(orders, mse_test_list, yerr=std_test_list, color=\"r\", \\\n    marker=\"o\", markersize=10, markerfacecolor=\"none\", markeredgecolor=\"r\",\n    capsize=5, label=\"Test\")\nplt.xlabel(\"Polynomial Order\")\nplt.ylabel(\"Error (MSE)\")\nplt.xticks(orders)\nplt.ylim([0, 5])\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "errorbar"
          ],
          "code_str": "plt.errorbar",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.errorbar"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "errorbar"
          ],
          "code_str": "plt.errorbar",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.errorbar"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xticks"
          ],
          "code_str": "plt.xticks",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xticks"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_polynomial_fitting_overfitting_and_cross_validation",
        "ref_id": "Cross-Validation",
        "headings": [
          "Overfitting and Cross-Validation",
          "Cross Validation"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained": [
    {
      "source": "!pip install wget",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    },
    {
      "source": "import copy\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nmpl.rcParams[\"font.size\"] = 20\nmpl.rcParams[\"lines.linewidth\"] = 2\n\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n\ndef seed_all(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n\n# for the purpose of reproduce\nSEED = 0\nseed_all(SEED)",
      "names": [
        {
          "import_components": [
            "copy"
          ],
          "code_str": "copy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "copy"
        },
        {
          "import_components": [
            "random"
          ],
          "code_str": "random",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "random"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "random",
            "seed"
          ],
          "code_str": "random.seed",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "random.seed"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "seed"
          ],
          "code_str": "np.random.seed",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "numpy.random.seed"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "Explain-Effect-of-Regularization-using-One-Feature",
        "headings": [
          "Explain Effect of Regularization using One Feature"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv \\\n    --output delaney-processed.csv",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "Load-Dataset",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "DELANEY_FILE = \"delaney-processed.csv\"\nTASK_COL = 'measured log solubility in mols per litre'\ndf = pd.read_csv(DELANEY_FILE)\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "Load-Dataset",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "X = df[\"Molecular Weight\"].values.reshape(-1, 1)\ny = df[TASK_COL].values.reshape(-1, 1)",
      "names": [],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# do 90:10 train:test split\ntest_size = int(len(X)*0.1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def run_gd(X_train, y_train, X_test, y_test, lr, M,\n           n_epochs = 20, normalize=True, norm=None, lamda=1):\n    theta_list = []\n    loss_list = []\n    loss_test_list = []\n\n    poly_features = PolynomialFeatures(degree=M)\n    X_train_poly = poly_features.fit_transform(X_train)\n    X_test_poly = poly_features.fit_transform(X_test)\n\n    if normalize:\n        scaler = StandardScaler()\n        X_train_poly = scaler.fit_transform(X_train_poly)\n        X_test_poly = scaler.transform(X_test_poly)\n    else:\n        scaler = None\n\n    X_train_poly = np.hstack([np.ones((X_train_poly.shape[0], 1)), X_train_poly])\n    X_test_poly = np.hstack([np.ones((X_test_poly.shape[0], 1)), X_test_poly])\n    theta = np.zeros(X_train_poly.shape[1]).reshape(-1, 1)\n    # theta = np.random.randn(X_train_poly.shape[1]).reshape(-1, 1)\n\n    # gd fit\n    for _ in range(n_epochs):\n        theta_list.append(copy.deepcopy(theta))\n\n        y_pred = X_train_poly @ theta\n        loss = np.mean((y_pred - y_train).reshape(-1)**2)\n        loss_list.append(loss)\n        grad = 2*X_train_poly.T @ (X_train_poly @ theta - y_train) / y_train.shape[0]\n        if norm is None:\n            grad = grad\n        elif norm == \"l1\":\n            grad += lamda*np.sign(theta)\n        elif norm == \"l2\":\n            grad += lamda*2*theta\n        else:\n            raise NotImplementedError(f\"Norm {norm} is not valid normalization method\")\n\n        theta = theta - lr * grad\n\n\n        # predict and calculate rmse of test dataset\n        y_test_pred = X_test_poly @ theta\n        loss_test = np.mean((y_test_pred-y_test)**2)\n        loss_test_list.append(loss_test)\n\n    return theta_list, loss_list, loss_test_list, scaler",
      "names": [
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones"
          ],
          "code_str": "np.ones",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "numpy.ones"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones"
          ],
          "code_str": "np.ones",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "numpy.ones"
        },
        {
          "import_components": [
            "numpy",
            "zeros"
          ],
          "code_str": "np.zeros",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "numpy.zeros"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "copy",
            "deepcopy"
          ],
          "code_str": "copy.deepcopy",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "copy.deepcopy"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "sign"
          ],
          "code_str": "np.sign",
          "lineno": 34,
          "end_lineno": 34,
          "context": "none",
          "resolved_location": "numpy.sign"
        },
        {
          "import_components": [
            "NotImplementedError"
          ],
          "code_str": "NotImplementedError",
          "lineno": 38,
          "end_lineno": 38,
          "context": "none",
          "resolved_location": "NotImplementedError"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 45,
          "end_lineno": 45,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "lr = 5e-2\nn_epochs = 50\nnormalize = True\nnorm = None # regularization in GD\n\n\norders = [0, 1, 5, 10]\nresults = {}\n\nncols = 4\nnrows = len(orders)//ncols if len(orders)%ncols==0 else len(orders)//ncols+1\nfig, axs = plt.subplots(nrows, ncols, figsize=(5*ncols, 5*nrows))\naxs = axs.flatten()\nfig.tight_layout()\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, wspace=0.5, hspace=0.5)\n\nfor idx, M in enumerate(orders):\n    theta_list, loss_list, loss_test_list, scaler = run_gd(X_train, y_train, X_test, y_test, lr, M, n_epochs, normalize)\n    results[M] = (theta_list, loss_list, loss_test_list, scaler)\n\n    # plot sampled datapoints\n    ax = axs[idx]\n    ax.scatter(X_train, y_train,\n                s=50, marker='o', facecolors='none', edgecolor=\"blue\")\n\n    # plot fitting curve\n    poly_features = PolynomialFeatures(degree=M)\n    x_lin = np.linspace(np.min(X), np.max(X), 100).reshape(-1, 1)\n    x_lin_poly = poly_features.fit_transform(x_lin)\n    if normalize:\n        x_lin_poly_norm = scaler.transform(x_lin_poly)\n    else:\n        x_lin_poly_norm = x_lin_poly\n    x_lin_poly_norm = np.hstack([np.ones((x_lin_poly_norm.shape[0], 1)), x_lin_poly_norm])\n    y_lin_pred = x_lin_poly_norm @ theta_list[-1]\n    ax.plot(x_lin.reshape(-1), y_lin_pred.reshape(-1), \"red\", label=f\"M={M}\")\n\n    ax.set_ylim(-10, 2)\n    # ax.set_xlabel(\"Molecular Weight\")\n    # ax.set_ylabel(\"log solubility (mol/L)\")\n    ax.legend(loc=\"upper right\")",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots_adjust"
          ],
          "code_str": "plt.subplots_adjust",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots_adjust"
        },
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "enumerate"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 34,
          "end_lineno": 34,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones"
          ],
          "code_str": "np.ones",
          "lineno": 34,
          "end_lineno": 34,
          "context": "none",
          "resolved_location": "numpy.ones"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(loss_list, c=\"blue\", label=\"Training\")\nax.plot(loss_test_list, c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def V(xx, yy, X_train, y_train, normalize=True):\n    losses = []\n    theta = np.hstack([xx.reshape(-1, 1), yy.reshape(-1, 1)])\n\n    if normalize:\n        scaler = StandardScaler()\n        X_train_norm = scaler.fit_transform(X_train)\n    else:\n        scaler = None\n    X_train_norm = np.hstack([np.ones((X_train_norm.shape[0], 1)), X_train_norm])\n\n    for i in range(theta.shape[0]):\n        y_pred = X_train_norm @ theta[i].reshape(-1, 1)\n        loss = np.mean((y_pred - y_train).reshape(-1)**2)\n        losses.append(loss)\n    return np.array(losses)",
      "names": [
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones"
          ],
          "code_str": "np.ones",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.ones"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.array"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "t1 = np.arange(-6, 2, 1e-1)\nt2 = np.arange(-4, 4, 1e-1)\nxx, yy = np.meshgrid(t1, t2)\nz = V(xx.ravel(), yy.ravel(), X_train, y_train).reshape(len(t2), -1)\n\n\nfig,ax = plt.subplots(1,1,figsize=(5,5))\n\n# z = np.ma.masked_greater(z, 10)\nn_levels = 75\nc = ax.contourf(t1, t2, z, cmap='rainbow', levels=n_levels, zorder=1)\nax.contour(t1,t2, z, levels=n_levels, zorder=1, colors='black', alpha=0.2)\ncb = fig.colorbar(c)\ncb.set_label(\"Loss\")\n\nr=0.1\ng=0.1\nb=0.2\nax.patch.set_facecolor((r,g,b,.15))\n\n\n# plot trajectory\ntheta_list = results[1][0]\nfor i in range(len(theta_list)-1):\n    from_point = (theta_list[i][0], theta_list[i][-1])\n    to_point = (theta_list[i+1][0], theta_list[i+1][-1])\n    plt.quiver(from_point[0], from_point[1], # from point\n               to_point[0]-from_point[0], to_point[1]-from_point[1], # to point\n               angles=\"xy\", scale_units=\"xy\", scale=1, color=\"black\",\n               linewidth=1.5)\n\nax.set_xlabel(r'$\\theta_0$')\nax.set_ylabel(r'$\\theta_1$')\nax.set_aspect(\"equal\")",
      "names": [
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "Polynomial-Fitting",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "Polynomial Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "lr = 5e-2\nn_epochs = 50\nnormalize = True\nnorm = \"l2\" # regularization in GD\nlamda = 1\n\nresults = {}\n\nfig, axs = plt.subplots(nrows, ncols, figsize=(6*ncols, 6*nrows))\naxs = axs.flatten()\nfig.tight_layout()\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, wspace=0.5, hspace=0.5)\n\nfor idx, M in enumerate(orders):\n    theta_list, loss_list, loss_test_list, scaler = run_gd(X_train, y_train, X_test, y_test,\n                                                           lr, M, n_epochs, normalize, norm=norm, lamda=lamda)\n    results[M] = (theta_list, loss_list, loss_test_list, scaler)\n\n    # plot sampled datapoints\n    ax = axs[idx]\n    ax.scatter(X_train, y_train,\n                s=50, marker='o', facecolors='none', edgecolor=\"blue\")\n\n    # plot fitting curve\n    poly_features = PolynomialFeatures(degree=M)\n    x_lin = np.linspace(np.min(X), np.max(X), 100).reshape(-1, 1)\n    x_lin_poly = poly_features.fit_transform(x_lin)\n    if normalize:\n        x_lin_poly_norm = scaler.transform(x_lin_poly)\n    else:\n        x_lin_poly_norm = x_lin_poly\n    x_lin_poly_norm = np.hstack([np.ones((x_lin_poly_norm.shape[0], 1)), x_lin_poly_norm])\n    y_lin_pred = x_lin_poly_norm @ theta_list[-1]\n    ax.plot(x_lin.reshape(-1), y_lin_pred.reshape(-1), \"red\", label=f\"M={M}\")\n\n    ax.set_ylim(-10, 2)\n    # ax.set_xlabel(\"Normalized Molecular Weight\")\n    # ax.set_ylabel(\"log solubility (mol/L)\")\n    ax.legend(loc=\"upper right\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots_adjust"
          ],
          "code_str": "plt.subplots_adjust",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots_adjust"
        },
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "enumerate"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 32,
          "end_lineno": 32,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones"
          ],
          "code_str": "np.ones",
          "lineno": 32,
          "end_lineno": 32,
          "context": "none",
          "resolved_location": "numpy.ones"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "L2-Norm",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "L2 Norm"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(loss_list, c=\"blue\", label=\"Training\")\nax.plot(loss_test_list, c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "L2-Norm",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "L2 Norm"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def V(xx, yy, X_train, y_train, normalize=True, norm=None, lamda=1):\n    losses = []\n    theta = np.hstack([xx.reshape(-1, 1), yy.reshape(-1, 1)])\n\n    if normalize:\n        scaler = StandardScaler()\n        X_train_norm = scaler.fit_transform(X_train)\n    else:\n        scaler = None\n    X_train_norm = np.hstack([np.ones((X_train_norm.shape[0], 1)), X_train_norm])\n\n    for i in range(theta.shape[0]):\n        y_pred = X_train_norm @ theta[i].reshape(-1, 1)\n        loss = np.mean((y_pred - y_train).reshape(-1)**2)\n        if norm is None:\n            loss = loss\n        elif norm == \"l1\":\n            loss += lamda*np.sum(np.abs(theta[i]))\n        elif norm == \"l2\":\n            loss += lamda*np.sum(theta[i]**2)\n        else:\n            raise NotImplementedError(f\"Norm {norm} is not supported\")\n        losses.append(loss)\n    return np.array(losses)",
      "names": [
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones"
          ],
          "code_str": "np.ones",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.ones"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "NotImplementedError"
          ],
          "code_str": "NotImplementedError",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "NotImplementedError"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "numpy.array"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "L2-Norm",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "L2 Norm"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig,ax = plt.subplots(1,1,figsize=(5,5))\n\n# plot contour\nt1 = np.arange(-6, 2, 1e-1)\nt2 = np.arange(-4, 4, 1e-1)\nxx, yy = np.meshgrid(t1, t2)\nz = V(xx.ravel(), yy.ravel(), X_train, y_train, norm=None)\nz = z.reshape(len(t2), -1)\n\nn_levels = 75\nc = ax.contourf(t1, t2, z, cmap='rainbow', levels=n_levels, zorder=1)\nax.contour(t1,t2, z, levels=n_levels, zorder=1, colors='black', alpha=0.2)\ncb = fig.colorbar(c)\ncb.set_label(\"Loss\")\n\nr=0.1\ng=0.1\nb=0.2\nax.patch.set_facecolor((r,g,b,.15))\n\n\n# plot l2\nx = np.linspace(-6, 2, 100)\ny = np.linspace(-4, 4, 100)\nxx, yy = np.meshgrid(x, y)\nzz = np.sqrt(xx**2 + yy**2)\nmask = xx**2 + yy**2 > 4\nzz_masked = np.ma.masked_where(mask, zz)\nn_levels = 5\n# ax.contourf(xx, yy, zz_masked, levels=n_levels, zorder=1, alppha=0.2)\nax.contour(xx, yy, zz_masked, levels=n_levels,\n                     zorder=1, colors='black', alpha=0.5)\n\n# plot trajectory\ntheta_list = results[1][0]\nfor i in range(len(theta_list)-1):\n    from_point = (theta_list[i][0], theta_list[i][-1])\n    to_point = (theta_list[i+1][0], theta_list[i+1][-1])\n    plt.quiver(from_point[0], from_point[1], # from point\n               to_point[0]-from_point[0], to_point[1]-from_point[1], # to point\n               angles=\"xy\", scale_units=\"xy\", scale=1, color=\"black\",\n               linewidth=1.5)\n\nax.set_xlabel(r'$\\theta_0$')\nax.set_ylabel(r'$\\theta_1$')\nax.set_aspect(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "numpy",
            "ma",
            "masked_where"
          ],
          "code_str": "np.ma.masked_where",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.ma.masked_where"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 36,
          "end_lineno": 36,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 36,
          "end_lineno": 36,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 39,
          "end_lineno": 39,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "L2-Norm",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "L2 Norm"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "lr = 5e-2\nn_epochs = 50\nnormalize = True\nnorm = \"l1\" # regularization in GD\nlamda = 1\n\nresults = {}\n\nfig, axs = plt.subplots(nrows, ncols, figsize=(6*ncols, 6*nrows))\naxs = axs.flatten()\nplt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, wspace=0.5, hspace=0.5)\n\nfor idx, M in enumerate(orders):\n    theta_list, loss_list, loss_test_list, scaler = run_gd(X_train, y_train, X_test, y_test,\n                                                           lr, M, n_epochs, normalize, norm=norm, lamda=lamda)\n    results[M] = (theta_list, loss_list, loss_test_list, scaler)\n\n    # plot sampled datapoints\n    ax = axs[idx]\n    ax.scatter(X_train, y_train,\n                s=50, marker='o', facecolors='none', edgecolor=\"blue\")\n\n    # plot fitting curve\n    poly_features = PolynomialFeatures(degree=M)\n    x_lin = np.linspace(np.min(X), np.max(X), 100).reshape(-1, 1)\n    x_lin_poly = poly_features.fit_transform(x_lin)\n    if normalize:\n        x_lin_poly_norm = scaler.transform(x_lin_poly)\n    else:\n        x_lin_poly_norm = x_lin_poly\n    x_lin_poly_norm = np.hstack([np.ones((x_lin_poly_norm.shape[0], 1)), x_lin_poly_norm])\n    y_lin_pred = x_lin_poly_norm @ theta_list[-1]\n    ax.plot(x_lin.reshape(-1), y_lin_pred.reshape(-1), \"red\", label=f\"M={M}\")\n\n    ax.set_ylim(-10, 2)\n    # ax.set_xlabel(\"Normalized Molecular Weight\")\n    # ax.set_ylabel(\"log solubility (mol/L)\")\n    ax.legend(loc=\"upper right\")\n\nplt.tight_layout()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots_adjust"
          ],
          "code_str": "plt.subplots_adjust",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots_adjust"
        },
        {
          "import_components": [
            "enumerate"
          ],
          "code_str": "enumerate",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "enumerate"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones"
          ],
          "code_str": "np.ones",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "numpy.ones"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "tight_layout"
          ],
          "code_str": "plt.tight_layout",
          "lineno": 40,
          "end_lineno": 40,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.tight_layout"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "L1-Norm",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "L1 Norm"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(loss_list, c=\"blue\", label=\"Training\")\nax.plot(loss_test_list, c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "L1-Norm",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "L1 Norm"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def V(xx, yy, X_train, y_train, normalize=True, norm=None, lamda=1):\n    losses = []\n    theta = np.hstack([xx.reshape(-1, 1), yy.reshape(-1, 1)])\n\n    if normalize:\n        scaler = StandardScaler()\n        X_train_norm = scaler.fit_transform(X_train)\n    else:\n        scaler = None\n    X_train_norm = np.hstack([np.ones((X_train_norm.shape[0], 1)), X_train_norm])\n\n    for i in range(theta.shape[0]):\n        y_pred = X_train_norm @ theta[i].reshape(-1, 1)\n        loss = np.mean((y_pred - y_train).reshape(-1)**2)\n        if norm is None:\n            loss = loss\n        elif norm == \"l1\":\n            loss += lamda*np.sum(np.abs(theta[i]))\n        elif norm == \"l2\":\n            loss += lamda*np.sum(theta[i]**2)\n        else:\n            raise NotImplementedError(f\"Norm {norm} is not supported\")\n        losses.append(loss)\n    return np.array(losses)",
      "names": [
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones"
          ],
          "code_str": "np.ones",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.ones"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "NotImplementedError"
          ],
          "code_str": "NotImplementedError",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "NotImplementedError"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "numpy.array"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "L1-Norm",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "L1 Norm"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig,ax = plt.subplots(1,1,figsize=(5,5))\n\n# plot contour\nt1 = np.arange(-6, 2, 1e-1)\nt2 = np.arange(-4, 4, 1e-1)\nxx, yy = np.meshgrid(t1, t2)\nz = V(xx.ravel(), yy.ravel(), X_train, y_train, norm=None)\nz = z.reshape(len(t2), -1)\n\nn_levels = 75\nc = ax.contourf(t1, t2, z, cmap='rainbow', levels=n_levels, zorder=1)\nax.contour(t1,t2, z, levels=n_levels, zorder=1, colors='black', alpha=0.2)\ncb = fig.colorbar(c)\ncb.set_label(\"Loss\")\n\nr=0.1\ng=0.1\nb=0.2\nax.patch.set_facecolor((r,g,b,.15))\n\n\n# plot l2\nx = np.linspace(-6, 2, 100)\ny = np.linspace(-4, 4, 100)\nxx, yy = np.meshgrid(x, y)\nzz = np.abs(xx) + np.abs(yy)\nmask = np.abs(xx) + np.abs(yy) > 4\nzz_masked = np.ma.masked_where(mask, zz)\nn_levels = 5\nax.contour(xx, yy, zz_masked, levels=n_levels,\n                     zorder=1, colors='black', alpha=0.5)\n\n# plot trajectory\ntheta_list = results[1][0]\nfor i in range(len(theta_list)-1):\n    from_point = (theta_list[i][0], theta_list[i][-1])\n    to_point = (theta_list[i+1][0], theta_list[i+1][-1])\n    plt.quiver(from_point[0], from_point[1], # from point\n               to_point[0]-from_point[0], to_point[1]-from_point[1], # to point\n               angles=\"xy\", scale_units=\"xy\", scale=1, color=\"black\",\n               linewidth=1.5)\n\nax.set_xlabel(r'$\\theta_0$')\nax.set_ylabel(r'$\\theta_1$')\nax.set_aspect(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "numpy",
            "ma",
            "masked_where"
          ],
          "code_str": "np.ma.masked_where",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.ma.masked_where"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 35,
          "end_lineno": 35,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 35,
          "end_lineno": 35,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 38,
          "end_lineno": 38,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        }
      ],
      "example": {
        "document": "examples/linear_models/Reference_Ch4_Part_1_regularization_effect_explained",
        "ref_id": "L1-Norm",
        "headings": [
          "Explain Effect of Regularization using One Feature",
          "L1 Norm"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression": [
    {
      "source": "!pip install wget",
      "names": [],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    },
    {
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom sklearn.metrics import confusion_matrix\n\ncmap = plt.get_cmap('tab10')\ncolors = [cmap(i) for i in range(cmap.N)]\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", device)\n\n#import os\n#os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"",
      "names": [
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "colors"
          ],
          "code_str": "matplotlib.colors",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_from",
          "resolved_location": "matplotlib.colors"
        },
        {
          "import_components": [
            "matplotlib",
            "colors",
            "ListedColormap"
          ],
          "code_str": "ListedColormap",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib.colors.ListedColormap"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "get_cmap"
          ],
          "code_str": "plt.get_cmap",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.get_cmap"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Multi-class-Classification-Using-Softmax-Regression",
        "headings": [
          "Multi-class Classification Using Softmax Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv \\\n    --output delaney-processed.csv",
      "names": [],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Load-Dataset",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "DELANEY_FILE = \"delaney-processed.csv\"\nTASK_COL = 'measured log solubility in mols per litre'\ndf = pd.read_csv(DELANEY_FILE)\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Load-Dataset",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def assign_label(x):\n    if x >= -2:\n        return 0\n    elif x < -2 and x >= -4:\n        return 1\n    else:\n        return 2\n\ndf[\"soluble\"] = df[TASK_COL].apply(assign_label)\n\n\nn_class = 3\nX = df[[\n        \"Molecular Weight\",\n        \"Polar Surface Area\"]].values\nonehot = np.eye(n_class)\nY = df[\"soluble\"].values\nY_onehot = onehot[Y]\nY = Y_onehot\nprint(\"Shape of X:\", X.shape)\nprint(\"Shape of Y:\", Y.shape)",
      "names": [
        {
          "import_components": [
            "numpy",
            "eye"
          ],
          "code_str": "np.eye",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.eye"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Input-data",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Input data"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.bar(range(n_class), np.sum(Y, axis=0))\nplt.xticks(range(n_class), [r\"Soluble [-2, $\\inf$)\",\n                            \"Weakly Soluble [-4, -2)\",\n                            r\"Insoluble (-$\\inf$, -4)\"], rotation=60)",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "bar"
          ],
          "code_str": "plt.bar",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.bar"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.sum"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xticks"
          ],
          "code_str": "plt.xticks",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xticks"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Input-data",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Input data"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.model_selection import train_test_split\n\n# training/validation dataset\ntest_size = int(len(X)*0.1)\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, shuffle=True)\n\n# create dataloaders\nX_train, X_test, y_train, y_test = map(torch.tensor, (X_train, X_test, y_train, y_test))\nbatch_size = 128 #batch size in minibatch gradient descent\ntrain_data = torch.utils.data.TensorDataset(X_train, y_train)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n                                           shuffle=True, drop_last=False)\ntest_data = torch.utils.data.TensorDataset(X_test, y_test)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n                                          shuffle=False, drop_last=False)",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "map"
          ],
          "code_str": "map",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "map"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Input-data",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Input data"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# Define linear regression model\nclass LinearRegresion(torch.nn.Module):\n    def __init__(self, indim, outdim):\n        super(LinearRegresion, self).__init__()\n        self.norm = nn.BatchNorm1d(indim)\n        self.linear = torch.nn.Linear(indim, outdim)\n    def forward(self, x):\n        x = self.norm(x)\n        x = self.linear(x)\n        return x\n\ndef train_one_epcoh(model, criterion, optimizer, dataloader):\n    losses = []\n    model.train()\n    for x, y_true in dataloader:\n        if device == \"cuda\":\n            x, y_true = x.to(device), y_true.to(device)\n        x, y_true = x.float(), y_true.float()\n        optimizer.zero_grad()\n        y_pred = model(x) # we will choose linear regression model for forward propagation\n        y_pred = nn.Softmax(dim=-1)(y_pred)\n        loss = criterion(y_pred, y_true)\n        loss.backward() #backprogatation\n        optimizer.step() #backprogatation\n        losses.append(loss.cpu().detach().item())\n    return losses\n\n# no backpropagation in the validation/testing runs\ndef val_one_epcoh(model, criterion, dataloader):\n    losses = []\n    model.eval()\n    with torch.no_grad():\n        for x, y_true in dataloader:\n            if device == \"cuda\":\n                x, y_true = x.to(device), y_true.to(device)\n            x, y_true = x.float(), y_true.float()\n            y_pred = model(x)\n            y_pred = nn.Softmax(dim=-1)(y_pred)\n            loss = criterion(y_pred, y_true)\n            losses.append(loss.cpu().detach().item())\n    return losses",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "super"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Training-Utils",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Training Utils"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "model = LinearRegresion(X.shape[-1], n_class)\nmodel = model.to(device)\nmodel = model.float()\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.05) #learning rate: lr\nn_epochs = 1000\n\ntrain_loss = []\nval_loss = []\n\nfor epoch in range(n_epochs):\n    losses = train_one_epcoh(model, criterion, optimizer, train_loader)\n    train_loss.append(np.mean(losses))\n    losses = val_one_epcoh(model, criterion, test_loader)\n    val_loss.append(np.mean(losses))",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Training-Softmax-Regression-models",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Training Softmax Regression models"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(train_loss, c=\"blue\", label=\"Training\")\nax.plot(val_loss, c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Plotting-training-Curve",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Training Softmax Regression models",
          "Plotting training Curve"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# grid data for visualization\nx_min, x_max = X_train[:, 0].min(), X_train[:, 0].max()\ny_min, y_max = X_train[:, 1].min(), X_train[:, 1].max()\n\nx_min = x_min.item()\ny_min = y_min.item()\nx_max = x_max.item()\ny_max = y_max.item()\n\nxx = np.linspace(x_min, x_max, 100)\nyy = np.linspace(y_min, y_max, 100)\n\nxx, yy = np.meshgrid(xx, yy)\ngrids = np.hstack([xx.ravel().reshape(-1, 1), yy.ravel().reshape(-1, 1)])\n\ngrid_data = torch.utils.data.TensorDataset(\n    torch.tensor(grids).float()\n)\ngrid_loader = torch.utils.data.DataLoader(grid_data, batch_size=batch_size,\n                                          shuffle=False, drop_last=False)",
      "names": [
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.hstack"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Visualize-Decision-Boundaries",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Training Softmax Regression models",
          "Visualize Decision Boundaries"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "predictions = []\nmodel.eval()\nwith torch.no_grad():\n    for x, in grid_loader:\n        if device == \"cuda\":\n            x = x.to(device)\n        x = x.float()\n        y_pred = model(x)\n        y_pred = nn.Softmax(dim=-1)(y_pred)\n        y_pred = torch.argmax(y_pred, dim=-1)\n        predictions.extend([y_pred[i].item() for i in range(len(y_pred))])",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Visualize-Decision-Boundaries",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Training Softmax Regression models",
          "Visualize Decision Boundaries"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# plot space separation\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\n\ncustom_cmap = ListedColormap([cmap(0), cmap(1), cmap(2)])\nmesh_pred = np.array(predictions).reshape(xx.shape)\nplt.pcolormesh(xx, yy, mesh_pred,\n              cmap=custom_cmap, alpha=0.5)\nplt.scatter([v.item() for v in X_train[:, 0]], [v.item() for v in X_train[:, -1]],\n            c=[torch.argmax(y_train[i]).item() for i in range(len(y_train))], cmap=custom_cmap,\n            edgecolors='none', alpha=0.5)\ncbar = plt.colorbar(ticks=[0, 1, 2])\n# plt.title(\"Training Data and Decision Boundary\")\nfig.tight_layout()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "colors",
            "ListedColormap"
          ],
          "code_str": "ListedColormap",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.colors.ListedColormap"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "pcolormesh"
          ],
          "code_str": "plt.pcolormesh",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.pcolormesh"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "colorbar"
          ],
          "code_str": "plt.colorbar",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.colorbar"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Visualize-Decision-Boundaries",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Training Softmax Regression models",
          "Visualize Decision Boundaries"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# plot space separation\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\n\ncustom_cmap = ListedColormap([cmap(0), cmap(1), cmap(2)])\nmesh_pred = np.array(predictions).reshape(xx.shape)\nplt.pcolormesh(xx, yy, mesh_pred,\n              cmap=custom_cmap, alpha=0.5)\nplt.scatter([v.item() for v in X_test[:, 0]], [v.item() for v in X_test[:, -1]],\n           c=[torch.argmax(y_test[i]).item() for i in range(len(y_test))], cmap=custom_cmap,\n            edgecolors='none', alpha=0.5)\ncbar = plt.colorbar(ticks=[0, 1, 2])\nfig.tight_layout()\nplt.title(\"Validation Data\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "colors",
            "ListedColormap"
          ],
          "code_str": "ListedColormap",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.colors.ListedColormap"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "pcolormesh"
          ],
          "code_str": "plt.pcolormesh",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.pcolormesh"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "colorbar"
          ],
          "code_str": "plt.colorbar",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.colorbar"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "title"
          ],
          "code_str": "plt.title",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.title"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Visualize-Decision-Boundaries",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Training Softmax Regression models",
          "Visualize Decision Boundaries"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "y_test_pred = []\ny_test_true = []\nmodel.eval()\nwith torch.no_grad():\n    for x,y in test_loader:\n        if device == \"cuda\":\n            x = x.to(device)\n        x = x.float()\n        y_test_true.extend([torch.argmax(y[i]).item() for i in range(len(y))])\n        y_pred = model(x)\n        y_pred = nn.Softmax(dim=-1)(y_pred)\n        y_pred = torch.argmax(y_pred, dim=-1)\n        y_test_pred.extend([y_pred[i].item() for i in range(len(y_pred))])",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Confusion-Matrix",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Training Softmax Regression models",
          "Confusion Matrix"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "confusion_matrix(y_test_true, y_test_pred)",
      "names": [],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "Confusion-Matrix",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Training Softmax Regression models",
          "Confusion Matrix"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.metrics import RocCurveDisplay\ncolors = [cmap(0), cmap(1), cmap(2)]\ntarget_names = {\n    0: r\"Soluble\",\n    1: \"Weakly Soluble \",\n    2: r\"Insoluble\"\n}\n\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\n\nfor class_id, color in zip(range(n_class), colors):\n    RocCurveDisplay.from_predictions(\n        np.array(y_test_true)==class_id,\n        np.array(y_test_pred)==class_id,\n        name=f\"{target_names[class_id]}\",\n        color=color,\n        ax=ax,\n    )\n_ = ax.set(\n    xlabel=\"False Positive Rate\",\n    ylabel=\"True Positive Rate\",\n)\n\nax.legend(bbox_to_anchor=(1.3, 1))",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "zip"
          ],
          "code_str": "zip",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "zip"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.array"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_1_multi_class_softmax_regression",
        "ref_id": "AUROC",
        "headings": [
          "Multi-class Classification Using Softmax Regression",
          "Training Softmax Regression models",
          "AUROC"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/nn/Reference_Ch5_Part_3_MLP": [
    {
      "source": "!pip install pandas numpy matplotlib torch wget seaborn scikit-learn",
      "names": [],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Multilayer-Perceptron-(MLP)---An-example-to-compare-the-linear-model-with-the-MLP",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\ncmap = plt.get_cmap('tab10')\ncolors = [cmap(i) for i in range(cmap.N)]\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2",
      "names": [
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 12,
          "end_lineno": 12,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 13,
          "end_lineno": 13,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "colors"
          ],
          "code_str": "matplotlib.colors",
          "lineno": 14,
          "end_lineno": 14,
          "context": "import_from",
          "resolved_location": "matplotlib.colors"
        },
        {
          "import_components": [
            "matplotlib",
            "colors",
            "ListedColormap"
          ],
          "code_str": "ListedColormap",
          "lineno": 14,
          "end_lineno": 14,
          "context": "import_target",
          "resolved_location": "matplotlib.colors.ListedColormap"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "get_cmap"
          ],
          "code_str": "plt.get_cmap",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.get_cmap"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Multilayer-Perceptron-(MLP)---An-example-to-compare-the-linear-model-with-the-MLP",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv \\\n    --output delaney-processed.csv",
      "names": [],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Load-Dataset",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "DELANEY_FILE = \"delaney-processed.csv\"\nTASK_COL = 'measured log solubility in mols per litre'\ndf = pd.read_csv(DELANEY_FILE)\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Load-Dataset",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "X = df[[\n        \"Molecular Weight\",\n        \"Polar Surface Area\"]].values\nY = (df[TASK_COL].values.reshape(-1, 1) >= -2).astype(int)\nprint(\"Shape of X:\", X.shape)\nprint(\"Shape of Y:\", Y.shape)",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Load-Dataset",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", device)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Load-Dataset",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class LinearRegresion(torch.nn.Module):\n    def __init__(self, indim):\n        super(LinearRegresion, self).__init__()\n        self.norm = nn.BatchNorm1d(indim)\n        self.linear = torch.nn.Linear(indim, 1)\n    def forward(self, x):\n        x = self.norm(x)\n        x = self.linear(x)\n        return x",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "super"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Linear-Model",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Linear Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass MLPRegresion(torch.nn.Module):\n    def __init__(self, in_dim):\n        super(MLPRegresion, self).__init__()\n        self.model = nn.Sequential(*[\n            # Normalizes input features.\n            nn.BatchNorm1d(in_dim),\n\n            # input -> hidden layer 1\n            # 10 neurons in hidden layer 1\n            nn.Linear(in_dim, 10),\n            nn.ReLU(),\n\n            # hidden layer 1 -> hidden layer 2\n            # 5 neurons in hidden layer 2\n            nn.Linear(10, 5),\n            nn.ReLU(),\n\n            # hidden layer 2 -> output\n            nn.Linear(5, 1),\n        ])\n\n    def forward( self, x):\n        for layer in self.model:\n            x = layer(x)\n        return x",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "super"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "MLP-Model",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "MLP Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def train_one_epcoh(model, criterion, optimizer, dataloader):\n    losses = []\n    model.train()\n    for x, y_true in dataloader:\n        if device == \"cuda\":\n            x, y_true = x.to(device), y_true.to(device)\n        x, y_true = x.float(), y_true.float()\n        optimizer.zero_grad() #initalize the gradients to be zero\n        output = model(x) # forward progagation in Pytorch\n        y_pred = torch.sigmoid(output) # sigmoid transformation to obtain y^hat\n        # cross entropy loss\n        loss = criterion(y_pred, y_true.reshape(y_pred.shape))\n        loss.backward() # backprogagation\n        optimizer.step() # update gradient for 1 step\n        losses.append(loss.cpu().detach().item()) # record the loss .detach()\n    return losses\n\n# no backprogagation, no optimization\ndef val_one_epcoh(model, criterion, dataloader):\n    losses = []\n    model.eval()\n    with torch.no_grad():\n        for x, y_true in dataloader:\n            if device == \"cuda\":\n                x, y_true = x.to(device), y_true.to(device)\n            x, y_true = x.float(), y_true.float()\n            output = model(x)\n            y_pred = torch.sigmoid(output)\n            loss = criterion(y_pred, y_true.reshape(y_pred.shape))\n            losses.append(loss.cpu().detach().item())\n    return losses",
      "names": [],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Training-Utils",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Training Utils"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.model_selection import train_test_split\n\n# training/validation dataset\ntest_size = int(len(X)*0.1)\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, shuffle=True)\n\n# create dataloaders\n# X_train, X_test, y_train, y_test = map(torch.tensor, (X_train, X_test, y_train, y_test))\nX_train, X_test, y_train, y_test = map(\n    lambda x: torch.tensor(x, dtype=torch.float32), (X_train, X_test, y_train, y_test)\n)\n\nbatch_size = 128\ntrain_data = torch.utils.data.TensorDataset(X_train, y_train)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n                                           shuffle=True, drop_last=False)\ntest_data = torch.utils.data.TensorDataset(X_test, y_test)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n                                          shuffle=False, drop_last=False)",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "map"
          ],
          "code_str": "map",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "map"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Prepare-Dataset",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Prepare Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# grid data for visualization\nx_min, x_max = X_train[:, 0].min(), X_train[:, 0].max()\ny_min, y_max = X_train[:, 1].min(), X_train[:, 1].max()\n\nxx = np.linspace(x_min, x_max, 100)\nyy = np.linspace(y_min, y_max, 100)\n\nxx, yy = np.meshgrid(xx, yy)\ngrids = np.hstack([xx.ravel().reshape(-1, 1), yy.ravel().reshape(-1, 1)])\n\ngrid_data = torch.utils.data.TensorDataset(\n    torch.tensor(grids).float()\n)\ngrid_loader = torch.utils.data.DataLoader(grid_data, batch_size=batch_size,\n                                          shuffle=False, drop_last=False)",
      "names": [
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.hstack"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Prepare-Dataset",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Prepare Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "model = LinearRegresion(2)\nmodel = model.to(device)\nmodel = model.float()\ncriterion = torch.nn.BCELoss() # Selection of the binary cross entrpy loss\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01) #batch gradient descent\nn_epochs = 500\n\ntrain_loss = []\nval_loss = []\n\nfor epoch in range(n_epochs):\n    losses = train_one_epcoh(model, criterion, optimizer, train_loader) # training\n    train_loss.append(np.mean(losses)) # average losses of the batches within the epoch\n    losses = val_one_epcoh(model, criterion, test_loader) # testing\n    val_loss.append(np.mean(losses))",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Train-Logistic-Model",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Train Logistic Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(train_loss, c=\"blue\", label=\"Training\")\nax.plot(val_loss, c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Train-Logistic-Model",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Train Logistic Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "model.eval()\ntruth = []\npreds = []\nwith torch.no_grad():\n    for x, y_true in test_loader:\n        if device == \"cuda\":\n            x, y_true = x.to(device), y_true.to(device)\n        x, y_true = x.float(), y_true.float()\n\n        output = model(x)\n        y_pred = torch.sigmoid(output).reshape(-1)\n        preds.extend([y_pred[i].item() for i in range(len(y_pred))])\n\n        y_true = y_true.reshape(y_pred.shape)\n        truth.extend([y_true[i].item() for i in range(len(y_true))])\n\nconfusion_matrix(np.array(truth), np.array(preds)>0.5)",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.array"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Train-Logistic-Model",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Train Logistic Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "predictions = []\nmodel.eval()\nwith torch.no_grad():\n    for x, in grid_loader:\n        if device == \"cuda\":\n            x = x.to(device)\n        x = x.float()\n        output = model(x)\n        y_pred = torch.sigmoid(output).reshape(-1)\n        predictions.extend([y_pred[i].item() for i in range(len(y_pred))])\n\n\n# plot space separation\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\n\ncustom_cmap = ListedColormap([cmap(0), cmap(1)])\nmesh_pred = np.array(predictions).reshape(xx.shape)\nplt.pcolormesh(xx, yy, mesh_pred>=0.5,\n              cmap=custom_cmap, alpha=0.5)\nplt.scatter(X_train[:, 0], X_train[:, -1],\n            c=y_train, cmap=custom_cmap,\n            edgecolors='none', alpha=0.5)\nfig.tight_layout()",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "colors",
            "ListedColormap"
          ],
          "code_str": "ListedColormap",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "matplotlib.colors.ListedColormap"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "pcolormesh"
          ],
          "code_str": "plt.pcolormesh",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.pcolormesh"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Train-Logistic-Model",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Train Logistic Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "model = MLPRegresion(2) # 2 input features\nmodel = model.to(device)\nmodel = model.float()\ncriterion = torch.nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.05)\nn_epochs = 1000\n\ntrain_loss = []\nval_loss = []\n\nfor epoch in range(n_epochs):\n    losses = train_one_epcoh(model, criterion, optimizer, train_loader)\n    train_loss.append(np.mean(losses))\n    losses = val_one_epcoh(model, criterion, test_loader)\n    val_loss.append(np.mean(losses))",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Train-MLP-Model",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Train MLP Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(train_loss, c=\"blue\", label=\"Training\")\nax.plot(val_loss, c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Train-MLP-Model",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Train MLP Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "model.eval()\ntruth = []\npreds = []\nwith torch.no_grad():\n    for x, y_true in test_loader:\n        if device == \"cuda\":\n            x, y_true = x.to(device), y_true.to(device)\n        x, y_true = x.float(), y_true.float()\n\n        output = model(x)\n        y_pred = torch.sigmoid(output).reshape(-1)\n        preds.extend([y_pred[i].item() for i in range(len(y_pred))])\n\n        y_true = y_true.reshape(y_pred.shape)\n        truth.extend([y_true[i].item() for i in range(len(y_true))])\n\nconfusion_matrix(np.array(truth), np.array(preds)>0.5)",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.array"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Train-MLP-Model",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Train MLP Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "predictions = []\nmodel.eval()\nwith torch.no_grad():\n    for x, in grid_loader:\n        if device == \"cuda\":\n            x = x.to(device)\n        x = x.float()\n        output = model(x)\n        y_pred = torch.sigmoid(output).reshape(-1)\n        predictions.extend([y_pred[i].item() for i in range(len(y_pred))])\n\n\n# plot space separation\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\n\ncustom_cmap = ListedColormap([cmap(0), cmap(1)])\nmesh_pred = np.array(predictions).reshape(xx.shape)\nplt.pcolormesh(xx, yy, mesh_pred>=0.5,\n              cmap=custom_cmap, alpha=0.5)\nplt.scatter(X_train[:, 0], X_train[:, -1],\n            c=y_train, cmap=custom_cmap,\n            edgecolors='none', alpha=0.5)\nfig.tight_layout()",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "colors",
            "ListedColormap"
          ],
          "code_str": "ListedColormap",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "matplotlib.colors.ListedColormap"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "pcolormesh"
          ],
          "code_str": "plt.pcolormesh",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.pcolormesh"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_3_MLP",
        "ref_id": "Train-MLP-Model",
        "headings": [
          "Multilayer Perceptron (MLP) - An example to compare the linear model with the MLP",
          "Train MLP Model"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques": [
    {
      "source": "!pip install wget",
      "names": [],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    },
    {
      "source": "import numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import RocCurveDisplay, auc\nfrom sklearn.model_selection import train_test_split\n\ncmap = plt.get_cmap('tab10')\ncolors = [cmap(i) for i in range(cmap.N)]\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2",
      "names": [
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 8,
          "end_lineno": 8,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 9,
          "end_lineno": 9,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "colors"
          ],
          "code_str": "matplotlib.colors",
          "lineno": 10,
          "end_lineno": 10,
          "context": "import_from",
          "resolved_location": "matplotlib.colors"
        },
        {
          "import_components": [
            "matplotlib",
            "colors",
            "ListedColormap"
          ],
          "code_str": "ListedColormap",
          "lineno": 10,
          "end_lineno": 10,
          "context": "import_target",
          "resolved_location": "matplotlib.colors.ListedColormap"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "get_cmap"
          ],
          "code_str": "plt.get_cmap",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.get_cmap"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Techniques-to-Prevent-Overfitting-in-Neural-Networks",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv \\\n    --output delaney-processed.csv",
      "names": [],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Load-Dataset",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "DELANEY_FILE = \"delaney-processed.csv\"\nTASK_COL = 'measured log solubility in mols per litre'\ndf = pd.read_csv(DELANEY_FILE)\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Load-Dataset",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "X = df[[\n        \"Molecular Weight\",\n        \"Number of H-Bond Donors\",\n        \"Number of Rings\",\n        \"Polar Surface Area\"]].values\nY = df[TASK_COL].values.reshape(-1, 1) >= -2\nprint(\"Shape of X:\", X.shape)\nprint(\"Shape of Y:\", Y.shape)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Load-Dataset",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", device)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Load-Dataset",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class MLPRegresion(torch.nn.Module):\n    def __init__(self, in_dim, hidden_dim, out_dim, norm=False, dropout=None):\n        super(MLPRegresion, self).__init__()\n        hidden_dim = [in_dim] + hidden_dim\n        nn = []\n        if norm:\n            nn.append(torch.nn.BatchNorm1d(in_dim))\n\n        for i in range(1, len(hidden_dim)):\n            nn.append(torch.nn.Linear(hidden_dim[i-1], hidden_dim[i]))\n            if dropout is not None:\n                nn.append(torch.nn.Dropout(dropout))\n            nn.append(torch.nn.ReLU())\n        nn.append(torch.nn.Linear(hidden_dim[-1], out_dim))\n        self.model = torch.nn.Sequential(*nn)\n\n\n    def forward( self, x):\n        for layer in self.model:\n            x = layer(x)\n        return x",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "MLP-Model",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "MLP Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def train_one_epcoh(model, criterion, optimizer, dataloader):\n    losses = []\n    model.train()\n    for x, y_true in dataloader:\n        if device == \"cuda\":\n            x, y_true = x.to(device), y_true.to(device)\n        x, y_true = x.float(), y_true.float()\n        optimizer.zero_grad()\n        y_pred = model(x)\n        y_pred = torch.sigmoid(y_pred)\n        loss = criterion(y_pred, y_true.reshape(y_pred.shape))\n        loss.backward()\n        optimizer.step()\n        losses.append(loss.cpu().detach().item())\n    return losses\n\n\ndef val_one_epcoh(model, criterion, dataloader):\n    losses = []\n    model.eval()\n    with torch.no_grad():\n        for x, y_true in dataloader:\n            if device == \"cuda\":\n                x, y_true = x.to(device), y_true.to(device)\n            x, y_true = x.float(), y_true.float()\n            y_pred = model(x)\n            y_pred = torch.sigmoid(y_pred)\n            loss = criterion(y_pred, y_true.reshape(y_pred.shape))\n            losses.append(loss.cpu().detach().item())\n    return losses",
      "names": [],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Training-Utils",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Training Utils"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def sample_dataloaders(batch_size=128):\n    # training/validation dataset\n    test_size = int(len(X)*0.3)\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, shuffle=True)\n\n    # create dataloaders\n    X_train, X_test, y_train, y_test = map(torch.tensor, (X_train, X_test, y_train, y_test))\n\n    train_data = torch.utils.data.TensorDataset(X_train, y_train)\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n                                            shuffle=True, drop_last=False)\n    test_data = torch.utils.data.TensorDataset(X_test, y_test)\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n                                            shuffle=False, drop_last=False)\n    return train_loader, test_loader",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "map"
          ],
          "code_str": "map",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "map"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Training-Utils",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Training Utils"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def run_one_fold(model, criterion, optimizer, train_loader, test_loader, n_epochs, early_stop=None):\n    train_loss = []\n    val_loss = []\n    for epoch in range(n_epochs):\n        losses = train_one_epcoh(model, criterion, optimizer, train_loader)\n        train_loss.append(np.mean(losses))\n        losses = val_one_epcoh(model, criterion, test_loader)\n        val_loss.append(np.mean(losses))\n        if early_stop is not None:\n            early_stop(np.mean(losses), model)\n            if early_stop.early_stop:\n                print(\"Early stopping\")\n                break\n    return train_loss, val_loss",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Training-Utils",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Training Utils"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def evaluate(model, test_loader):\n    model.eval()\n    truth = []\n    preds = []\n    with torch.no_grad():\n        for x, y_true in test_loader:\n            if device == \"cuda\":\n                x, y_true = x.to(device), y_true.to(device)\n            x, y_true = x.float(), y_true.float()\n            truth.extend(y_true.cpu().detach().numpy().tolist())\n            output = model(x)\n            y_pred = torch.sigmoid(output).reshape(-1)\n            y_pred = y_pred.cpu().detach().numpy()\n            preds.extend(y_pred.tolist())\n    return truth, preds",
      "names": [],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Training-Utils",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Training Utils"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "n_splits = 3  # K-fold cross validation\nn_epochs = 1500\nbatchzise = 32\nhidden_dims = [512, 256, 256, 128, 128]\nlr = 0.1\nnorm = True\n\n## Feel free to tune hyperparameters below\n\n# weight_decay = 1e-3\nweight_decay = 0\n# dropout = None\ndropout = 0.5",
      "names": [],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Dropout,-Ridge-Regularization-(weight-decay)",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Binary Classification Model to test teachniques to avoid overfitting",
          "Dropout, Ridge Regularization (weight decay)"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n\ntprs = []\naucs = []\nmean_fpr = np.linspace(0, 1, 100)\n\ntrain_list = []\ntest_list = []\n\nfor fold in range(n_splits):\n    # define model\n    model = MLPRegresion(X.shape[1], hidden_dims, Y.shape[1], norm, dropout)\n    model = model.to(device)\n    model = model.float()\n    criterion = torch.nn.BCELoss()\n    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n\n    # train\n    train_loader, test_loader = sample_dataloaders(batchzise)\n    train_loss, val_loss = run_one_fold(model, criterion, optimizer,\n                                        train_loader, test_loader, n_epochs)\n    train_list.append(train_loss)\n    test_list.append(val_loss)\n    # evaluate\n    y_test_true, y_test_pred = evaluate(model, test_loader)\n\n    # record ROC curve\n    viz = RocCurveDisplay.from_predictions(\n        np.array(y_test_true),\n        np.array(y_test_pred),\n        alpha=0.3,\n        lw=1,\n        ax=ax,\n        plot_chance_level=(fold == n_splits-1),\n    )\n    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n    interp_tpr[0] = 0.0\n    tprs.append(interp_tpr)\n    aucs.append(viz.roc_auc)\n\n# plot\nmean_tpr = np.mean(tprs, axis=0)\nmean_tpr[-1] = 1.0\nmean_auc = auc(mean_fpr, mean_tpr)\nstd_auc = np.std(aucs)\nax.plot(\n    mean_fpr,\n    mean_tpr,\n    color=\"b\",\n    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n    lw=2,\n    alpha=0.8,\n)\n\nstd_tpr = np.std(tprs, axis=0)\ntprs_upper = np.minimum(mean_tpr + std_tpr, 1)\ntprs_lower = np.maximum(mean_tpr - std_tpr, 0)\nax.fill_between(\n    mean_fpr,\n    tprs_lower,\n    tprs_upper,\n    color=\"grey\",\n    alpha=0.2,\n    label=r\"$\\pm$ 1 std. dev.\",\n)\n\nax.set(\n    xlabel=\"False Positive Rate\",\n    ylabel=\"True Positive Rate\",\n)\nax.legend(loc=\"lower right\", bbox_to_anchor=(1.3, 1))\nplt.show()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 30,
          "end_lineno": 30,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "interp"
          ],
          "code_str": "np.interp",
          "lineno": 36,
          "end_lineno": 36,
          "context": "none",
          "resolved_location": "numpy.interp"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 42,
          "end_lineno": 42,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 45,
          "end_lineno": 45,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 55,
          "end_lineno": 55,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "numpy",
            "minimum"
          ],
          "code_str": "np.minimum",
          "lineno": 56,
          "end_lineno": 56,
          "context": "none",
          "resolved_location": "numpy.minimum"
        },
        {
          "import_components": [
            "numpy",
            "maximum"
          ],
          "code_str": "np.maximum",
          "lineno": 57,
          "end_lineno": 57,
          "context": "none",
          "resolved_location": "numpy.maximum"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 72,
          "end_lineno": 72,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Dropout,-Ridge-Regularization-(weight-decay)",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Binary Classification Model to test teachniques to avoid overfitting",
          "Dropout, Ridge Regularization (weight decay)"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\n\ntrain_mean = np.vstack([np.array(l).reshape(1, -1) for l in train_list]).mean(axis=0)\ntrain_std = np.vstack([np.array(l).reshape(1, -1) for l in train_list]).std(axis=0)\n\nplt.plot(range(n_epochs), train_mean, color=\"b\", label=\"Training\")\n# plt.fill_between(range(n_epochs),\n#                  train_mean-train_std, train_mean+train_std,\n#                  alpha=0.5, color=\"b\")\n\ntest_mean = np.vstack([np.array(l).reshape(1, -1) for l in test_list]).mean(axis=0)\ntest_std = np.vstack([np.array(l).reshape(1, -1) for l in test_list]).std(axis=0)\nplt.plot(range(n_epochs), test_mean, color=\"red\", label=\"Test\")\n# plt.fill_between(range(n_epochs),\n#                  test_mean-test_std, test_mean+test_std,\n#                  alpha=0.5, color=\"r\")\n\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"BCE Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "numpy",
            "vstack"
          ],
          "code_str": "np.vstack",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.vstack"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "vstack"
          ],
          "code_str": "np.vstack",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.vstack"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "vstack"
          ],
          "code_str": "np.vstack",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.vstack"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "vstack"
          ],
          "code_str": "np.vstack",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.vstack"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Dropout,-Ridge-Regularization-(weight-decay)",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Binary Classification Model to test teachniques to avoid overfitting",
          "Dropout, Ridge Regularization (weight decay)"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "lr = 0.1\nweight_decay = 0\ndropout = None\nnorm = True",
      "names": [],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Early-Stopping",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Early Stopping"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=3, delta=1e-3, verbose=0):\n        \"\"\"\n        Params\n        ------\n        patience : int\n            steps/ epochs to wait after last time validation loss improved\n        delta : float\n            minimum change in the monitored quantity to qualify as an improvement\n        path : str\n            path to checkpoint params\n        \"\"\"\n        self.patience = patience\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.inf\n        self.delta = delta\n        self.verbose = verbose\n        self.scores = []\n\n    def __call__(self, val_loss, model):\n        score = -val_loss\n        self.scores.append(score)\n        if self.best_score is None:\n            self.best_score = score\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.verbose > 0:\n              print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.counter = 0",
      "names": [
        {
          "import_components": [
            "numpy",
            "inf"
          ],
          "code_str": "np.inf",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "numpy.inf"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Early-Stopping",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Early Stopping"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "patience = 30 # Early Stopping if validation loss does not increase for 30 epochs\ndelta = 1e-5",
      "names": [],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Early-Stopping",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Early Stopping"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n\n\ntprs = []\naucs = []\nmean_fpr = np.linspace(0, 1, 100)\n\ntrain_list = []\ntest_list = []\n\nfor fold in range(n_splits):\n    early_stopping = EarlyStopping(patience=patience, delta=delta)\n    # define model\n    model = MLPRegresion(X.shape[1], hidden_dims, Y.shape[1], norm, dropout)\n    model = model.to(device)\n    model = model.float()\n    criterion = torch.nn.BCELoss()\n    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n\n    # train\n    train_loader, test_loader = sample_dataloaders(batchzise)\n    train_loss, val_loss = run_one_fold(model, criterion, optimizer,\n                                        train_loader, test_loader, n_epochs, early_stopping)\n    train_list.append(train_loss)\n    test_list.append(val_loss)\n    # evaluate\n    y_test_true, y_test_pred = evaluate(model, test_loader)\n\n    # record ROC curve\n    viz = RocCurveDisplay.from_predictions(\n        np.array(y_test_true),\n        np.array(y_test_pred),\n        alpha=0.3,\n        lw=1,\n        ax=ax,\n        plot_chance_level=(fold == n_splits-1),\n    )\n    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n    interp_tpr[0] = 0.0\n    tprs.append(interp_tpr)\n    aucs.append(viz.roc_auc)\n\n# plot\nmean_tpr = np.mean(tprs, axis=0)\nmean_tpr[-1] = 1.0\nmean_auc = auc(mean_fpr, mean_tpr)\nstd_auc = np.std(aucs)\nax.plot(\n    mean_fpr,\n    mean_tpr,\n    color=\"b\",\n    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n    lw=2,\n    alpha=0.8,\n)\n\nstd_tpr = np.std(tprs, axis=0)\ntprs_upper = np.minimum(mean_tpr + std_tpr, 1)\ntprs_lower = np.maximum(mean_tpr - std_tpr, 0)\nax.fill_between(\n    mean_fpr,\n    tprs_lower,\n    tprs_upper,\n    color=\"grey\",\n    alpha=0.2,\n    label=r\"$\\pm$ 1 std. dev.\",\n)\n\nax.set(\n    xlabel=\"False Positive Rate\",\n    ylabel=\"True Positive Rate\",\n)\nax.legend(loc=\"lower right\", bbox_to_anchor=(1.3, 1))\nplt.show()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 32,
          "end_lineno": 32,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "interp"
          ],
          "code_str": "np.interp",
          "lineno": 38,
          "end_lineno": 38,
          "context": "none",
          "resolved_location": "numpy.interp"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 44,
          "end_lineno": 44,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 47,
          "end_lineno": 47,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 57,
          "end_lineno": 57,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "numpy",
            "minimum"
          ],
          "code_str": "np.minimum",
          "lineno": 58,
          "end_lineno": 58,
          "context": "none",
          "resolved_location": "numpy.minimum"
        },
        {
          "import_components": [
            "numpy",
            "maximum"
          ],
          "code_str": "np.maximum",
          "lineno": 59,
          "end_lineno": 59,
          "context": "none",
          "resolved_location": "numpy.maximum"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 74,
          "end_lineno": 74,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Early-Stopping",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Early Stopping"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\n\nplt.plot(train_loss, color=\"b\", label=\"Training\")\nplt.plot(val_loss, color=\"red\", label=\"Test\")\n\n\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"BCE Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_Ch5_Part_4_avoid_overfitting_techniques",
        "ref_id": "Early-Stopping",
        "headings": [
          "Techniques to Prevent Overfitting in Neural Networks",
          "Early Stopping"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/nn/Reference_ch5_Part_2_xor": [
    {
      "source": "import numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\ncmap = plt.get_cmap('tab10')\ncolors = [cmap(i) for i in range(cmap.N)]\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2",
      "names": [
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "colors"
          ],
          "code_str": "matplotlib.colors",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_from",
          "resolved_location": "matplotlib.colors"
        },
        {
          "import_components": [
            "matplotlib",
            "colors",
            "ListedColormap"
          ],
          "code_str": "ListedColormap",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib.colors.ListedColormap"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "get_cmap"
          ],
          "code_str": "plt.get_cmap",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.get_cmap"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_ch5_Part_2_xor",
        "ref_id": "A-simple-nonlinear-dataset:-XOR",
        "headings": [
          "A simple nonlinear dataset: XOR"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\nY = np.array([0, 1, 1, 0])",
      "names": [
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.array"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_ch5_Part_2_xor",
        "ref_id": "XOR-Dataset",
        "headings": [
          "A simple nonlinear dataset: XOR",
          "XOR Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\nplt.scatter(X[:, 0], X[:, 1], c=[colors[Y[i]] for i in range(len(Y))], s=500)\nplt.xlim([-0.2, 1.2])\nplt.ylim([-0.2, 1.2])\nfig.tight_layout()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_ch5_Part_2_xor",
        "ref_id": "XOR-Dataset",
        "headings": [
          "A simple nonlinear dataset: XOR",
          "XOR Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import torch\nclass LinearRegresion(torch.nn.Module):\n    def __init__(self, indim):\n        super(LinearRegresion, self).__init__()\n        self.linear = torch.nn.Linear(indim, 1)\n    def forward(self, x):\n        x = self.linear(x)\n        return x",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "super"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_ch5_Part_2_xor",
        "ref_id": "PyTorch-implementation",
        "headings": [
          "A simple nonlinear dataset: XOR",
          "PyTorch implementation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "x = np.linspace(-10, 10, 1000)\ny = 1/(1+np.exp(-x))\n\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\nplt.plot(x, y, \"k-\", linewidth=3)",
      "names": [
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "exp"
          ],
          "code_str": "np.exp",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.exp"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_ch5_Part_2_xor",
        "ref_id": "Logistic-Regression",
        "headings": [
          "A simple nonlinear dataset: XOR",
          "PyTorch implementation",
          "Logistic Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "model = LinearRegresion(2)\ncriterion = torch.nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n\ntrain_loss = []\ndata = torch.from_numpy(X).float()\ny_true = torch.from_numpy(Y).float()\n\nfor epoch in range(500):\n    optimizer.zero_grad()\n\n    output = model(data)\n    y_pred = torch.sigmoid(output)\n\n    loss = criterion(y_pred, y_true.reshape(y_pred.shape))\n\n    train_loss.append(loss.item())\n    loss.backward()\n    optimizer.step()",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_ch5_Part_2_xor",
        "ref_id": "Logistic-Regression",
        "headings": [
          "A simple nonlinear dataset: XOR",
          "PyTorch implementation",
          "Logistic Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\nplt.plot(train_loss)\nfig.tight_layout()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_ch5_Part_2_xor",
        "ref_id": "Logistic-Regression",
        "headings": [
          "A simple nonlinear dataset: XOR",
          "PyTorch implementation",
          "Logistic Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "x1 = np.linspace(0, 1, 100)\nx2 = np.linspace(0, 1, 100)\nxx1, xx2 = np.meshgrid(x1, x2)\nx_grid = np.hstack([xx1.ravel().reshape(-1, 1), xx2.ravel().reshape(-1, 1)])\nx_grid = torch.from_numpy(x_grid).float()\noutput = model(x_grid)\ny_grid_pred = torch.sigmoid(output)\ny_grid_pred = y_grid_pred.reshape(xx1.shape)\n\n\n# plot space separation\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\n\ncustom_cmap = ListedColormap([cmap(0), cmap(1)])\nplt.pcolormesh(xx1, xx2, y_grid_pred>=0.5, cmap=custom_cmap, alpha=0.5)\n\nplt.scatter(X[:, 0], X[:, 1], c=[colors[Y[i]] for i in range(len(Y))], s=500)\nplt.xlim([-0.2, 1.2])\nplt.ylim([-0.2, 1.2])\nfig.tight_layout()",
      "names": [
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "colors",
            "ListedColormap"
          ],
          "code_str": "ListedColormap",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "matplotlib.colors.ListedColormap"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "pcolormesh"
          ],
          "code_str": "plt.pcolormesh",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.pcolormesh"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_ch5_Part_2_xor",
        "ref_id": "Logistic-Regression",
        "headings": [
          "A simple nonlinear dataset: XOR",
          "PyTorch implementation",
          "Logistic Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass MLPRegresion(torch.nn.Module):\n    def __init__(self, indim, hidden_dims):\n        assert isinstance(hidden_dims, list), f\"Hidden dimensions {hidden_dims} should be a list\"\n        super(MLPRegresion, self).__init__()\n        hidden_dims = [indim] + hidden_dims\n        layers = []\n        for i in range(len(hidden_dims)-1):\n            layers.append(torch.nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n\n        layers.append(torch.nn.Linear(hidden_dims[-1], 1))\n\n        self.layers = nn.ModuleList(layers)\n\n    def forward( self, x):\n        for layer in self.layers[:-1]:\n            x = layer(x)\n            x = nn.ReLU()(x)\n        x = self.layers[-1](x)\n        return x",
      "names": [
        {
          "import_components": [
            "isinstance"
          ],
          "code_str": "isinstance",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "isinstance"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_ch5_Part_2_xor",
        "ref_id": "Multiple-layer-Perceptron",
        "headings": [
          "A simple nonlinear dataset: XOR",
          "Multiple layer Perceptron"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "model = MLPRegresion(2, [3, 2])\ncriterion = torch.nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n\ntrain_loss = []\ndata = torch.from_numpy(X).float()\ny_true = torch.from_numpy(Y).float()\n\nfor epoch in range(5000):\n    optimizer.zero_grad()\n\n    output = model(data)\n    y_pred = torch.sigmoid(output)\n\n    loss = criterion(y_pred, y_true.reshape(y_pred.shape))\n\n    train_loss.append(loss.item())\n    loss.backward()\n    optimizer.step()",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_ch5_Part_2_xor",
        "ref_id": "Multiple-layer-Perceptron",
        "headings": [
          "A simple nonlinear dataset: XOR",
          "Multiple layer Perceptron"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\nplt.plot(train_loss)\nfig.tight_layout()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_ch5_Part_2_xor",
        "ref_id": "Multiple-layer-Perceptron",
        "headings": [
          "A simple nonlinear dataset: XOR",
          "Multiple layer Perceptron"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "x1 = np.linspace(0, 1, 100)\nx2 = np.linspace(0, 1, 100)\nxx1, xx2 = np.meshgrid(x1, x2)\nx_grid = np.hstack([xx1.ravel().reshape(-1, 1), xx2.ravel().reshape(-1, 1)])\nx_grid = torch.from_numpy(x_grid).float()\n\nwith torch.no_grad():\n    output = model(x_grid)\n\ny_grid_pred = torch.sigmoid(output)\ny_grid_pred = y_grid_pred.reshape(xx1.shape)\n\n\n# plot space separation\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\n\ncustom_cmap = ListedColormap([cmap(0), cmap(1)])\nplt.pcolormesh(xx1, xx2, y_grid_pred>=0.5, cmap=custom_cmap, alpha=0.5)\n\nplt.scatter(X[:, 0], X[:, 1], c=[colors[Y[i]] for i in range(len(Y))], s=500)\nplt.xlim([-0.2, 1.2])\nplt.ylim([-0.2, 1.2])\nfig.tight_layout()",
      "names": [
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "colors",
            "ListedColormap"
          ],
          "code_str": "ListedColormap",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "matplotlib.colors.ListedColormap"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "pcolormesh"
          ],
          "code_str": "plt.pcolormesh",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.pcolormesh"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        }
      ],
      "example": {
        "document": "examples/nn/Reference_ch5_Part_2_xor",
        "ref_id": "Multiple-layer-Perceptron",
        "headings": [
          "A simple nonlinear dataset: XOR",
          "Multiple layer Perceptron"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/non_parametric/Reference_Ch4_part_2_decision_tree": [
    {
      "source": "!pip install wget",
      "names": [],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    },
    {
      "source": "import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt",
      "names": [
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_from",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "pyplot",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "Decision-Tree",
        "headings": [
          "Decision Tree"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget https://raw.githubusercontent.com/xuhuihuang/uwmadisonchem361/refs/heads/main/delaney_dataset_200compounds.csv \\\n--output delaney_dataset_200compounds.csv\n\n!python -m wget https://raw.githubusercontent.com/xuhuihuang/uwmadisonchem361/refs/heads/main/delaney_dataset_40compounds.csv \\\n--output delaney_dataset_40compounds.csv\n\n!python -m wget https://raw.githubusercontent.com/xuhuihuang/uwmadisonchem361/refs/heads/main/delaney_dataset_44compounds_with_outliers.csv \\\n--output delaney_dataset_44compounds_with_outliers.csv",
      "names": [],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "Download-Datasets",
        "headings": [
          "Decision Tree",
          "Download Datasets"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "df = pd.read_csv('delaney_dataset_200compounds.csv')\ndf.head(2)",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "Load-the-curated-Delaney-dataset,-which-contains-200-compounds:",
        "headings": [
          "Decision Tree",
          "Download Datasets",
          "Load the curated Delaney dataset, which contains 200 compounds:"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "data = df.iloc[:].values",
      "names": [],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "Load-the-curated-Delaney-dataset,-which-contains-200-compounds:",
        "headings": [
          "Decision Tree",
          "Download Datasets",
          "Load the curated Delaney dataset, which contains 200 compounds:"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# data with Molecular Weight and Polar Surface Are as features.\nX = data[:,0:2]\n\n# solubility labels\ny = data[:,3].astype(int)",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "int"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "Load-the-curated-Delaney-dataset,-which-contains-200-compounds:",
        "headings": [
          "Decision Tree",
          "Download Datasets",
          "Load the curated Delaney dataset, which contains 200 compounds:"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1,1,figsize=(3,3))\n\nax.scatter(X[np.where(y==1)[0],0],X[np.where(y==1)[0],1],s=25, marker='o', facecolors='none', edgecolor=\"blue\", label='soluble')\nax.scatter(X[np.where(y==-1)[0],0],X[np.where(y==-1)[0],1],s=50, marker='X', color='red',linewidths=0.1, label='non-soluble')\n\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"Polar Surface Area\")\n\nax.set_xlim(80,300)\nax.set_ylim(-20,120)\n\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "Visualize-the-200-compounds",
        "headings": [
          "Decision Tree",
          "Download Datasets",
          "Visualize the 200 compounds"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.inspection import DecisionBoundaryDisplay",
      "names": [],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "Perform-decision-tree-classification-on-this-dataset,-let's-do-the-first-split",
        "headings": [
          "Decision Tree",
          "Perform decision tree classification on this dataset, let\u2019s do the first split"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "clf = DecisionTreeClassifier(random_state=42,max_leaf_nodes=2,criterion='entropy')\nclf.fit(X, y)",
      "names": [],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "Perform-decision-tree-classification-on-this-dataset,-let's-do-the-first-split",
        "headings": [
          "Decision Tree",
          "Perform decision tree classification on this dataset, let\u2019s do the first split"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 3))\nplot_tree(clf, filled=False, feature_names=[\"Molecular Weight (Da.)\", \"Polar Surface Area\"], class_names=[\"Non-soluble\", \"Soluble\"], fontsize=8)",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "Perform-decision-tree-classification-on-this-dataset,-let's-do-the-first-split",
        "headings": [
          "Decision Tree",
          "Perform decision tree classification on this dataset, let\u2019s do the first split"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "a = np.arange(80,301,0.1)\nb = np.arange(-20,121,0.1)\naa,bb = np.meshgrid(a,b)\nX_grid = np.concatenate([aa.ravel().reshape(-1,1),bb.ravel().reshape(-1,1)],axis=1)\n\nf, ax = plt.subplots(1,1,figsize=(3,3))\n#plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\nDecisionBoundaryDisplay.from_estimator(\n    clf,\n    X_grid,\n    cmap=plt.cm.RdYlBu,\n    response_method=\"predict\",\n    ax=ax,\n    alpha=0.3,\n)\nax.scatter(X[np.where(y==1)[0],0],X[np.where(y==1)[0],1],s=25, marker='o', facecolors='none', edgecolor=\"blue\", label='soluble')\nax.scatter(X[np.where(y==-1)[0],0],X[np.where(y==-1)[0],1],s=50, marker='X', color='red',linewidths=0.1, label='non-soluble')\n\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"Polar Surface Area\")\n\nax.set_xlim(80,300)\nax.set_ylim(-20,120)\n\nplt.legend()",
      "names": [
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "numpy",
            "concatenate"
          ],
          "code_str": "np.concatenate",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.concatenate"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "In-this-visualization,-the-blue-region-indicates-that-the-model-predicts-the-points-within-this-area-as-soluble-and-vice-versa",
        "headings": [
          "Decision Tree",
          "Perform decision tree classification on this dataset, let\u2019s do the first split",
          "Visualize the predicted regions from one-split decision tree model.",
          "In this visualization, the blue region indicates that the model predicts the points within this area as soluble and vice versa"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def entropy(p):\n    return -p*np.log2(p) - (1-p)*np.log2(1-p)\n\ndef infogain(X,y,thres,axis=0):\n\n    pos = len(np.where(y==1)[0])\n    neg = len(np.where(y==-1)[0])\n\n    if pos == 0 or neg == 0:\n        Hy = 0\n    else:\n        Hy = entropy(pos/(pos+neg))\n\n    idx0 = np.where(X[:,axis]<=thres)[0]\n    idx1 = np.where(X[:,axis]>thres)[0]\n\n    p0 = len(idx0)/(len(idx0)+len(idx1))\n    p1 = 1 - p0\n\n    y0 = y[idx0]\n    pos = len(np.where(y0==1)[0])\n    neg = len(np.where(y0==-1)[0])\n    if pos == 0 or neg == 0:\n        Hy0 = 0\n    else:\n        Hy0 = entropy(pos/(pos+neg))\n\n    y1 = y[idx1]\n    pos = len(np.where(y1==1)[0])\n    neg = len(np.where(y1==-1)[0])\n    if pos == 0 or neg == 0:\n        Hy1 = 0\n    else:\n        Hy1 = entropy(pos/(pos+neg))\n\n    HySplit = p0*Hy0 + p1*Hy1\n\n    return Hy-HySplit",
      "names": [
        {
          "import_components": [
            "numpy",
            "log2"
          ],
          "code_str": "np.log2",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.log2"
        },
        {
          "import_components": [
            "numpy",
            "log2"
          ],
          "code_str": "np.log2",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.log2"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 30,
          "end_lineno": 30,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 30,
          "end_lineno": 30,
          "context": "none",
          "resolved_location": "numpy.where"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "You-can-manually-write-the-info-gain-formula-to-find-the-split,-which-is-consistent-with-result-from-sklearn",
        "headings": [
          "Decision Tree",
          "You can manually write the info gain formula to find the split, which is consistent with result from sklearn"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# scan the first feature of molecular weight\nthres = np.arange(80,301,0.1)\nig = []\nfor i in thres:\n    ig.append(infogain(X,y,i,axis=0))\n\nf, ax = plt.subplots(1,1,figsize=(3,3))\nax.plot(thres,ig,c='blue')\n\nax.set_xlabel(\"Thres at Molecular Weight (Da.)\")\nax.set_ylabel(\"Info Gain\")",
      "names": [
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "You-can-manually-write-the-info-gain-formula-to-find-the-split,-which-is-consistent-with-result-from-sklearn",
        "headings": [
          "Decision Tree",
          "You can manually write the info gain formula to find the split, which is consistent with result from sklearn"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# scan the second feature of polar surface area\nthres = np.arange(-20,121,0.1)\nig = []\nfor i in thres:\n    ig.append(infogain(X,y,i,axis=1))\n\nf, ax = plt.subplots(1,1,figsize=(3,3))\nax.plot(thres,ig,c='blue')\n\nax.set_xlabel(\"Thres at Polar Surface Area\")\nax.set_ylabel(\"Info Gain\")",
      "names": [
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "You-can-manually-write-the-info-gain-formula-to-find-the-split,-which-is-consistent-with-result-from-sklearn",
        "headings": [
          "Decision Tree",
          "You can manually write the info gain formula to find the split, which is consistent with result from sklearn"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "for num_nodes in range(2,20):\n\n    clf = DecisionTreeClassifier(random_state=42,max_leaf_nodes=num_nodes,criterion='entropy')\n    clf.fit(X, y)\n    # when score == 1, indicating that all data points are correctly classified\n    score = clf.score(X, y)\n\n    plt.figure(figsize=(5, 4))\n    plot_tree(clf, filled=False, feature_names=[\"Molecular Weight (Da.)\", \"Polar Surface Area\"], class_names=[\"Non-soluble\", \"Soluble\"], fontsize=8)\n\n\n    a = np.arange(80,301,0.1)\n    b = np.arange(-20,121,0.1)\n    aa,bb = np.meshgrid(a,b)\n    X_grid = np.concatenate([aa.ravel().reshape(-1,1),bb.ravel().reshape(-1,1)],axis=1)\n\n    f, ax = plt.subplots(1,1,figsize=(3,3))\n    #plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n    DecisionBoundaryDisplay.from_estimator(\n        clf,\n        X_grid,\n        cmap=plt.cm.RdYlBu,\n        response_method=\"predict\",\n        ax=ax,\n        alpha=0.3,\n    )\n    ax.scatter(X[np.where(y==1)[0],0],X[np.where(y==1)[0],1],s=25, marker='o', facecolors='none', edgecolor=\"blue\", label='soluble')\n    ax.scatter(X[np.where(y==-1)[0],0],X[np.where(y==-1)[0],1],s=50, marker='X', color='red',linewidths=0.1, label='non-soluble')\n\n    ax.set_xlabel(\"Molecular Weight (Da.)\")\n    ax.set_ylabel(\"Polar Surface Area\")\n\n    ax.set_xlim(80,300)\n    ax.set_ylim(-20,120)\n\n    if score == 1.:\n        break",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "numpy",
            "concatenate"
          ],
          "code_str": "np.concatenate",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.concatenate"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.where"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "Split-until-all-data-points-are-correctly-classified",
        "headings": [
          "Decision Tree",
          "You can manually write the info gain formula to find the split, which is consistent with result from sklearn",
          "Split until all data points are correctly classified"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "df = pd.read_csv('delaney_dataset_40compounds.csv')\ndf.head(2)\n\ndata = df.iloc[:].values\n\n# data with Molecular Weight and Polar Surface Are as features.\nX = data[:,0:2]\n\n# solubility labels\ny = data[:,3].astype(int)",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "int"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "We-then-show-decision-tree-is-not-robust-to-noisy-data,-lets-use-40-compounds-dataset-again",
        "headings": [
          "Decision Tree",
          "You can manually write the info gain formula to find the split, which is consistent with result from sklearn",
          "We then show decision tree is not robust to noisy data, lets use 40 compounds dataset again"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "for num_nodes in range(2,20):\n\n    clf = DecisionTreeClassifier(random_state=42,max_leaf_nodes=num_nodes,criterion='entropy')\n    clf.fit(X, y)\n    # when score == 1, indicating that all data points are correctly classified\n    score = clf.score(X, y)\n\n    plt.figure(figsize=(5, 4))\n    plot_tree(clf, filled=False, feature_names=[\"Molecular Weight (Da.)\", \"Polar Surface Area\"], class_names=[\"Non-soluble\", \"Soluble\"], fontsize=8)\n\n\n    a = np.arange(80,301,0.1)\n    b = np.arange(-20,121,0.1)\n    aa,bb = np.meshgrid(a,b)\n    X_grid = np.concatenate([aa.ravel().reshape(-1,1),bb.ravel().reshape(-1,1)],axis=1)\n\n    f, ax = plt.subplots(1,1,figsize=(3,3))\n    #plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n    DecisionBoundaryDisplay.from_estimator(\n        clf,\n        X_grid,\n        cmap=plt.cm.RdYlBu,\n        response_method=\"predict\",\n        ax=ax,\n        alpha=0.3,\n    )\n    ax.scatter(X[np.where(y==1)[0],0],X[np.where(y==1)[0],1],s=25, marker='o', facecolors='none', edgecolor=\"blue\", label='soluble')\n    ax.scatter(X[np.where(y==-1)[0],0],X[np.where(y==-1)[0],1],s=50, marker='X', color='red',linewidths=0.1, label='non-soluble')\n\n    ax.set_xlabel(\"Molecular Weight (Da.)\")\n    ax.set_ylabel(\"Polar Surface Area\")\n\n    ax.set_xlim(80,300)\n    ax.set_ylim(-20,120)\n\n    if score == 1.:\n        break",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "numpy",
            "concatenate"
          ],
          "code_str": "np.concatenate",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.concatenate"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.where"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_decision_tree",
        "ref_id": "We-then-show-decision-tree-is-not-robust-to-noisy-data,-lets-use-40-compounds-dataset-again",
        "headings": [
          "Decision Tree",
          "You can manually write the info gain formula to find the split, which is consistent with result from sklearn",
          "We then show decision tree is not robust to noisy data, lets use 40 compounds dataset again"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/non_parametric/Reference_Ch4_part_2_kNN": [
    {
      "source": "!pip install wget",
      "names": [],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_kNN",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    },
    {
      "source": "import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt",
      "names": [
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_from",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "pyplot",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_kNN",
        "ref_id": "K-nearest-Neighbour",
        "headings": [
          "K-nearest Neighbour"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget https://raw.githubusercontent.com/xuhuihuang/uwmadisonchem361/refs/heads/main/delaney_dataset_200compounds.csv \\\n--output delaney_dataset_200compounds.csv\n\n!python -m wget https://raw.githubusercontent.com/xuhuihuang/uwmadisonchem361/refs/heads/main/delaney_dataset_40compounds.csv \\\n--output delaney_dataset_40compounds.csv\n\n!python -m wget https://raw.githubusercontent.com/xuhuihuang/uwmadisonchem361/refs/heads/main/delaney_dataset_44compounds_with_outliers.csv \\\n--output delaney_dataset_44compounds_with_outliers.csv",
      "names": [],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_kNN",
        "ref_id": "Download-Datasets",
        "headings": [
          "K-nearest Neighbour",
          "Download Datasets"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "df = pd.read_csv('delaney_dataset_40compounds.csv')\ndf.head(2)",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_kNN",
        "ref_id": "Load-the-curated-Delaney-dataset,-which-contains-40-compounds:",
        "headings": [
          "K-nearest Neighbour",
          "Download Datasets",
          "Load the curated Delaney dataset, which contains 40 compounds:"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "data = df.iloc[:].values",
      "names": [],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_kNN",
        "ref_id": "Load-the-curated-Delaney-dataset,-which-contains-40-compounds:",
        "headings": [
          "K-nearest Neighbour",
          "Download Datasets",
          "Load the curated Delaney dataset, which contains 40 compounds:"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# data with log solubility and Polar Surface Are as features.\nX = data[:,[2,1]]\n\n# solubility labels\ny = data[:,3].astype(int)",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "int"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_kNN",
        "ref_id": "Load-the-curated-Delaney-dataset,-which-contains-40-compounds:",
        "headings": [
          "K-nearest Neighbour",
          "Download Datasets",
          "Load the curated Delaney dataset, which contains 40 compounds:"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1,1,figsize=(3,3))\n\nax.scatter(X[np.where(y==1)[0],0],X[np.where(y==1)[0],1],s=25, marker='o', facecolors='none', edgecolor=\"blue\", label='soluble')\nax.scatter(X[np.where(y==-1)[0],0],X[np.where(y==-1)[0],1],s=50, marker='X', color='red',linewidths=0.1, label='non-soluble')\n\nax.set_xlabel(\"log solubility (mol/L)\")\nax.set_ylabel(\"Polar Surface Area\")\n#plt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.where"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_kNN",
        "ref_id": "Load-the-curated-Delaney-dataset,-which-contains-40-compounds:",
        "headings": [
          "K-nearest Neighbour",
          "Download Datasets",
          "Load the curated Delaney dataset, which contains 40 compounds:"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.neighbors import KNeighborsClassifier\n\nneigh = KNeighborsClassifier(n_neighbors=1)\nneigh.fit(X, y)",
      "names": [],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_kNN",
        "ref_id": "Let's-fit-a-1-NN-model",
        "headings": [
          "K-nearest Neighbour",
          "Download Datasets",
          "Let\u2019s fit a 1-NN model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "a = np.arange(-6,1.1,0.1)\nb = np.arange(-20,121,1)\naa,bb = np.meshgrid(a,b)\nX_grid = np.concatenate([aa.ravel().reshape(-1,1),bb.ravel().reshape(-1,1)],axis=1)\npredict_labels = neigh.predict(X_grid)\n\nfrom matplotlib.colors import ListedColormap\n\ncolors = ['red', 'blue']\ncmap = ListedColormap(colors)\n\nf, ax = plt.subplots(1,1,figsize=(3,3))\n#plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\nax.scatter(x=X_grid[:,0], y=X_grid[:,1], c=predict_labels, cmap = cmap, alpha=0.025)\n\nax.scatter(X[np.where(y==1)[0],0],X[np.where(y==1)[0],1],s=25, marker='o', facecolors='none', edgecolor=\"blue\", label='Soluble')\nax.scatter(X[np.where(y==-1)[0],0],X[np.where(y==-1)[0],1],s=50, marker='X', color='red',linewidths=0.1, label='Non-soluble')\n\nax.vlines(x=-2,ymin=-20,ymax=120,colors='black',linewidth=0.5,label='Ground truth boundary')\n\nax.set_xlabel(\"Log solubility (mol/L)\")\nax.set_ylabel(\"Polar Surface Area\")\n\nax.set_xlim(-6,1)\nax.set_ylim(-20,120)\n\nplt.legend()",
      "names": [
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "numpy",
            "concatenate"
          ],
          "code_str": "np.concatenate",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.concatenate"
        },
        {
          "import_components": [
            "matplotlib",
            "colors"
          ],
          "code_str": "matplotlib.colors",
          "lineno": 7,
          "end_lineno": 7,
          "context": "import_from",
          "resolved_location": "matplotlib.colors"
        },
        {
          "import_components": [
            "matplotlib",
            "colors",
            "ListedColormap"
          ],
          "code_str": "ListedColormap",
          "lineno": 7,
          "end_lineno": 7,
          "context": "import_target",
          "resolved_location": "matplotlib.colors.ListedColormap"
        },
        {
          "import_components": [
            "matplotlib",
            "colors",
            "ListedColormap"
          ],
          "code_str": "ListedColormap",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.colors.ListedColormap"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/non_parametric/Reference_Ch4_part_2_kNN",
        "ref_id": "As-demonstrated,-the-performance-of-the-1-NN-classifier-is-particularly-sensitive-to-features-that-are-either-uncorrelated-or-unnormalized",
        "headings": [
          "K-nearest Neighbour",
          "Download Datasets",
          "Visualize the predicted regions from 1-NN model.",
          "As demonstrated, the performance of the 1-NN classifier is particularly sensitive to features that are either uncorrelated or unnormalized"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/reduction/Reference_Ch3_part_1_pca_step_by_step": [
    {
      "source": "import random\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ncmap = plt.get_cmap('tab10')\ncolors = [cmap(i) for i in range(cmap.N)]\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\nn_samples = 100\nmarkersize = 100",
      "names": [
        {
          "import_components": [
            "random"
          ],
          "code_str": "random",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "random"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "get_cmap"
          ],
          "code_str": "plt.get_cmap",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.get_cmap"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "random",
            "seed"
          ],
          "code_str": "random.seed",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "random.seed"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "seed"
          ],
          "code_str": "np.random.seed",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.random.seed"
        }
      ],
      "example": {
        "document": "examples/reduction/Reference_Ch3_part_1_pca_step_by_step",
        "ref_id": "PCA-from-Scratch-(Eigen-Decomposition)",
        "headings": [
          "PCA from Scratch (Eigen Decomposition)"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# sample some data with noise\nx = np.linspace(-2, 2, n_samples)\ny = x\ny_noised = y + np.random.randn(n_samples)*0.5\n\nsamples = np.hstack([x.reshape(-1, 1), y_noised.reshape(-1, 1)])",
      "names": [
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "randn"
          ],
          "code_str": "np.random.randn",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.random.randn"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.hstack"
        }
      ],
      "example": {
        "document": "examples/reduction/Reference_Ch3_part_1_pca_step_by_step",
        "ref_id": "Sample-100-data-points",
        "headings": [
          "PCA from Scratch (Eigen Decomposition)",
          "Sample 100 data points"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.scatter(samples[:, 0], samples[:, 1], c=\"blue\", alpha=0.5)\nplt.plot(x, y, \"r-\")\n# plt.axis(\"off\")\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/reduction/Reference_Ch3_part_1_pca_step_by_step",
        "ref_id": "Sample-100-data-points",
        "headings": [
          "PCA from Scratch (Eigen Decomposition)",
          "Sample 100 data points"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# remove mean from samples\ndemeaned = True\n# define number of components\nncomponents = 2\n\ndata = samples\n\nif demeaned:\n    avg = np.mean(data, axis=0)\n    data = data - avg\n\n# compute covariance matrix\ncov = data.T@data # (2xn) x (nx2)\n\n# eigen decomposition of covariance matrix\neigenvalues, eigenvectors = np.linalg.eig(cov)\n# sort eigenvectors by eigenvalues, making sure the first PCs always capture more variance\nsorted_indices = np.argsort(eigenvalues)[::-1]\neigval = eigenvalues[sorted_indices]\neigvec = eigenvectors[:, sorted_indices]\n\n# the PCs we want\npcs = eigvec[:, :ncomponents]",
      "names": [
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "linalg",
            "eig"
          ],
          "code_str": "np.linalg.eig",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "numpy.linalg.eig"
        },
        {
          "import_components": [
            "numpy",
            "argsort"
          ],
          "code_str": "np.argsort",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "numpy.argsort"
        }
      ],
      "example": {
        "document": "examples/reduction/Reference_Ch3_part_1_pca_step_by_step",
        "ref_id": "Eigen-Decomposition-of-Covariance-Matrix",
        "headings": [
          "PCA from Scratch (Eigen Decomposition)",
          "Eigen Decomposition of Covariance Matrix"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "eigval",
      "names": [],
      "example": {
        "document": "examples/reduction/Reference_Ch3_part_1_pca_step_by_step",
        "ref_id": "Eigen-Decomposition-of-Covariance-Matrix",
        "headings": [
          "PCA from Scratch (Eigen Decomposition)",
          "Eigen Decomposition of Covariance Matrix"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "eigvec",
      "names": [],
      "example": {
        "document": "examples/reduction/Reference_Ch3_part_1_pca_step_by_step",
        "ref_id": "Eigen-Decomposition-of-Covariance-Matrix",
        "headings": [
          "PCA from Scratch (Eigen Decomposition)",
          "Eigen Decomposition of Covariance Matrix"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig = plt.figure(figsize=(5, 5))\nplt.scatter(data[:, 0], data[:, 1], c=\"blue\", alpha=0.5, label=\"Original\")\n\nfor i in range(pcs.shape[1]):\n    plt.quiver(*(0, 0), *(pcs[:, i]),\n               scale=1, scale_units=\"xy\", angles=\"xy\", \\\n               color=colors[i], label=f\"PC{i+1}\")\n\n\nplt.legend(loc=(1.05, 0))\n# plt.axis(\"off\")\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/reduction/Reference_Ch3_part_1_pca_step_by_step",
        "ref_id": "Plot-PCs",
        "headings": [
          "PCA from Scratch (Eigen Decomposition)",
          "Plot PCs"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig = plt.figure(figsize=(5, 5))\nplt.scatter(data[:, 0], data[:, 1],\n            c=\"blue\", alpha=0.5, label=\"Original\")\nfor i in range(pcs.shape[1]):\n    pc = eigvec[:, i].reshape((-1, 1))\n    reconstruct = data@pc@pc.T\n\n    plt.scatter(reconstruct[:, 0], reconstruct[:, 1], \\\n        c=colors[i], alpha=0.5, label=f\"Reconstructed on PC{i+1}\")\n    plt.legend(loc=(1.05, 0))\n# plt.axis(\"off\")\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/reduction/Reference_Ch3_part_1_pca_step_by_step",
        "ref_id": "Plot-reconstructed-data-on-each-PC",
        "headings": [
          "PCA from Scratch (Eigen Decomposition)",
          "Plot reconstructed data on each PC"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "i = 0 # PC1\nk = 85 # a good datapoint\n\nfig = plt.figure(figsize=(5, 5))\nplt.scatter(data[:, 0], data[:, 1],\n            c=\"blue\", alpha=0.5, label=\"Original\")\n\nplt.quiver(*(0, 0), *(pcs[:, i]),\n            scale=1, scale_units=\"xy\", angles=\"xy\", \\\n            color=\"r\", label=f\"PC{i+1}\")\n\n\npc = eigvec[:, i].reshape((-1, 1))\nreconstruct = data@pc@pc.T\n\nplt.quiver(0, 0, reconstruct[k, 0], reconstruct[k, 1], \\\n    scale=1, scale_units=\"xy\", angles=\"xy\", \\\n    color=colors[i], label=f\"Projection on PC{i+1}\")\n\nplt.quiver(0, 0, data[k, 0], data[k, 1], \\\n    scale=1, scale_units=\"xy\", angles=\"xy\", \\\n    color=\"k\", label=f\"One point\")\n\nplt.quiver(reconstruct[k, 0], reconstruct[k, 1], # start point\n           data[k, 0]-reconstruct[k, 0], data[k, 1]-reconstruct[k, 1], # vector\n            scale=1, scale_units=\"xy\", angles=\"xy\", \\\n            color=\"green\", label=f\"Reconstruction Error\")\n\nplt.legend(loc=(1.05, 0))\n# plt.axis(\"off\")\nplt.axis(\"equal\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "axis"
          ],
          "code_str": "plt.axis",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.axis"
        }
      ],
      "example": {
        "document": "examples/reduction/Reference_Ch3_part_1_pca_step_by_step",
        "ref_id": "Plot-projection-of-one-datapoint-on-PC1",
        "headings": [
          "PCA from Scratch (Eigen Decomposition)",
          "Plot projection of one datapoint on PC1"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/representation/Reference_Ch2_fingerprints": [
    {
      "source": "!pip install rdkit",
      "names": [],
      "example": {
        "document": "examples/representation/Reference_Ch2_fingerprints",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    },
    {
      "source": "import numpy as np\nfrom collections import OrderedDict\n\nimport rdkit.Chem as Chem\nimport rdkit.Chem.AllChem as AllChem\nimport rdkit.Chem.Draw as Draw\nfrom rdkit.Chem.Draw import rdMolDraw2D\n\nfrom IPython.display import SVG",
      "names": [
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "collections"
          ],
          "code_str": "collections",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_from",
          "resolved_location": "collections"
        },
        {
          "import_components": [
            "collections",
            "OrderedDict"
          ],
          "code_str": "OrderedDict",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "collections.OrderedDict"
        },
        {
          "import_components": [
            "IPython",
            "display"
          ],
          "code_str": "IPython.display",
          "lineno": 9,
          "end_lineno": 9,
          "context": "import_from",
          "resolved_location": "IPython.display"
        },
        {
          "import_components": [
            "IPython",
            "display",
            "SVG"
          ],
          "code_str": "SVG",
          "lineno": 9,
          "end_lineno": 9,
          "context": "import_target",
          "resolved_location": "IPython.core.display.SVG"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_fingerprints",
        "ref_id": "Molecular-Fingerprints",
        "headings": [
          "Molecular Fingerprints"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "smi = \"Cn1c(=O)c2c(ncn2C)n(C)c1=O\"\nmol = Chem.MolFromSmiles(smi)",
      "names": [],
      "example": {
        "document": "examples/representation/Reference_Ch2_fingerprints",
        "ref_id": "Load-Caffeine-Molecule-from-SMILES",
        "headings": [
          "Molecular Fingerprints",
          "Load Caffeine Molecule from SMILES"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "width, height = 300, 300\n# Render high resolution molecule\n\ndrawer = rdMolDraw2D.MolDraw2DSVG(width, height)\nopts = drawer.drawOptions()\nopts.bondLineWidth = 5\ndrawer.DrawMolecule(mol)\ndrawer.FinishDrawing()\nsvg = drawer.GetDrawingText()\nSVG(svg)",
      "names": [
        {
          "import_components": [
            "IPython",
            "display",
            "SVG"
          ],
          "code_str": "SVG",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "IPython.core.display.SVG"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_fingerprints",
        "ref_id": "Draw",
        "headings": [
          "Molecular Fingerprints",
          "Draw"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "bi = {} # bit info\nfp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024, bitInfo=bi)\nprint(\"Number of 1-bit:\", np.sum(fp))",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "sum"
          ],
          "code_str": "np.sum",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.sum"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_fingerprints",
        "ref_id": "Morgan-Fingerprint",
        "headings": [
          "Molecular Fingerprints",
          "Morgan Fingerprint"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "on_bits = [(mol, i, bi) for i in fp.GetOnBits()]\nlabels = [f\"Bit {str(i[1])}\" for i in on_bits]\nDraw.DrawMorganBits(on_bits, molsPerRow=5, legends=labels)",
      "names": [
        {
          "import_components": [
            "str"
          ],
          "code_str": "str",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "str"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_fingerprints",
        "ref_id": "Morgan-Fingerprint",
        "headings": [
          "Molecular Fingerprints",
          "Morgan Fingerprint"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# predefine a few\nPATTERNS = OrderedDict({\n    \"alkane\": [\"[CX4]\"],\n    \"halogen\": [\"[$([F,Cl,Br,I]-!@[#6]);!$([F,Cl,Br,I]-!@C-!@[F,Cl,Br,I]);!$([F,Cl,Br,I]-[C,S](=[O,S,N]))]\"],\n    \"alcohol\": [\"[O;H1;$(O-!@[#6;!$(C=!@[O,N,S])])]\"],\n    \"ether\": [\"[OD2]([#6])[#6]\"],\n    \"amine\": [\"[NX3;H2,H1;!$(NC=O)]\"], # \"[N;$(N-[#6]);!$(N-[!#6;!#1]);!$(N-C=[O,N,S])]\"\n    \"amide\": [\"[NX3][CX3](=[OX1])[#6]\"],\n    \"enamine\": [\"[NX3][CX3]=[CX3]\"],\n    \"aldehyde\": [\"[CH;D2;!$(C-[!#6;!#1])]=O\"],\n    \"ketone\": [\"[#6][CX3](=O)[#6]\"],\n    \"carboxylic acids\": [\"[CX3](=O)[OX2H1]\"],\n})",
      "names": [
        {
          "import_components": [
            "collections",
            "OrderedDict"
          ],
          "code_str": "OrderedDict",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "collections.OrderedDict"
        },
        {
          "import_components": [
            "collections",
            "OrderedDict",
            "()"
          ],
          "code_str": "PATTERNS",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "collections.OrderedDict"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_fingerprints",
        "ref_id": "Functional-Group-Fingerprint",
        "headings": [
          "Molecular Fingerprints",
          "Functional Group Fingerprint"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def get_atomids_in_functional_group(mol, pat_strs):\n    results = []\n\n    for pat_str in pat_strs:\n        pattern = Chem.MolFromSmarts(pat_str)\n        matches = mol.GetSubstructMatches(pattern)\n        if matches:\n            results.extend(matches)\n    return results",
      "names": [],
      "example": {
        "document": "examples/representation/Reference_Ch2_fingerprints",
        "ref_id": "Functional-Group-Fingerprint",
        "headings": [
          "Molecular Fingerprints",
          "Functional Group Fingerprint"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# binary\nprint(\"Binary functional-group fingerprint:\")\nfor name, pattern_str in PATTERNS.items():\n    pat_strs = PATTERNS[name]\n    results = get_atomids_in_functional_group(mol, pat_strs)\n    print(f\"{name}: {1 if len(results) > 0 else 0}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "collections",
            "OrderedDict",
            "()"
          ],
          "code_str": "PATTERNS",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "collections.OrderedDict"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_fingerprints",
        "ref_id": "Functional-Group-Fingerprint",
        "headings": [
          "Molecular Fingerprints",
          "Functional Group Fingerprint"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# count-based\nprint(\"Count-based functional-group fingerprint:\")\nfor name, pattern_str in PATTERNS.items():\n    pat_strs = PATTERNS[name]\n    results = get_atomids_in_functional_group(mol, pat_strs)\n    print(f\"{name}: {len(results)}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "collections",
            "OrderedDict",
            "()"
          ],
          "code_str": "PATTERNS",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "collections.OrderedDict"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_fingerprints",
        "ref_id": "Functional-Group-Fingerprint",
        "headings": [
          "Molecular Fingerprints",
          "Functional Group Fingerprint"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/representation/Reference_Ch2_molecular_properties": [
    {
      "source": "!pip install rdkit wget",
      "names": [],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    },
    {
      "source": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport rdkit.Chem as Chem\nfrom rdkit.Chem import Descriptors\nfrom rdkit.Chem.rdmolops import GetAdjacencyMatrix\n\nfrom IPython.display import SVG",
      "names": [
        {
          "import_components": [
            "itertools"
          ],
          "code_str": "itertools",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "itertools"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "IPython",
            "display"
          ],
          "code_str": "IPython.display",
          "lineno": 9,
          "end_lineno": 9,
          "context": "import_from",
          "resolved_location": "IPython.display"
        },
        {
          "import_components": [
            "IPython",
            "display",
            "SVG"
          ],
          "code_str": "SVG",
          "lineno": 9,
          "end_lineno": 9,
          "context": "import_target",
          "resolved_location": "IPython.core.display.SVG"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Molecular-Descriptors",
        "headings": [
          "Molecular Descriptors"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "smi = \"C1=NC(=C2C(=N1)N(C=N2)[C@H]3[C@@H]([C@@H]([C@H](O3)COP(=O)(O)OP(=O)(O)OP(=O)(O)O)O)O)N\"\nmol = Chem.MolFromSmiles(smi)\nmol",
      "names": [],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Load-From-SMILES",
        "headings": [
          "Molecular Descriptors",
          "Load From SMILES"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# quantitative estimation of drug-likeness (QED)\nq = Descriptors.qed(mol)\nprint(\"QED:\", q)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Molecular-Properties",
        "headings": [
          "Molecular Descriptors",
          "Molecular Properties"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "## Download source code to compute synthetic availability score from rdkit\n!python -m wget https://raw.githubusercontent.com/rdkit/rdkit/master/Contrib/SA_Score/sascorer.py\n!python -m wget https://raw.githubusercontent.com/rdkit/rdkit/master/Contrib/SA_Score/fpscores.pkl.gz",
      "names": [],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Molecular-Properties",
        "headings": [
          "Molecular Descriptors",
          "Molecular Properties"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import os, sys\nfrom rdkit.Chem import RDConfig\n# using literature contributors\n# from https://github.com/rdkit/rdkit/tree/master/Contrib\nsys.path.append(os.path.join(RDConfig.RDContribDir, 'SA_Score'))\n\nimport sascorer\ns = sascorer.calculateScore(mol)\nprint(\"Synthetic Availability:\", s)",
      "names": [
        {
          "import_components": [
            "os"
          ],
          "code_str": "os",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "os"
        },
        {
          "import_components": [
            "sys"
          ],
          "code_str": "sys",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "sys"
        },
        {
          "import_components": [
            "os",
            "path",
            "join"
          ],
          "code_str": "os.path.join",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "os.path.join"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Molecular-Properties",
        "headings": [
          "Molecular Descriptors",
          "Molecular Properties"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# define a pattern\nprimary_amine = \"[NX3;H2;!$(NC=[!#6]);!$(NC#[!#6])][#6]\"\npattern = Chem.MolFromSmarts(primary_amine)\n# match the patter\nhits = mol.GetSubstructMatches(pattern)\nprint(f\"Number of amine functional group in ATP: {len(hits)}\")\nprint(f\"Atom indices in each selected functional group: {hits}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Functional-Groups",
        "headings": [
          "Molecular Descriptors",
          "Functional Groups"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "atom_ids = list(itertools.chain(*hits))\nprint(f\"Atoms matching the functional group: {atom_ids}\")\n\n\natoms = [] # get all atoms\nfor a in mol.GetAtoms():\n    atoms.append(a.GetIdx())\n\nbond_ids = []\nfor bond in mol.GetBonds():\n    aid1 = atoms[bond.GetBeginAtomIdx()]\n    aid2 = atoms[bond.GetEndAtomIdx()]\n    for hit in hits:\n        # make sure bonds connecting atoms in the same functional group\n        if (aid1 in hit) and (aid2 in hit):\n            bond_ids.append(mol.GetBondBetweenAtoms(aid1, aid2).GetIdx())\n            break\nprint(f\"Bonds matching the functional group: {bond_ids}\")",
      "names": [
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "itertools",
            "chain"
          ],
          "code_str": "itertools.chain",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "itertools.chain"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Functional-Groups",
        "headings": [
          "Molecular Descriptors",
          "Functional Groups"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def draw_single_mol(mol, size=(300, 300), **highlights):\n    # copy the molecule to avoid modifying molecule\n    mol = Chem.Mol(mol)\n    drawer = Chem.Draw.rdMolDraw2D.MolDraw2DSVG(*size)\n    if highlights is not None:\n        Chem.Draw.rdMolDraw2D.PrepareAndDrawMolecule(drawer, mol, **highlights)\n    else:\n        drawer.DrawMolecule(mol)\n    drawer.FinishDrawing()\n    svg = drawer.GetDrawingText()\n    return svg.replace('svg:','')",
      "names": [],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Functional-Groups",
        "headings": [
          "Molecular Descriptors",
          "Functional Groups"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "SVG(\n    draw_single_mol(mol, highlightAtoms=atom_ids, highlightBonds=bond_ids)\n   )",
      "names": [
        {
          "import_components": [
            "IPython",
            "display",
            "SVG"
          ],
          "code_str": "SVG",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "IPython.core.display.SVG"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Functional-Groups",
        "headings": [
          "Molecular Descriptors",
          "Functional Groups"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def mol_with_atom_index(mol):\n    mol = Chem.Mol(mol)\n    for atom in mol.GetAtoms():\n        atom.SetAtomMapNum(atom.GetIdx())\n    return mol\n\nSVG(draw_single_mol(mol_with_atom_index(mol)))",
      "names": [
        {
          "import_components": [
            "IPython",
            "display",
            "SVG"
          ],
          "code_str": "SVG",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "IPython.core.display.SVG"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Molecular-Graph",
        "headings": [
          "Molecular Descriptors",
          "Molecular Graph"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "adjacency_matrix = GetAdjacencyMatrix(mol)\nprint(\"Shape of Adjacency matrix:\", adjacency_matrix.shape)\n\n## uncomment the following command to print the adjacency matrix,\n# and check a few adjacency_matrix[i][j] with the atom indices indicated above\n\nadjacency_matrix",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Molecular-Graph",
        "headings": [
          "Molecular Descriptors",
          "Molecular Graph"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "allowed_atom_types = [\"C\", \"N\", \"O\", \"P\"]\n# create onehot embeddings\n# dim+1 to deal with unknown types\natom_emb = np.zeros((len(mol.GetAtoms()), len(allowed_atom_types)+1))\nfor atom in mol.GetAtoms():\n    try:\n        atom_idx = atom.GetIdx()\n        ele = atom.GetSymbol()\n        type_idx = allowed_atom_types.index(ele)\n        atom_emb[atom_idx, type_idx] = 1\n    except:\n        atom_emb[atom_idx, -1] = 1",
      "names": [
        {
          "import_components": [
            "numpy",
            "zeros"
          ],
          "code_str": "np.zeros",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.zeros"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Molecular-Graph",
        "headings": [
          "Molecular Descriptors",
          "Molecular Graph"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "atom_emb",
      "names": [],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Molecular-Graph",
        "headings": [
          "Molecular Descriptors",
          "Molecular Graph"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "allowed_bond_types = [Chem.rdchem.BondType.SINGLE, Chem.rdchem.BondType.DOUBLE, \\\n                      Chem.rdchem.BondType.TRIPLE, Chem.rdchem.BondType.AROMATIC]\n# create onehot embeddings\n# dim+1 to deal with unknown types\nbond_emb = np.zeros((len(mol.GetBonds()), len(allowed_bond_types)+1))\nfor bond in mol.GetBonds():\n    try:\n        bond_idx = bond.GetIdx()\n        b_type = bond.GetBondType()\n        type_idx = allowed_bond_types.index(b_type)\n        bond_emb[bond_idx, type_idx] = 1\n    except:\n        bond_emb[bond_idx, -1] = 1",
      "names": [
        {
          "import_components": [
            "numpy",
            "zeros"
          ],
          "code_str": "np.zeros",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.zeros"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Molecular-Graph",
        "headings": [
          "Molecular Descriptors",
          "Molecular Graph"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "bond_emb",
      "names": [],
      "example": {
        "document": "examples/representation/Reference_Ch2_molecular_properties",
        "ref_id": "Molecular-Graph",
        "headings": [
          "Molecular Descriptors",
          "Molecular Graph"
        ]
      },
      "doc_lineno": null
    }
  ],
  "examples/transformer/Reference_Ch8_PLM_colab": [
    {
      "source": "!pip install numpy pandas matplotlib torch wget seaborn scikit-learn transformers",
      "names": [],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Predict-log-EC50s-of-Dual-Agonists-Peptide-using-Pretrained-Protein-Language-Model",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\n\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2",
      "names": [
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Import-Packages",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Import Packages"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", device)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Import-Packages",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Import Packages"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# download the pre-processed dataset from github\n!python -m wget https://raw.githubusercontent.com/xuhuihuang/uwmadisonchem361/main/CNN_training_data.csv \\\n--output CNN_training_data.csv",
      "names": [],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Load-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "filename = \"CNN_training_data.csv\"\ndf = pd.read_csv(filename)\ndf",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Load-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from transformers import AutoTokenizer\nmodel_name = \"facebook/esm2_t6_8M_UR50D\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nprint(f\"Number of tokens: {tokenizer.vocab_size}\")\nprint(\"Vocabulary:\", tokenizer.get_vocab())",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Create-PyTorch-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Create PyTorch Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "seq = df.iloc[0][\"Aligned_Sequence\"]\nprint(f\"Sequence: {seq}\")\n\ntokens = tokenizer.tokenize(seq)\nprint(f\"Tokens: {tokens}\")\n\ntoken_ids = tokenizer(seq, max_length=30, \\\n    padding=False, truncation=False, return_tensors=\"pt\")\nprint(f\"Token IDs: {token_ids}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Create-PyTorch-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Create PyTorch Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def encode_sequence(sequence):\n    return tokenizer(sequence, padding=False, truncation=False, \\\n        return_tensors=\"pt\")[\"input_ids\"]",
      "names": [],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Create-PyTorch-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Create PyTorch Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class PeptideDataset(Dataset):\n    def __init__(self, df, encoder,\n                 seq_col=\"Aligned_Sequence\", target_cols=(\"EC50_LOG_T1\", \"EC50_LOG_T2\")):\n        self.df = df\n        self.encoder = encoder\n        self.seq_col = seq_col\n        self.target_cols = target_cols\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        sequence = row[self.seq_col]\n        indices = self.encoder(sequence)\n        label = [row[col] for col in self.target_cols]\n        return indices.reshape(-1), torch.tensor(label, dtype=float).reshape(-1)",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "float"
          ],
          "code_str": "float",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "float"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Create-PyTorch-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Create PyTorch Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.model_selection import train_test_split\n\n# training/validation dataset\ndata_size = df.shape[0]\ntest_ratio = 0.10\ntest_size = int(data_size*test_ratio)\ntrain_indices, test_indices = train_test_split(range(data_size), test_size=test_size, shuffle=True)\nprint(f\"Training size: {len(train_indices)}, test size: {len(test_indices)}\")\ntrain_df, test_df = df.iloc[train_indices], df.iloc[test_indices]",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Split-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Split Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# create dataloaders\nbatch_size = 10\nencoder = encode_sequence\ntrain_data = PeptideDataset(train_df, encoder=encoder)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n                                           shuffle=True, drop_last=False)\ntest_data = PeptideDataset(test_df, encoder=encoder)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n                                          shuffle=False, drop_last=False)",
      "names": [],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Split-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Split Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "train_data[0]",
      "names": [],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Split-Dataset",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Split Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from transformers import AutoModel\nmodel = AutoModel.from_pretrained(model_name)\nprint(\"Number of parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\ndummy_input = torch.zeros(1, 3).long()\noutput_dct = model(dummy_input)\nprint(\"Output dictionary keys:\", output_dct.keys())\nprint(\"Last hidden state shape:\", output_dct[\"last_hidden_state\"].shape) # per residue\nprint(\"Pooler output shape:\", output_dct[\"pooler_output\"].shape) # per sequence",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "sum"
          ],
          "code_str": "sum",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "sum"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Protein-Language-Model-(PLM)",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Protein Language Model (PLM)"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import torch.nn as nn\nclass MultiHeadModel(nn.Module):\n\n    def __init__(self, esm_name, encoder_frozen=True, dropout=0.3):\n        super().__init__()\n        # encode each sequence to a vector\n        model = AutoModel.from_pretrained(esm_name)\n        self.base_model = model\n        self.encoder_frozen = encoder_frozen\n        if self.encoder_frozen:\n            for _, param in self.base_model.named_parameters():\n                param.requires_grad = False\n\n        ## calculate output dim of the base model\n        self.dummy_input = torch.zeros(1, 1)\n        self.flattened_size = self._calculate_flattened_size()\n\n        self.fc = nn.Linear(in_features=self.flattened_size, out_features=64, bias=True)\n\n        self.dropout = nn.Dropout(dropout)\n\n        # fully connected layer for GCGR\n        self.head_1 = nn.Linear(in_features=64, out_features=1, bias=True)\n\n        # fully connected layer for GLP-1R\n        self.head_2 = nn.Linear(in_features=64, out_features=1, bias=True)\n\n    def _calculate_flattened_size(self):\n        \"\"\"Pass dummy data through the network to get the flattened size.\"\"\"\n        with torch.no_grad():\n            input_seqs = self.dummy_input.long()\n            base_out_dict = self.base_model(input_seqs)\n            hidden_dim = base_out_dict[\"pooler_output\"].shape[-1]\n        return hidden_dim\n\n\n    def forward(self, input_seqs):\n        input_seqs = input_seqs.long()\n        base_out_dict = self.base_model(input_seqs)\n\n        # amino acid embeddings pooled to a sequence embedding\n        base_out = base_out_dict[\"pooler_output\"]\n        base_out = self.fc(base_out)\n\n        # two linear head\n        out_1 = self.head_1(self.dropout(base_out))\n        out_2 = self.head_2(self.dropout(base_out))\n\n        return torch.cat([out_1, out_2], dim=1)",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "super"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Model-Wrapper",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Model Wrapper"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def train_one_epoch(model, criterion, optimizer, dataloader):\n    losses = []\n    model.train()\n    for x, y_true in dataloader:\n        if device == \"cuda\":\n            x, y_true = x.to(device), y_true.to(device)\n        y_true = y_true.float()\n        optimizer.zero_grad()\n        y_pred = model(x)\n        loss = criterion(y_pred, y_true.squeeze(1))\n        loss.backward()\n        optimizer.step()\n        losses.append(loss.cpu().detach().item())\n    return losses\n\n\ndef val_one_epoch(model, criterion, dataloader):\n    losses = []\n    model.eval()\n    with torch.no_grad():\n        for x, y_true in dataloader:\n            if device == \"cuda\":\n                x, y_true = x.to(device), y_true.to(device)\n            y_true = y_true.float()\n            y_pred = model(x)\n            loss = criterion(y_pred, y_true.squeeze(1))\n            losses.append(loss.cpu().detach().item())\n    return losses",
      "names": [],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Training-Utils",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Training Utils"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# loss function: 0.5 GCGR MSE + 0.5 GLP-1R MSE\ndef multi_task_loss(y_pred, y_true):\n    y1_pred, y1_true = y_pred[:, 0], y_true[:, 0]\n    y2_pred, y2_true = y_pred[:, -1], y_true[:, -1]\n    mse1 = nn.MSELoss()(y1_pred, y1_true)\n    mse2 = nn.MSELoss()(y2_pred, y2_true)\n    return 0.5 * mse1 + 0.5 * mse2",
      "names": [],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Training-Utils",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Training Utils"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "model = MultiHeadModel(esm_name=model_name, encoder_frozen=True, dropout=0.3)\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\"Total number of parameters: {total_params}\")\n\n\nmodel = model.to(device)\nmodel = model.float()\ncriterion = multi_task_loss\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\nn_epochs = 500",
      "names": [
        {
          "import_components": [
            "sum"
          ],
          "code_str": "sum",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "sum"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Training",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Training"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "train_loss = []\nval_loss = []\n\nfor epoch in range(n_epochs):\n    losses = train_one_epoch(model, criterion, optimizer, train_loader)\n    train_loss.append(np.mean(losses))\n    losses = val_one_epoch(model, criterion, test_loader)\n    val_loss.append(np.mean(losses))\n    if epoch % 20 == 0:\n        print(f\"Epoch: {epoch}\")",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Training",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Training"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(train_loss, c=\"blue\", label=\"Training\")\nax.plot(val_loss, c=\"red\", label=\"Test\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Training",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Training"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "truths = []\npredictions = []\nmodel.eval()\nwith torch.no_grad():\n    for x,y in test_loader:\n        if device == \"cuda\":\n            x = x.to(device)\n        x = x.float()\n\n        y_pred = model(x)\n        predictions.extend(y_pred.cpu().detach().numpy().tolist())\n\n        y = y.squeeze(1).float().numpy().tolist()\n        truths.extend(y)",
      "names": [],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Evaluation-metrics",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Evaluation metrics"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "y1_true = [pair[0] for pair in truths]\ny1_pred = [pair[0] for pair in predictions]\ny2_true = [pair[1] for pair in truths]\ny2_pred = [pair[1] for pair in predictions]\ntmp_df = pd.DataFrame({\"y1\": y1_true, r\"$\\hat{y_1}$\": y1_pred,\n                       \"y2\": y2_true, r\"$\\hat{y_2}$\": y2_pred})\n\n# scatter plot\ng = sns.JointGrid(x=\"y1\", y=r\"$\\hat{y_1}$\", data=tmp_df)\ng = g.plot_joint(plt.scatter, c=\"green\", alpha=0.5)\n\n# line: y_pred = y\ny_line = np.linspace(np.min(y1_true), np.max(y1_true), 200)\ng.ax_joint.plot(y_line, y_line, color=\"blue\", linestyle=\"--\");\n\n# histograms\ng = g.plot_marginals(sns.histplot, data=df, color=\"green\", kde=False)\n\ng.ax_joint.set_xlim(np.min(y_line), np.max(y_line))\ng.ax_joint.set_ylim(np.min(y_line), np.max(y_line))\n\nplt.show()",
      "names": [
        {
          "import_components": [
            "pandas",
            "DataFrame"
          ],
          "code_str": "pd.DataFrame",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "pandas.DataFrame"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "GCGR",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Evaluation metrics",
          "GCGR"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(f\"MSE: {mean_squared_error(y1_true, y1_pred):.2f}\")\nprint(f\"Coefficient of determination: {r2_score(y1_true, y1_pred):.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "GCGR",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Evaluation metrics",
          "GCGR"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# scatter plot\ng = sns.JointGrid(x=\"y2\", y=r\"$\\hat{y_2}$\", data=tmp_df)\ng = g.plot_joint(plt.scatter, c=\"blue\", alpha=0.5, label=\"GLP-1R\")\n\n# line: y_pred = y\ny_line = np.linspace(np.min(y2_true), np.max(y2_true), 200)\ng.ax_joint.plot(y_line, y_line, color=\"blue\", linestyle=\"--\");\n\n# histograms\ng = g.plot_marginals(sns.histplot, data=df, color=\"blue\", kde=False)\n\ng.ax_joint.set_xlim(np.min(y_line), np.max(y_line))\ng.ax_joint.set_ylim(np.min(y_line), np.max(y_line))\n\nplt.show()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "GLP-1R",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Evaluation metrics",
          "GLP-1R"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(f\"MSE: {mean_squared_error(y2_true, y2_pred):.2f}\")\nprint(f\"Coefficient of determination: {r2_score(y2_true, y2_pred):.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "GLP-1R",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Evaluation metrics",
          "GLP-1R"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.model_selection import KFold\n\nbatch_size = 10\nn_splits = 6\nn_epochs = 600\n\n# cross validation\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\nall_indices = np.arange(df.shape[0])\ncriterion = multi_task_loss",
      "names": [
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.arange"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Cross-Validation",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Cross Validation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def run_one_fold(train_df, test_df):\n    encoder = encode_sequence\n    train_data = PeptideDataset(train_df, encoder=encoder)\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n                                            shuffle=True, drop_last=False)\n    test_data = PeptideDataset(test_df, encoder=encoder)\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n                                            shuffle=False, drop_last=False)\n\n    model = MultiHeadModel(esm_name=model_name, encoder_frozen=True, dropout=0.3)\n\n    model = model.to(device)\n    model = model.float()\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n    train_loss = []\n    val_loss = []\n\n    for epoch in range(n_epochs):\n        losses = train_one_epoch(model, criterion, optimizer, train_loader)\n        train_loss.append(np.mean(losses))\n        losses = val_one_epoch(model, criterion, test_loader)\n        val_loss.append(np.mean(losses))\n\n    truths = []\n    predictions = []\n    model.eval()\n    with torch.no_grad():\n        for x,y in test_loader:\n            if device == \"cuda\":\n                x = x.to(device)\n            x = x.float()\n            y_pred = model(x)\n            predictions.extend(y_pred.cpu().detach().numpy().tolist())\n\n            y = y.squeeze(1).float().numpy().tolist()\n            truths.extend(y)\n    return truths, predictions",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Cross-Validation",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Cross Validation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.metrics import mean_squared_error\ntask_results = []\n\nn_threads = n_splits\n\nfor train_index, test_index in kf.split(all_indices):\n    train_df, test_df = df.iloc[train_indices], df.iloc[test_indices]\n    truths, predictions = run_one_fold(train_df, test_df)\n\n    y1_true = [pair[0] for pair in truths]\n    y1_pred = [pair[0] for pair in predictions]\n    y2_true = [pair[1] for pair in truths]\n    y2_pred = [pair[1] for pair in predictions]\n\n    mse1 = mean_squared_error(y1_true, y1_pred)\n    mse2 = mean_squared_error(y2_true, y2_pred)\n    task_results.append([mse1, mse2])",
      "names": [],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Cross-Validation",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Cross Validation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "avg_rmse = np.array(np.sqrt(task_results)).mean(axis=0)\nstd_rmse = np.array(np.sqrt(task_results)).std(axis=0)\nprint(f\"RMSE: {avg_rmse}\")\nprint(f\"Std of RMSE: {std_rmse}\")",
      "names": [
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "examples/transformer/Reference_Ch8_PLM_colab",
        "ref_id": "Cross-Validation",
        "headings": [
          "Predict log EC50s of Dual-Agonists Peptide using Pretrained Protein Language Model",
          "Cross Validation"
        ]
      },
      "doc_lineno": null
    }
  ],
  "homeworks": [
    {
      "source": ".. notes::\n\n   More problem sets are in development to further enhance the learning experience.",
      "names": [],
      "example": {
        "document": "homeworks",
        "ref_id": "hands-on-homeworks",
        "headings": [
          "Hands-on Homeworks"
        ]
      },
      "doc_lineno": null
    }
  ],
  "homeworks/hw0/Chem361_hw0_reference": [
    {
      "source": "!pip install pandas matplotlib rdkit scikit-learn wget",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "1.-Install-Dependencies",
        "headings": [
          "CHEM361 - Homework0",
          "1. Install Dependencies"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "2.-Download-Dataset",
        "headings": [
          "CHEM361 - Homework0",
          "2. Download Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import pandas as pd\n\nDELANEY_FILE = \"delaney-processed.csv\"\ndf = pd.read_csv(DELANEY_FILE)\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "3.-Load-Dataset",
        "headings": [
          "CHEM361 - Homework0",
          "3. Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# df.head(5) means print the top five rows of the DataFrame.\ndf.head(5)",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "3.-Load-Dataset",
        "headings": [
          "CHEM361 - Homework0",
          "3. Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from rdkit.Chem import PandasTools\n\nPandasTools.AddMoleculeColumnToFrame(df, \"smiles\", \"mol\")\ndf.head(5)",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "4.-Generate-Molecule",
        "headings": [
          "CHEM361 - Homework0",
          "4. Generate Molecule"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# df.iloc[0, -1] retrieves the value located at the intersection of the first row and the last column of the DataFrame.\ndf.iloc[0,-1]",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "4.-Generate-Molecule",
        "headings": [
          "CHEM361 - Homework0",
          "4. Generate Molecule"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "molecular_weight = df.iloc[:][\"Molecular Weight\"].values\nlog_solubility = df.iloc[:][\"ESOL predicted log solubility in mols per litre\"].values",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "5.-Obtain-Chemical-Properties",
        "headings": [
          "CHEM361 - Homework0",
          "5. Obtain Chemical Properties"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from matplotlib import pyplot as plt\n\nf, ax = plt.subplots(1,1,figsize=(3,3))\nax.scatter(molecular_weight,log_solubility,s=15, marker='o', facecolors='none', edgecolor=\"blue\")\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"log solubility (mol/L)\")",
      "names": [
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_from",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "pyplot",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "5.-Obtain-Chemical-Properties",
        "headings": [
          "CHEM361 - Homework0",
          "5. Obtain Chemical Properties"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.linear_model import LinearRegression\n\nX = molecular_weight.reshape(-1,1)\ny = log_solubility\n\nregressor = LinearRegression().fit(X, y)",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "6.-Linear-Regression",
        "headings": [
          "CHEM361 - Homework0",
          "6. Linear Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.metrics import mean_squared_error, r2_score\n\ny_pred = regressor.predict(X)\n\nprint(f\"Mean squared error: {mean_squared_error(y, y_pred):.2f}\")\nprint(f\"Coefficient of determination: {r2_score(y, y_pred):.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "6.-Linear-Regression",
        "headings": [
          "CHEM361 - Homework0",
          "6. Linear Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1,1,figsize=(3,3))\n\nax.scatter(molecular_weight,log_solubility,s=15, marker='o', facecolors='none', edgecolor=\"blue\", label=\"All data points\")\nax.plot(\n    X,\n    regressor.predict(X),\n    linewidth=2,\n    color=\"tab:orange\",\n    label=\"Model predictions\",\n)\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"log solubility (mol/L)\")\nax.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "6.-Linear-Regression",
        "headings": [
          "CHEM361 - Homework0",
          "6. Linear Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.model_selection import train_test_split\n\ntest_size = int(len(X)*0.1) # do 90:10 train:test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "7.-Linear-Regression-with-Model-Validation",
        "headings": [
          "CHEM361 - Homework0",
          "7. Linear Regression with Model Validation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "regressor = LinearRegression().fit(X_train, y_train)\n\ny_pred = regressor.predict(X_train)\n\nprint(f\"Mean squared error on training set: {mean_squared_error(y_train, y_pred):.2f}\")\nprint(f\"Coefficient of determination on training set: {r2_score(y_train, y_pred):.2f}\")\n\ny_pred = regressor.predict(X_test)\n\nprint(f\"Mean squared error on test set: {mean_squared_error(y_test, y_pred):.2f}\")\nprint(f\"Coefficient of determination on test set: {r2_score(y_test, y_pred):.2f}\")\n\n# You\u2019ll notice that the error on test set is larger, which is expected since you\u2019re evaluating the model on unseen data.",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "7.-Linear-Regression-with-Model-Validation",
        "headings": [
          "CHEM361 - Homework0",
          "7. Linear Regression with Model Validation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1,2,figsize=(7,3), sharex=True, sharey=True)\n\nax[0].scatter(X_train,y_train,s=15, marker='o', facecolors='none', edgecolor=\"blue\", label=\"Train data points\")\nax[0].plot(\n    X_train,\n    regressor.predict(X_train),\n    linewidth=2,\n    color=\"tab:orange\",\n    label=\"Model predictions\",\n)\nax[0].set_xlabel(\"Molecular Weight (Da.)\")\nax[0].set_ylabel(\"log solubility (mol/L)\")\nax[0].legend()\nax[0].set_title('Train set')\n\nax[1].scatter(X_test,y_test,s=15, marker='o', facecolors='none', edgecolor=\"blue\", label=\"Test data points\")\nax[1].plot(\n    X_test,\n    regressor.predict(X_test),\n    linewidth=2,\n    color=\"tab:orange\",\n    label=\"Model predictions\",\n)\nax[1].set_xlabel(\"Molecular Weight (Da.)\")\nax[1].set_ylabel(\"log solubility (mol/L)\")\nax[1].legend()\nax[1].set_title('Test set')",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_reference",
        "ref_id": "7.-Linear-Regression-with-Model-Validation",
        "headings": [
          "CHEM361 - Homework0",
          "7. Linear Regression with Model Validation"
        ]
      },
      "doc_lineno": null
    }
  ],
  "homeworks/hw0/Chem361_hw0_solutions": [
    {
      "source": "!pip install pandas matplotlib rdkit scikit-learn wget",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "CHEM361---Homework0-Solutions",
        "headings": [
          "CHEM361 - Homework0 Solutions"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!python -m wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "CHEM361---Homework0-Solutions",
        "headings": [
          "CHEM361 - Homework0 Solutions"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import pandas as pd\n\nDELANEY_FILE = \"delaney-processed.csv\"\ndf = pd.read_csv(DELANEY_FILE)\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q1.1",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q1",
          "Q1.1"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "df.head(5)",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q1.1",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q1",
          "Q1.1"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import numpy as np\nmolecular_weight = df.iloc[:][\"Molecular Weight\"].values\nprint(\"Min MW:\", np.min(molecular_weight))\nprint(\"Max MW:\", np.max(molecular_weight))",
      "names": [
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "numpy.max"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q1.2",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q1",
          "Q1.2"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "num_rings = df.iloc[:][\"Number of Rings\"].values\nmask = num_rings >= 2\nnew_df = df[mask]\n\n# print to check molecules with at least two rings are filtered\nnew_df.head(5)",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q1.3",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q1",
          "Q1.3"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(\"Number of chemical compounds with at least two rings:\", new_df.shape[0])",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q1.3",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q1",
          "Q1.3"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# select any two from Q1.4\n# I will select the first two\ntwo_rows_df = new_df.iloc[:2]\ntwo_rows_df",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q1.4",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q1",
          "Q1.4"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# print Compound ID and SMILES\nfor idx, row in two_rows_df.iterrows():\n    print(\"Compound ID:\", row[\"Compound ID\"])\n    print(\"SMILES:\", row[\"smiles\"])",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q1.4",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q1",
          "Q1.4"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from rdkit.Chem import PandasTools\n\n# get molecule from smiles\nPandasTools.AddMoleculeColumnToFrame(two_rows_df, \"smiles\", \"mol\")\ntwo_rows_df",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q1.5",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q1",
          "Q1.5"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# Just in case the above cell didn't show image,\n# try plot the two molecules one-by-one.\n# We will learn how to plot multiple mol images at once later in the course\n\n# plot the first molecule\ntwo_rows_df.iloc[0, -1]",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q1.5",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q1",
          "Q1.5"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# plot the second molecule\ntwo_rows_df.iloc[1, -1]",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q1.5",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q1",
          "Q1.5"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# get data we need\nlog_solubility = df.iloc[:][\"ESOL predicted log solubility in mols per litre\"].values\n\n# prepare X and y\nX = molecular_weight.reshape(-1,1)\ny = log_solubility",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q2.1",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q2",
          "Q2.1"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.model_selection import train_test_split\n\n# do 70:30 train:test split\ntest_size = int(len(X)*0.3)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q2.1",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q2",
          "Q2.1"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.linear_model import LinearRegression\n\n# fit the model using training data\nregressor = LinearRegression().fit(X_train, y_train)\n\n# print slope and intercept\nprint(\"Slope:\", regressor.coef_)\nprint(\"Intercept:\", regressor.intercept_)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q2.1",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q2",
          "Q2.1"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.metrics import mean_squared_error, r2_score\n\ny_pred_train = regressor.predict(X_train)\nprint(f\"MSE of training: {mean_squared_error(y_train, y_pred_train):.2f}\")\n\ny_pred_test = regressor.predict(X_test)\nprint(f\"MSE of test: {mean_squared_error(y_test, y_pred_test):.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q2.2",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q2",
          "Q2.2"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(f\"Coefficient of determination on training data: {r2_score(y_train, y_pred_train):.2f}\")\nprint(f\"Coefficient of determination on test data: {r2_score(y_test, y_pred_test):.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q2.2",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q2",
          "Q2.2"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from matplotlib import pyplot as plt\n\nf, ax = plt.subplots(1,2,figsize=(7,3), sharex=True, sharey=True)\n\nax[0].scatter(X_train,y_train,s=15, marker='o', facecolors='none', edgecolor=\"blue\", label=\"Train data points\")\nax[0].plot(\n    X_train,\n    regressor.predict(X_train),\n    linewidth=2,\n    color=\"tab:orange\",\n    label=\"Model predictions\",\n)\nax[0].set_xlabel(\"Molecular Weight (Da.)\")\nax[0].set_ylabel(\"log solubility (mol/L)\")\nax[0].legend()\nax[0].set_title('Train set')\n\nax[1].scatter(X_test,y_test,s=15, marker='o', facecolors='none', edgecolor=\"blue\", label=\"Test data points\")\nax[1].plot(\n    X_test,\n    regressor.predict(X_test),\n    linewidth=2,\n    color=\"tab:orange\",\n    label=\"Model predictions\",\n)\nax[1].set_xlabel(\"Molecular Weight (Da.)\")\nax[1].set_ylabel(\"log solubility (mol/L)\")\nax[1].legend()\nax[1].set_title('Test set')",
      "names": [
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_from",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "pyplot",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q-2.3",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q2",
          "Q 2.3"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# copy the code and change the column to pick\npolar_surface_area = df.iloc[:][\"Polar Surface Area\"].values\n\n# prepare X and y\nX = polar_surface_area.reshape(-1,1)\ny = log_solubility",
      "names": [],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q2.4",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q2",
          "Q2.4"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# split data\ntest_size = int(len(X)*0.3)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q2.4",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q2",
          "Q2.4"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# fit the model\nregressor = LinearRegression().fit(X_train, y_train)\n\n# print slope and intercept\nprint(\"Slope:\", regressor.coef_)\nprint(\"Intercept:\", regressor.intercept_)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q2.4",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q2",
          "Q2.4"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# plot mse of training and test\n\ny_pred_train = regressor.predict(X_train)\nprint(f\"MSE of training: {mean_squared_error(y_train, y_pred_train):.2f}\")\n\ny_pred_test = regressor.predict(X_test)\nprint(f\"MSE of test: {mean_squared_error(y_test, y_pred_test):.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q2.4",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q2",
          "Q2.4"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(f\"Coefficient of determination on training data: {r2_score(y_train, y_pred_train):.2f}\")\nprint(f\"Coefficient of determination on test data: {r2_score(y_test, y_pred_test):.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q2.4",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q2",
          "Q2.4"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1,2,figsize=(7,3), sharex=True, sharey=True)\n\nax[0].scatter(X_train,y_train,s=15, marker='o', facecolors='none', edgecolor=\"blue\", label=\"Train data points\")\nax[0].plot(\n    X_train,\n    regressor.predict(X_train),\n    linewidth=2,\n    color=\"tab:orange\",\n    label=\"Model predictions\",\n)\nax[0].set_xlabel(\"Polar Surface Area\") # change x labels\nax[0].set_ylabel(\"log solubility (mol/L)\")\nax[0].legend()\nax[0].set_title('Train set')\n\nax[1].scatter(X_test,y_test,s=15, marker='o', facecolors='none', edgecolor=\"blue\", label=\"Test data points\")\nax[1].plot(\n    X_test,\n    regressor.predict(X_test),\n    linewidth=2,\n    color=\"tab:orange\",\n    label=\"Model predictions\",\n)\nax[1].set_xlabel(\"Polar Surface Area\") # change x labels\nax[1].set_ylabel(\"log solubility (mol/L)\")\nax[1].legend()\nax[1].set_title('Test set')",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        }
      ],
      "example": {
        "document": "homeworks/hw0/Chem361_hw0_solutions",
        "ref_id": "Q2.4",
        "headings": [
          "CHEM361 - Homework0 Solutions",
          "Q2",
          "Q2.4"
        ]
      },
      "doc_lineno": null
    }
  ],
  "homeworks/hw1/Chem361_hw1_reference": [
    {
      "source": "!pip install pandas matplotlib rdkit scikit-learn wget\n\n!python -m wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv \\\n    --output delaney-processed.csv",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "1.-Install-Dependencies-and-Download-Dataset",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "1. Install Dependencies and Download Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import rdkit.Chem as Chem\n\n# caffeine\nsmi = \"Cn1c(=O)c2c(ncn2C)n(C)c1=O\"\nmol = Chem.MolFromSmiles(smi)\nmol",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "2.1-Load-Molecule-from-SMILES",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "2. Molecular Representations",
          "2.1 Load Molecule from SMILES"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "Chem.MolToSmiles(mol, canonical=True)",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "2.2-Canonical-SMILES",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "2. Molecular Representations",
          "2.2 Canonical SMILES"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "smi1 = \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\"\nmol1 = Chem.MolFromSmiles(smi1)\ncan_smi1 = Chem.MolToSmiles(mol1, canonical=True)\nprint(f\"The canonical SMILES in RDKit for {smi1} is {can_smi1}\")\nmol1",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "2.2-Canonical-SMILES",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "2. Molecular Representations",
          "2.2 Canonical SMILES"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "smi2 = \"CN1C(=O)C2=C(N=CN2C)N(C)C1=O\"\nmol2 = Chem.MolFromSmiles(smi2)\ncan_smi2 = Chem.MolToSmiles(mol2, canonical=True)\nprint(f\"The canonical SMILES in RDKit for {smi2} is {can_smi2}\")\nmol2",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "2.2-Canonical-SMILES",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "2. Molecular Representations",
          "2.2 Canonical SMILES"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import rdkit.Chem.AllChem as AllChem\n\nfp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024)",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "2.3.-Morgan-Fingerprints-and-Bit-Collisions",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "2. Molecular Representations",
          "2.3. Morgan Fingerprints and Bit Collisions"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(\"Positions of 1-bit:\")\nfor idx in fp.GetOnBits():\n    print(idx, end=\", \")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "2.3.-Morgan-Fingerprints-and-Bit-Collisions",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "2. Molecular Representations",
          "2.3. Morgan Fingerprints and Bit Collisions"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import rdkit.Chem.Draw as Draw\n\nbi = {} # bit info\nfp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=2048, bitInfo=bi)\n\nidx = 33\non_bits = [(mol, idx, bi)]\nlabels = [f\"Bit {str(idx)}\"]\nDraw.DrawMorganBits(on_bits, molsPerRow=1, legends=labels)",
      "names": [
        {
          "import_components": [
            "str"
          ],
          "code_str": "str",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "str"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "2.3.-Morgan-Fingerprints-and-Bit-Collisions",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "2. Molecular Representations",
          "2.3. Morgan Fingerprints and Bit Collisions"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import numpy as np\nimport rdkit.Chem.Descriptors as Descriptors\nproperty_array = np.array([\n    Descriptors.MolWt(mol),\n    Chem.Lipinski.NumHAcceptors(mol),\n    Chem.Lipinski.NumHDonors(mol),\n    Chem.Lipinski.RingCount(mol)\n])\nprint(\"Custom molecular descriptor array:\", property_array)",
      "names": [
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "2.4.-Molecular-Properties",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "2. Molecular Representations",
          "2.4. Molecular Properties"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# quantitative estimation of drug-likeness (QED)\nq = Descriptors.qed(mol)\nprint(\"QED of caffeine:\", q)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "2.4.-Molecular-Properties",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "2. Molecular Representations",
          "2.4. Molecular Properties"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "## Download source code to compute synthetic availability score from rdkit\n!python -m wget https://raw.githubusercontent.com/rdkit/rdkit/master/Contrib/SA_Score/sascorer.py\n!python -m wget https://raw.githubusercontent.com/rdkit/rdkit/master/Contrib/SA_Score/fpscores.pkl.gz",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "2.4.-Molecular-Properties",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "2. Molecular Representations",
          "2.4. Molecular Properties"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import os, sys\nfrom rdkit.Chem import RDConfig\n# using literature contributors\n# from https://github.com/rdkit/rdkit/tree/master/Contrib\nsys.path.append(os.path.join(RDConfig.RDContribDir, 'SA_Score'))\n\nimport sascorer\ns = sascorer.calculateScore(mol)\nprint(\"Synthetic Availability:\", s)",
      "names": [
        {
          "import_components": [
            "os"
          ],
          "code_str": "os",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "os"
        },
        {
          "import_components": [
            "sys"
          ],
          "code_str": "sys",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "sys"
        },
        {
          "import_components": [
            "os",
            "path",
            "join"
          ],
          "code_str": "os.path.join",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "os.path.join"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "2.4.-Molecular-Properties",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "2. Molecular Representations",
          "2.4. Molecular Properties"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import pandas as pd\n\nDELANEY_FILE = \"delaney-processed.csv\"\ndf = pd.read_csv(DELANEY_FILE)\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "3.1-Load-Dataset",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "3. Work on a Dataset",
          "3.1 Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "df.head(5)",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "3.1-Load-Dataset",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "3. Work on a Dataset",
          "3.1 Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from rdkit.Chem import PandasTools\nPandasTools.AddMoleculeColumnToFrame(df, \"smiles\", \"mol\")",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "3.2.-Pandas-DataFrame-Operations",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "3. Work on a Dataset",
          "3.2. Pandas DataFrame Operations"
        ]
      },
      "doc_lineno": 1010
    },
    {
      "source": "# fetch the smiles column in df\nsmis = df[\"smiles\"]\n\n# apply Chem.MolFromSmiles for each SMILES string\n# mols is a column of molecules\nmols = smis.apply(lambda x: Chem.MolFromSmiles(x))\n\n# add mols to df\ndf[\"mol\"] = mols",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "3.2.-Pandas-DataFrame-Operations",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "3. Work on a Dataset",
          "3.2. Pandas DataFrame Operations"
        ]
      },
      "doc_lineno": 1017
    },
    {
      "source": "# get molecules from smiles\ndf[\"mol\"] = df[\"smiles\"].apply(lambda x: Chem.MolFromSmiles(x))",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "3.2.-Pandas-DataFrame-Operations",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "3. Work on a Dataset",
          "3.2. Pandas DataFrame Operations"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# rdFingerprintGenerator is recommended in the newer versions of rdkit to replace AllChem.GetMorganFingerprintAsBitVect\nfrom rdkit.Chem import rdFingerprintGenerator\n\nmorgan_fp_gen = rdFingerprintGenerator.GetMorganGenerator(includeChirality=True, radius=2, fpSize=1024)\n\n# morgan_fp_gen.GetFingerprint(mol) converts a mol to a fingerprint\n# we use apply to convert all mols to fingerprints\ndf[\"fp\"] = df[\"mol\"].apply(lambda x: morgan_fp_gen.GetFingerprint(x))",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "3.2.-Pandas-DataFrame-Operations",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "3. Work on a Dataset",
          "3.2. Pandas DataFrame Operations"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "df.head(3)",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "3.2.-Pandas-DataFrame-Operations",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "3. Work on a Dataset",
          "3.2. Pandas DataFrame Operations"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# select multi-columns\nX = df[[\"Molecular Weight\", \"Number of H-Bond Donors\", \"Number of Rings\", \"Number of Rotatable Bonds\"]]\n\n# keep values only, discard the df.index\nX = X.values\n\n# print the shape\nprint(\"Shape of X:\", X.shape)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "4.-Clustering",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "4. Clustering"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(X)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "4.-Clustering",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "4. Clustering"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.preprocessing import StandardScaler\n\n# create a scaler object\nscaler = StandardScaler()\n\n# transform X to Z, Z has a mean of 0 and std of 1\nZ = scaler.fit_transform(X)",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "4.1-Data-Normalization",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "4. Clustering",
          "4.1 Data Normalization"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "Z",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "4.1-Data-Normalization",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "4. Clustering",
          "4.1 Data Normalization"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(\"Check the mean of each feature:\", Z.mean(axis=0))\nprint(\"Check the std of each feature:\", Z.sdt(axis=0))",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "4.1-Data-Normalization",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "4. Clustering",
          "4.1 Data Normalization"
        ]
      },
      "doc_lineno": 1536
    },
    {
      "source": "from sklearn.cluster import KMeans\n\n# please explore n_clusters\nn_clusters = 3\n\nk_means = KMeans(n_clusters, init=\"k-means++\")\n\n# fit data\nk_means.fit(Z)\n\n# fetch predicted labels for each datapoint\nlabels = k_means.labels_",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "4.2-K-means-Clustering",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "4. Clustering",
          "4.2 K-means Clustering"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# you can use for-loop to find out the size, but here's a quicker way\nfrom collections import Counter\nCounter(labels)",
      "names": [
        {
          "import_components": [
            "collections"
          ],
          "code_str": "collections",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_from",
          "resolved_location": "collections"
        },
        {
          "import_components": [
            "collections",
            "Counter"
          ],
          "code_str": "Counter",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "collections.Counter"
        },
        {
          "import_components": [
            "collections",
            "Counter"
          ],
          "code_str": "Counter",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "collections.Counter"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "4.2-K-means-Clustering",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "4. Clustering",
          "4.2 K-means Clustering"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "ssd = k_means.inertia_\nprint(f\"Sum of squared distance after model fitting: {ssd:.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "4.2-K-means-Clustering",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "4. Clustering",
          "4.2 K-means Clustering"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.cluster import DBSCAN\n\neps = 0.5\nmin_samples = 5\n\ndbscan = DBSCAN(eps=eps, min_samples=min_samples, \\\n    metric=\"euclidean\", algorithm=\"auto\")\n\ndbscan.fit(Z)",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "4.3-DBSCAN-Clustering",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "4. Clustering",
          "4.3 DBSCAN Clustering"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "counter = Counter(dbscan.labels_)\n# remove cluster_id=-1\ncounter.pop(-1)\n\nprint(\"Number of clusters:\", len(counter))\nprint(\"Size of each cluster:\", counter)",
      "names": [
        {
          "import_components": [
            "collections",
            "Counter"
          ],
          "code_str": "Counter",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "collections.Counter"
        },
        {
          "import_components": [
            "collections",
            "Counter",
            "()"
          ],
          "code_str": "counter",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "collections.Counter"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "collections",
            "Counter",
            "()"
          ],
          "code_str": "counter",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "collections.Counter"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "collections",
            "Counter",
            "()"
          ],
          "code_str": "counter",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "collections.Counter"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "4.3-DBSCAN-Clustering",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "4. Clustering",
          "4.3 DBSCAN Clustering"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.decomposition import PCA\nn_components = 1\npca = PCA(n_components=n_components)\npca.fit(Z)\n\nZ_reduced = pca.transform(Z)\nprint(\"Shape of the reduced matrix:\", Z_reduced.shape)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "5.1-PCA-on-Molecular-Descriptors",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "5. Dimensionality Reduction using PCA",
          "5.1 PCA on Molecular Descriptors"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# principal components\npca.components_",
      "names": [],
      "example": {
        "document": "homeworks/hw1/Chem361_hw1_reference",
        "ref_id": "5.1-PCA-on-Molecular-Descriptors",
        "headings": [
          "CHEM361 - Reference Jupyter Notebook for Homework 1",
          "5. Dimensionality Reduction using PCA",
          "5.1 PCA on Molecular Descriptors"
        ]
      },
      "doc_lineno": null
    }
  ],
  "homeworks/hw2/Chem361_hw2_reference": [
    {
      "source": "import copy\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport seaborn as sns\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\ncmap = plt.get_cmap(\"tab10\")\ncolors = [cmap(i) for i in range(cmap.N)]\n\nmpl.rcParams[\"font.size\"] = 24\nmpl.rcParams[\"lines.linewidth\"] = 2",
      "names": [
        {
          "import_components": [
            "copy"
          ],
          "code_str": "copy",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "copy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "animation"
          ],
          "code_str": "matplotlib.animation",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "matplotlib.animation"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "get_cmap"
          ],
          "code_str": "plt.get_cmap",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.get_cmap"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        },
        {
          "import_components": [
            "matplotlib",
            "rcParams"
          ],
          "code_str": "mpl.rcParams",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "matplotlib.rcParams"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Linear-Regression",
        "headings": [
          "Linear Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "!pip install pandas matplotlib rdkit scikit-learn wget\n\n!python -m wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv \\\n    --output delaney-processed.csv",
      "names": [],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "1.-Install-Dependencies-and-Download-Dataset",
        "headings": [
          "Linear Regression",
          "1. Install Dependencies and Download Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "DELANEY_FILE = \"delaney-processed.csv\"\ndf = pd.read_csv(DELANEY_FILE)\nprint(f\"Number of molecules in the dataset: {df.shape[0]}\")",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "2.-Load-Dataset",
        "headings": [
          "Linear Regression",
          "2. Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\nax.scatter(df[[\"Molecular Weight\"]].values,\n           df[\"measured log solubility in mols per litre\"].values, \\\n            s=15, marker='o', \\\n            facecolors='none', edgecolor=\"blue\")\n\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"log solubility (mol/L)\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "2.-Load-Dataset",
        "headings": [
          "Linear Regression",
          "2. Load Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# since we are coding the analytical solution without using sklearn\n# add bias term (all ones) to the input features\nX = df[[\"Molecular Weight\"]].values\nX = X.reshape(-1, 1)\nX = np.hstack([np.ones_like(X), X])\n\n# ground truth\nY = df[\"measured log solubility in mols per litre\"].values\nY = Y.reshape(-1, 1)\n\nprint(\"Shape of X:\", X.shape)\nprint(\"Shape of Y:\", Y.shape)",
      "names": [
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones_like"
          ],
          "code_str": "np.ones_like",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.ones_like"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "3.-Analytical-solution-of-Linear-Regression",
        "headings": [
          "Linear Regression",
          "3. Analytical solution of Linear Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "theta = np.linalg.inv((X.T @ X)) @ (X.T @ Y)",
      "names": [
        {
          "import_components": [
            "numpy",
            "linalg",
            "inv"
          ],
          "code_str": "np.linalg.inv",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.linalg.inv"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "3.-Analytical-solution-of-Linear-Regression",
        "headings": [
          "Linear Regression",
          "3. Analytical solution of Linear Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "theta",
      "names": [],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "3.-Analytical-solution-of-Linear-Regression",
        "headings": [
          "Linear Regression",
          "3. Analytical solution of Linear Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "y_pred = X @ theta\nloss = np.mean((y_pred - Y)**2)\nprint(f\"Loss: {loss}\")",
      "names": [
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Loss",
        "headings": [
          "Linear Regression",
          "3. Analytical solution of Linear Regression",
          "Loss"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nplt.tight_layout()\nax.scatter(X[:, -1], Y.reshape(-1), \\\n            s=15, marker='o', \\\n            facecolors='none', edgecolor=\"blue\")\n\nmin_X = np.min(X[:, -1])\nmax_X = np.max(X[:, -1])\nx_line = np.linspace(np.floor(min_X), np.ceil(max_X), 100)\nx_line = x_line.reshape(-1, 1)\nx_line = np.hstack([np.ones_like(x_line), x_line])\ny_pred_line = x_line @ theta\n\nline, = ax.plot(x_line[:, -1], y_pred_line, color=\"orange\", label=\"Fitted line\")\n\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"log solubility (mol/L)\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "tight_layout"
          ],
          "code_str": "plt.tight_layout",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.tight_layout"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "floor"
          ],
          "code_str": "np.floor",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.floor"
        },
        {
          "import_components": [
            "numpy",
            "ceil"
          ],
          "code_str": "np.ceil",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.ceil"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones_like"
          ],
          "code_str": "np.ones_like",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.ones_like"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Plot-the-regression-line",
        "headings": [
          "Linear Regression",
          "3. Analytical solution of Linear Regression",
          "Plot the regression line"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "min_logS = np.min(Y)\nmax_logS = np.max(Y)\nx_line = np.linspace(np.floor(min_logS), np.ceil(max_logS), 100)\n\ntmp_df = pd.DataFrame({\"y\": Y.reshape(-1), r\"$\\hat{y}$\": y_pred.reshape(-1)})\n\n# scatter plot\ng = sns.JointGrid(x=\"y\", y=r\"$\\hat{y}$\", data=tmp_df)\ng = g.plot_joint(plt.scatter, c=\"green\", alpha=0.5)\n\n# line: y_pred = y\ny_line = np.linspace(np.floor(Y.reshape(-1)), np.ceil(Y.reshape(-1)), 200)\ng.ax_joint.plot(y_line, y_line, color=\"blue\", linestyle=\"--\");\n\n# histograms\ng = g.plot_marginals(sns.histplot, data=df, color=\"green\", kde=False)",
      "names": [
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "floor"
          ],
          "code_str": "np.floor",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.floor"
        },
        {
          "import_components": [
            "numpy",
            "ceil"
          ],
          "code_str": "np.ceil",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.ceil"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame"
          ],
          "code_str": "pd.DataFrame",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "pandas.DataFrame"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "scatter"
          ],
          "code_str": "plt.scatter",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.scatter"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "floor"
          ],
          "code_str": "np.floor",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.floor"
        },
        {
          "import_components": [
            "numpy",
            "ceil"
          ],
          "code_str": "np.ceil",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.ceil"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Plot-Coefficient-of-Determination",
        "headings": [
          "Linear Regression",
          "3. Analytical solution of Linear Regression",
          "Plot Coefficient of Determination"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.metrics import r2_score\nprint(f\"Coefficient of determination: {r2_score(Y.reshape(-1), y_pred):.2f}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Plot-Coefficient-of-Determination",
        "headings": [
          "Linear Regression",
          "3. Analytical solution of Linear Regression",
          "Plot Coefficient of Determination"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nnorm_mw = scaler.fit_transform(df[[\"Molecular Weight\"]].values)\nX = np.hstack([np.ones_like(norm_mw), norm_mw])",
      "names": [
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones_like"
          ],
          "code_str": "np.ones_like",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.ones_like"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Data-Normalization",
        "headings": [
          "Linear Regression",
          "4. Gradient Descent Solution of Linear Regression",
          "Data Normalization"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "lr = 1e-1\n\ntheta_list = []\nloss_list = []\ntheta = np.array([0, 0]).reshape(-1, 1)\nn_epochs = 20\n\nfor _ in range(n_epochs):\n    theta_list.append(copy.deepcopy(theta))\n    y_pred = X @ theta\n    loss = np.mean((y_pred - Y).reshape(-1)**2)\n    loss_list.append(loss)\n    grad = 2*X.T @ (X @ theta - Y) / Y.shape[0]\n    theta = theta - lr * grad",
      "names": [
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "copy",
            "deepcopy"
          ],
          "code_str": "copy.deepcopy",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "copy.deepcopy"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Gradient-Descent-Fitting",
        "headings": [
          "Linear Regression",
          "4. Gradient Descent Solution of Linear Regression",
          "Gradient Descent Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(\"Final loss:\", loss_list[-1])",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Gradient-Descent-Fitting",
        "headings": [
          "Linear Regression",
          "4. Gradient Descent Solution of Linear Regression",
          "Gradient Descent Fitting"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(loss_list, c=\"blue\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Plot-Training-Curve",
        "headings": [
          "Linear Regression",
          "4. Gradient Descent Solution of Linear Regression",
          "Plot Training Curve"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def V(xx, yy):\n    losses = []\n    theta = np.hstack([xx.reshape(-1, 1), yy.reshape(-1, 1)])\n    for i in range(theta.shape[0]):\n        y_pred = X @ theta[i].reshape(-1, 1)\n        loss = np.mean((y_pred - Y).reshape(-1)**2)\n        losses.append(loss)\n    return np.array(losses)\n\n# calculate contour\nt1 = np.arange(-6, 2, 1e-1)\nt2 = np.arange(-4, 4, 1e-1)\nxx, yy = np.meshgrid(t1, t2)\nz = V(xx.ravel(), yy.ravel()).reshape(len(t2), -1)",
      "names": [
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Plot-Parameter-Contour",
        "headings": [
          "Linear Regression",
          "4. Gradient Descent Solution of Linear Regression",
          "Plot Parameter Contour"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig,ax = plt.subplots(1,1,figsize=(5,5))\n\nn_levels = 75\nc = ax.contourf(t1, t2, z, cmap='rainbow', levels=n_levels, zorder=1)\nax.contour(t1,t2, z, levels=n_levels, zorder=1, colors='black', alpha=0.2)\ncb = fig.colorbar(c)\ncb.set_label(\"Loss\")\n\nr=0.1\ng=0.1\nb=0.2\nax.patch.set_facecolor((r,g,b,.15))\n\n\n# plot trajectory\nfor i in range(len(theta_list)-1):\n    plt.quiver(theta_list[i][0], theta_list[i][1], # from point\n               theta_list[i+1][0]-theta_list[i][0],  theta_list[i+1][1]-theta_list[i][1], # to point:\n               angles=\"xy\", scale_units=\"xy\", scale=1, color=\"black\",\n               linewidth=1.5)\n\n\nax.set_xlabel(r'$\\theta_0$')\nax.set_ylabel(r'$\\theta_1$')",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Plot-Parameter-Contour",
        "headings": [
          "Linear Regression",
          "4. Gradient Descent Solution of Linear Regression",
          "Plot Parameter Contour"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n\nplt.tight_layout()\nax.scatter(X[:, -1], Y.reshape(-1), \\\n            s=15, marker='o', \\\n            facecolors='none', edgecolor=\"blue\")\n\nmin_X = np.min(X[:, -1])\nmax_X = np.max(X[:, -1])\nx_line = np.linspace(np.floor(min_X), np.ceil(max_X), 100)\nx_line = x_line.reshape(-1, 1)\nx_line = np.hstack([np.ones_like(x_line), x_line])\n\nline, = ax.plot([], [], color=\"orange\", label=\"\")\n\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"log solubility (mol/L)\")\n\nlegend = plt.legend(loc=\"upper right\")\n\ndef animate(i):\n    y_pred_line = x_line @ theta_list[i]\n    line.set_data(x_line[:, -1], y_pred_line)\n    line.set_label(f\"Epoch: {i}\")\n    legend = plt.legend()\n    return line, legend\n\n\nani = animation.FuncAnimation(f, animate, repeat=True, frames=len(theta_list), interval=100, blit=True)\n\nwriter = animation.PillowWriter(fps=10,\n                                metadata=dict(artist='Me'),\n                                bitrate=1800)\nani.save(\"theta_iteration.gif\", writer=writer)",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "tight_layout"
          ],
          "code_str": "plt.tight_layout",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.tight_layout"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "floor"
          ],
          "code_str": "np.floor",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.floor"
        },
        {
          "import_components": [
            "numpy",
            "ceil"
          ],
          "code_str": "np.ceil",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.ceil"
        },
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "numpy",
            "ones_like"
          ],
          "code_str": "np.ones_like",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "numpy.ones_like"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        },
        {
          "import_components": [
            "matplotlib",
            "animation",
            "FuncAnimation"
          ],
          "code_str": "animation.FuncAnimation",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "matplotlib.animation.FuncAnimation"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "animation",
            "PillowWriter"
          ],
          "code_str": "animation.PillowWriter",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "matplotlib.animation.PillowWriter"
        },
        {
          "import_components": [
            "dict"
          ],
          "code_str": "dict",
          "lineno": 32,
          "end_lineno": 32,
          "context": "none",
          "resolved_location": "dict"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Plot-Iterative-Procecss",
        "headings": [
          "Linear Regression",
          "4. Gradient Descent Solution of Linear Regression",
          "Plot Iterative Procecss"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "lr = 1e-1\n\ntheta_list = []\nloss_list = []\ntheta = np.array([0, 0]).reshape(-1, 1)\nn_epochs = 100\nbatch_size = 32 # change the batch size here\n\nfor _ in range(n_epochs):\n    indices = np.random.choice(X.shape[0], batch_size, replace=False)\n    theta_list.append(copy.deepcopy(theta))\n    y_pred = X[indices, :] @ theta\n    y_true = Y[indices]\n    loss = np.mean((y_pred - y_true).reshape(-1)**2)\n    loss_list.append(loss)\n    grad = 2*X[indices, :].T @ (y_pred - y_true) / len(indices)\n    theta = theta - lr * grad",
      "names": [
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "choice"
          ],
          "code_str": "np.random.choice",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "numpy.random.choice"
        },
        {
          "import_components": [
            "copy",
            "deepcopy"
          ],
          "code_str": "copy.deepcopy",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "copy.deepcopy"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "5.-Stochastic-Gradient-Descent-and-Mini-batching",
        "headings": [
          "Linear Regression",
          "5. Stochastic Gradient Descent and Mini-batching"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(\"Final loss:\", pd.Series(loss_list).rolling(5).mean().iloc[-1])",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "pandas",
            "Series"
          ],
          "code_str": "pd.Series",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "pandas.Series"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "5.-Stochastic-Gradient-Descent-and-Mini-batching",
        "headings": [
          "Linear Regression",
          "5. Stochastic Gradient Descent and Mini-batching"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nax.plot(loss_list, c=\"blue\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "id1",
        "headings": [
          "Linear Regression",
          "5. Stochastic Gradient Descent and Mini-batching",
          "Plot Training Curve"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def V(xx, yy):\n    losses = []\n    theta = np.hstack([xx.reshape(-1, 1), yy.reshape(-1, 1)])\n    for i in range(theta.shape[0]):\n        y_pred = X @ theta[i].reshape(-1, 1)\n        loss = np.mean((y_pred - Y).reshape(-1)**2) # mse\n        losses.append(loss)\n    return np.array(losses)\n\n# calculate contour\nregion = np.stack(theta_list)\n\nt1 = np.arange(-6, 2, 1e-1)\nt2 = np.arange(-4, 4, 1e-1)\nxx, yy = np.meshgrid(t1, t2)\nz = V(xx.ravel(), yy.ravel()).reshape(len(t2), -1)",
      "names": [
        {
          "import_components": [
            "numpy",
            "hstack"
          ],
          "code_str": "np.hstack",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.hstack"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "stack"
          ],
          "code_str": "np.stack",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.stack"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "meshgrid"
          ],
          "code_str": "np.meshgrid",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.meshgrid"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Parameter-Contour",
        "headings": [
          "Linear Regression",
          "5. Stochastic Gradient Descent and Mini-batching",
          "Parameter Contour"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "fig,ax = plt.subplots(1,1,figsize=(5,5))\n\n# z = np.ma.masked_greater(z, 10)\nn_levels = 75\nc = ax.contourf(t1, t2, z, cmap='rainbow', levels=n_levels, zorder=1)\nax.contour(t1,t2, z, levels=n_levels, zorder=1, colors='black', alpha=0.2)\ncb = fig.colorbar(c)\ncb.set_label(\"Loss\")\n\nr=0.1\ng=0.1\nb=0.2\nax.patch.set_facecolor((r,g,b,.15))\n\n\n# plot trajectory\n\nfor i in range(50):\n    plt.quiver(theta_list[i][0], theta_list[i][1], # from point\n               theta_list[i+1][0]-theta_list[i][0],  theta_list[i+1][1]-theta_list[i][1], # to point:\n               angles=\"xy\", scale_units=\"xy\", scale=1, color=\"black\",\n               linewidth=1.5)\n\n\nax.set_xlabel(r'$\\theta_0$')\nax.set_ylabel(r'$\\theta_1$')",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "quiver"
          ],
          "code_str": "plt.quiver",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.quiver"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Parameter-Contour",
        "headings": [
          "Linear Regression",
          "5. Stochastic Gradient Descent and Mini-batching",
          "Parameter Contour"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# features\n# we don't have to add bias manually when using sklearn LinearRegression\nX = df[[\"Molecular Weight\"]].values\nX = X.reshape(-1, 1)\n\n# ground truth\nY = df[\"measured log solubility in mols per litre\"].values\nY = Y.reshape(-1, 1)",
      "names": [],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "6.-SKLearn-Linear-Regression",
        "headings": [
          "Linear Regression",
          "6. SKLearn Linear Regression"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "model = LinearRegression()\nmodel.fit(X, Y)",
      "names": [],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Fit-Model",
        "headings": [
          "Linear Regression",
          "6. SKLearn Linear Regression",
          "Fit Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "print(\"Intercept:\", model.intercept_)\nprint(\"Coefficients:\", model.coef_)",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Fit-Model",
        "headings": [
          "Linear Regression",
          "6. SKLearn Linear Regression",
          "Fit Model"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from sklearn.metrics import mean_squared_error\n\ny_pred = model.predict(X)\nmse = mean_squared_error(Y, y_pred)\nprint(f\"Loss: {mse}\")",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "id2",
        "headings": [
          "Linear Regression",
          "6. SKLearn Linear Regression",
          "Loss"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "f, ax = plt.subplots(1, 1, figsize=(5,5))\n\nplt.tight_layout()\nax.scatter(X, Y, \\\n            s=15, marker='o', \\\n            facecolors='none', edgecolor=\"blue\")\n\nmin_X = np.min(X)\nmax_X = np.max(X)\n\nx_line = np.linspace(np.floor(min_X), np.ceil(max_X), 100)\nx_line = x_line.reshape(-1, 1)\ny_pred_line = model.predict(x_line)\n\nline, = ax.plot(x_line[:, -1], y_pred_line, color=\"orange\", label=\"Fitted line\")\n\nax.set_xlabel(\"Molecular Weight (Da.)\")\nax.set_ylabel(\"log solubility (mol/L)\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "tight_layout"
          ],
          "code_str": "plt.tight_layout",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.tight_layout"
        },
        {
          "import_components": [
            "numpy",
            "min"
          ],
          "code_str": "np.min",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.min"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "linspace"
          ],
          "code_str": "np.linspace",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.linspace"
        },
        {
          "import_components": [
            "numpy",
            "floor"
          ],
          "code_str": "np.floor",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.floor"
        },
        {
          "import_components": [
            "numpy",
            "ceil"
          ],
          "code_str": "np.ceil",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "numpy.ceil"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "Visualize-Results",
        "headings": [
          "Linear Regression",
          "6. SKLearn Linear Regression",
          "Visualize Results"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# polynomial regression on one feature\nX = df[[\"Molecular Weight\"]].values\n\n# ground truth\nY = df[\"measured log solubility in mols per litre\"].values\nY = Y.reshape(-1, 1)",
      "names": [],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "7.-Cross-Validation-and-Model-Selection",
        "headings": [
          "Linear Regression",
          "7. Cross Validation and Model Selection"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "## k-fold split from sklearn\nfrom sklearn.model_selection import KFold",
      "names": [],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "7.-Cross-Validation-and-Model-Selection",
        "headings": [
          "Linear Regression",
          "7. Cross Validation and Model Selection"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# define train/validation on one fold\ndef run_one_fold(X_train, y_train, X_test, y_test, M, normalize=True):\n    poly_features = PolynomialFeatures(degree=M)\n    X_train_poly = poly_features.fit_transform(X_train)\n    X_test_poly = poly_features.fit_transform(X_test)\n\n    if normalize:\n        scaler = StandardScaler()\n        X_train_poly = scaler.fit_transform(X_train_poly)\n        X_test_poly = scaler.transform(X_test_poly)\n    else:\n        scaler = None\n\n    model = LinearRegression()\n    model.fit(X_train_poly, y_train)\n\n    # predict and calculate rmse of training dataset\n    y_train_pred = model.predict(X_train_poly)\n    mse_train = np.mean((y_train_pred-y_train)**2)\n\n    # predict and calculate rmse of test dataset\n    y_test_pred = model.predict(X_test_poly)\n    mse_test = np.mean((y_test_pred-y_test)**2)\n    return mse_train, mse_test",
      "names": [
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "numpy.mean"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "7.-Cross-Validation-and-Model-Selection",
        "headings": [
          "Linear Regression",
          "7. Cross Validation and Model Selection"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "n_splits = 10 # 10-fold split\norders = [0, 1, 5, 10] # polynomial orders to scan\n\nmse_train_list = []\nstd_train_list = []\nmse_test_list = []\nstd_test_list = []\n\ncv_df = pd.DataFrame(columns=[\"M\", \"MSE_train\", \"MSE_test\"])\n\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\nfor M in orders:\n    mse_train_fold = []\n    mse_test_fold = []\n\n    for train_index, test_index in kf.split(X):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = Y[train_index], Y[test_index]\n\n        mse_train, mse_test = run_one_fold(X_train, y_train, X_test, y_test, M)\n        mse_train_fold.append(mse_train)\n        mse_test_fold.append(mse_test)\n\n    mse_train_list.append(np.mean(mse_train_fold))\n    std_train_list.append(np.std(mse_train_fold))\n    mse_test_list.append(np.mean(mse_test_fold))\n    std_test_list.append(np.std(mse_test_fold))",
      "names": [
        {
          "import_components": [
            "pandas",
            "DataFrame"
          ],
          "code_str": "pd.DataFrame",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "pandas.DataFrame"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.std"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "7.-Cross-Validation-and-Model-Selection",
        "headings": [
          "Linear Regression",
          "7. Cross Validation and Model Selection"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "plt.figure(figsize=(5, 5))\nplt.errorbar(orders, mse_train_list, yerr=std_train_list, color=\"b\", \\\n    marker=\"o\", markersize=10, markerfacecolor=\"none\", markeredgecolor=\"b\",\n    capsize=5, label=\"Training\")\nplt.errorbar(orders, mse_test_list, yerr=std_test_list, color=\"r\", \\\n    marker=\"o\", markersize=10, markerfacecolor=\"none\", markeredgecolor=\"r\",\n    capsize=5, label=\"Test\")\nplt.xlabel(\"Polynomial Order\")\nplt.ylabel(\"Error (MSE)\")\nplt.xticks(orders)\nplt.ylim([0, 8])\nplt.legend()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "errorbar"
          ],
          "code_str": "plt.errorbar",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.errorbar"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "errorbar"
          ],
          "code_str": "plt.errorbar",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.errorbar"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xticks"
          ],
          "code_str": "plt.xticks",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xticks"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        }
      ],
      "example": {
        "document": "homeworks/hw2/Chem361_hw2_reference",
        "ref_id": "7.-Cross-Validation-and-Model-Selection",
        "headings": [
          "Linear Regression",
          "7. Cross Validation and Model Selection"
        ]
      },
      "doc_lineno": null
    }
  ],
  "how2cite": [],
  "index": []
}